{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cuda_path = 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0\\\\bin'\n",
    "cudnn_path = 'D:\\\\Work\\\\software\\\\cuda\\\\bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + cuda_path\n",
    "os.environ[\"PATH\"] += os.pathsep + cudnn_path\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading..Orbitrap_aplysia/abd.pkl\n",
      "loading..Orbitrap_aplysia/buc.pkl\n"
     ]
    }
   ],
   "source": [
    "#import analysis\n",
    "import sys\n",
    "sys.path.insert(0,'./scripts/')\n",
    "\n",
    "import test_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots,scatter\n",
    "import seaborn as sns\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "\n",
    "def read_data(file_dir,DB_file_dir):\n",
    "    \n",
    "    data = []\n",
    "    label = []\n",
    "    \n",
    "    for i in range(len(file_dir)):\n",
    "        print('loading..{}'.format(file_dir[i]))\n",
    "        df=pd.read_pickle(file_dir[i])\n",
    "        psm_ID=list(pd.read_csv(DB_file_dir[i])['Scan'])\n",
    "        y=np.zeros(df.shape[0])\n",
    "\n",
    "        for i in range(0,df.shape[0]):\n",
    "            if df.index[i] in psm_ID:\n",
    "                y[i]=1\n",
    "\n",
    "        X = df.drop('RT',axis=1).fillna(0).values\n",
    "        y =y.astype(int)[X.sum(axis=1)!=0]\n",
    "        X = X[X.sum(axis=1)!=0]\n",
    "        X = X/X.max(axis=1).reshape(X.shape[0],1) #normalization\n",
    "        data.append(X)\n",
    "        label.append(y)\n",
    "        del X\n",
    "\n",
    "    data = np.concatenate((data))\n",
    "    label = np.concatenate((label))\n",
    "    return data,label\n",
    "\n",
    "file_dir = ['Orbitrap_aplysia/abd.pkl','Orbitrap_aplysia/buc.pkl']\n",
    "DB_file_dir = ['Aplysia_ganglia/Abdominal/DB search psm.csv','Aplysia_ganglia/Buccal/DB search psm.csv']\n",
    "\n",
    "data,label = read_data(file_dir,DB_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape((data.shape[0],data.shape[1],1))\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=1)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Conv1D, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling1D, AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# import tensorflow as tf\n",
    "# K.clear_session()\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "# sess = tf.Session(config=config)\n",
    "# set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "num_classes = 2\n",
    "input_shape = x_train.shape[1:]\n",
    "scale_weight = y_train[y_train==0].shape[0]/y_train[y_train==1].shape[0]\n",
    "\n",
    "n = 1\n",
    "version = 2\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Input image dimensions.\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train_aug = keras.utils.to_categorical(y_train_aug, num_classes)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3464, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train[:,1]==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-2\n",
    "    if epoch > 100:\n",
    "        lr *= 0.5e-6\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-6\n",
    "    elif epoch > 60:\n",
    "        lr *= 1e-5\n",
    "    elif epoch > 40:\n",
    "        lr *= 1e-4\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=8,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv1D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=2):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv1D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling1D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "INTERESTING_CLASS_ID =  1 # Choose the class of interest\n",
    "\n",
    "def single_class_accuracy(y_true, y_pred):\n",
    "    class_id_true = K.argmax(y_true, axis=-1)\n",
    "    class_id_preds = K.argmax(y_pred, axis=-1)\n",
    "    accuracy_mask = K.cast(K.equal(class_id_preds, INTERESTING_CLASS_ID), 'int32')\n",
    "    #recall_mask = K.cast(K.equal(class_id_true, INTERESTING_CLASS_ID), 'int32')\n",
    "\n",
    "    class_acc_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * accuracy_mask\n",
    "    #class_recall_tensor = K.cast(K.equal(class_id_true, class_id_true), 'int32') * recall_mask\n",
    "    class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n",
    "    #class_recall = K.sum(class_recall_tensor) / K.maximum(K.sum(recall_mask), 1)\n",
    "    return class_acc\n",
    "\n",
    "def single_class_recall(y_true, y_pred):\n",
    "    class_id_true = K.argmax(y_true, axis=-1)\n",
    "    class_id_preds = K.argmax(y_pred, axis=-1)\n",
    "    #accuracy_mask = K.cast(K.equal(class_id_preds, INTERESTING_CLASS_ID), 'int32')\n",
    "    recall_mask = K.cast(K.equal(class_id_true, INTERESTING_CLASS_ID), 'int32')\n",
    "\n",
    "    #class_acc_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * accuracy_mask\n",
    "    class_recall_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * recall_mask\n",
    "    #class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n",
    "    class_recall = K.sum(class_recall_tensor) / K.maximum(K.sum(recall_mask), 1)\n",
    "    return class_recall\n",
    "\n",
    "# if version == 2:\n",
    "#     model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "# else:\n",
    "#     model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adadelta(lr=1e-3),\n",
    "#                   metrics=[recall_m,precision_m,f1_m,single_class_accuracy,single_class_recall])\n",
    "# model.summary()\n",
    "# print(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 65244 samples, validate on 27962 samples\n",
      "Epoch 1/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 336s 5ms/step - loss: 1.2753 - recall_m: 0.7298 - precision_m: 0.7298 - f1_m: 0.7298 - single_class_accuracy: 0.1495 - single_class_recall: 0.6155 - val_loss: 0.6559 - val_recall_m: 0.8479 - val_precision_m: 0.8479 - val_f1_m: 0.8479 - val_single_class_accuracy: 0.2324 - val_single_class_recall: 0.6474\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.23245, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.001.h5\n",
      "Epoch 2/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 1.0236 - recall_m: 0.8503 - precision_m: 0.8503 - f1_m: 0.8503 - single_class_accuracy: 0.2434 - single_class_recall: 0.7042 - val_loss: 0.6374 - val_recall_m: 0.8625 - val_precision_m: 0.8625 - val_f1_m: 0.8625 - val_single_class_accuracy: 0.2548 - val_single_class_recall: 0.6793\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.23245 to 0.25480, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.002.h5\n",
      "Epoch 3/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.9654 - recall_m: 0.8637 - precision_m: 0.8637 - f1_m: 0.8637 - single_class_accuracy: 0.2601 - single_class_recall: 0.7146 - val_loss: 0.6547 - val_recall_m: 0.8543 - val_precision_m: 0.8543 - val_f1_m: 0.8543 - val_single_class_accuracy: 0.2462 - val_single_class_recall: 0.7065\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy did not improve from 0.25480\n",
      "Epoch 4/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.9311 - recall_m: 0.8677 - precision_m: 0.8677 - f1_m: 0.8677 - single_class_accuracy: 0.2701 - single_class_recall: 0.7274 - val_loss: 0.6305 - val_recall_m: 0.8621 - val_precision_m: 0.8621 - val_f1_m: 0.8621 - val_single_class_accuracy: 0.2598 - val_single_class_recall: 0.7071\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.25480 to 0.25976, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.004.h5\n",
      "Epoch 5/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.9026 - recall_m: 0.8728 - precision_m: 0.8728 - f1_m: 0.8728 - single_class_accuracy: 0.2754 - single_class_recall: 0.7256 - val_loss: 0.5811 - val_recall_m: 0.8770 - val_precision_m: 0.8770 - val_f1_m: 0.8770 - val_single_class_accuracy: 0.2806 - val_single_class_recall: 0.6855\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy improved from 0.25976 to 0.28060, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.005.h5\n",
      "Epoch 6/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.8812 - recall_m: 0.8752 - precision_m: 0.8752 - f1_m: 0.8752 - single_class_accuracy: 0.2808 - single_class_recall: 0.7245 - val_loss: 0.5968 - val_recall_m: 0.8731 - val_precision_m: 0.8731 - val_f1_m: 0.8731 - val_single_class_accuracy: 0.2772 - val_single_class_recall: 0.7062\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy did not improve from 0.28060\n",
      "Epoch 7/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.8597 - recall_m: 0.8782 - precision_m: 0.8782 - f1_m: 0.8782 - single_class_accuracy: 0.2889 - single_class_recall: 0.7513 - val_loss: 0.6243 - val_recall_m: 0.8633 - val_precision_m: 0.8633 - val_f1_m: 0.8633 - val_single_class_accuracy: 0.2654 - val_single_class_recall: 0.7279\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy did not improve from 0.28060\n",
      "Epoch 8/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.8371 - recall_m: 0.8832 - precision_m: 0.8832 - f1_m: 0.8832 - single_class_accuracy: 0.2971 - single_class_recall: 0.7412 - val_loss: 0.5766 - val_recall_m: 0.8787 - val_precision_m: 0.8787 - val_f1_m: 0.8787 - val_single_class_accuracy: 0.2856 - val_single_class_recall: 0.7091\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy improved from 0.28060 to 0.28565, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.008.h5\n",
      "Epoch 9/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.8256 - recall_m: 0.8850 - precision_m: 0.8850 - f1_m: 0.8850 - single_class_accuracy: 0.3004 - single_class_recall: 0.7441 - val_loss: 0.5619 - val_recall_m: 0.8824 - val_precision_m: 0.8824 - val_f1_m: 0.8824 - val_single_class_accuracy: 0.2940 - val_single_class_recall: 0.7038\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy improved from 0.28565 to 0.29402, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.009.h5\n",
      "Epoch 10/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.8094 - recall_m: 0.8866 - precision_m: 0.8866 - f1_m: 0.8866 - single_class_accuracy: 0.3048 - single_class_recall: 0.7550 - val_loss: 0.5199 - val_recall_m: 0.8973 - val_precision_m: 0.8973 - val_f1_m: 0.8973 - val_single_class_accuracy: 0.3172 - val_single_class_recall: 0.6772\n",
      "\n",
      "Epoch 00010: val_single_class_accuracy improved from 0.29402 to 0.31721, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.010.h5\n",
      "Epoch 11/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.7955 - recall_m: 0.8901 - precision_m: 0.8901 - f1_m: 0.8901 - single_class_accuracy: 0.3146 - single_class_recall: 0.7495 - val_loss: 0.5523 - val_recall_m: 0.8843 - val_precision_m: 0.8843 - val_f1_m: 0.8843 - val_single_class_accuracy: 0.2954 - val_single_class_recall: 0.7055\n",
      "\n",
      "Epoch 00011: val_single_class_accuracy did not improve from 0.31721\n",
      "Epoch 12/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.7826 - recall_m: 0.8903 - precision_m: 0.8903 - f1_m: 0.8903 - single_class_accuracy: 0.3144 - single_class_recall: 0.7523 - val_loss: 0.6043 - val_recall_m: 0.8652 - val_precision_m: 0.8652 - val_f1_m: 0.8652 - val_single_class_accuracy: 0.2683 - val_single_class_recall: 0.7358\n",
      "\n",
      "Epoch 00012: val_single_class_accuracy did not improve from 0.31721\n",
      "Epoch 13/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.7703 - recall_m: 0.8928 - precision_m: 0.8928 - f1_m: 0.8928 - single_class_accuracy: 0.3208 - single_class_recall: 0.7602 - val_loss: 0.5006 - val_recall_m: 0.9056 - val_precision_m: 0.9056 - val_f1_m: 0.9056 - val_single_class_accuracy: 0.3343 - val_single_class_recall: 0.6621\n",
      "\n",
      "Epoch 00013: val_single_class_accuracy improved from 0.31721 to 0.33428, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.013.h5\n",
      "Epoch 14/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.7649 - recall_m: 0.8943 - precision_m: 0.8943 - f1_m: 0.8943 - single_class_accuracy: 0.3255 - single_class_recall: 0.7534 - val_loss: 0.5897 - val_recall_m: 0.8727 - val_precision_m: 0.8727 - val_f1_m: 0.8727 - val_single_class_accuracy: 0.2798 - val_single_class_recall: 0.7244\n",
      "\n",
      "Epoch 00014: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 15/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.7532 - recall_m: 0.8965 - precision_m: 0.8965 - f1_m: 0.8965 - single_class_accuracy: 0.3309 - single_class_recall: 0.7549 - val_loss: 0.6214 - val_recall_m: 0.8614 - val_precision_m: 0.8614 - val_f1_m: 0.8614 - val_single_class_accuracy: 0.2664 - val_single_class_recall: 0.7437\n",
      "\n",
      "Epoch 00015: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 16/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.7449 - recall_m: 0.8989 - precision_m: 0.8989 - f1_m: 0.8989 - single_class_accuracy: 0.3339 - single_class_recall: 0.7523 - val_loss: 0.6707 - val_recall_m: 0.8402 - val_precision_m: 0.8402 - val_f1_m: 0.8402 - val_single_class_accuracy: 0.2397 - val_single_class_recall: 0.7583\n",
      "\n",
      "Epoch 00016: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 17/100\n",
      "Learning rate:  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.7319 - recall_m: 0.8999 - precision_m: 0.8999 - f1_m: 0.8999 - single_class_accuracy: 0.3315 - single_class_recall: 0.7573 - val_loss: 0.5207 - val_recall_m: 0.8951 - val_precision_m: 0.8951 - val_f1_m: 0.8951 - val_single_class_accuracy: 0.3155 - val_single_class_recall: 0.6928\n",
      "\n",
      "Epoch 00017: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 18/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.7268 - recall_m: 0.9022 - precision_m: 0.9022 - f1_m: 0.9022 - single_class_accuracy: 0.3470 - single_class_recall: 0.7599 - val_loss: 0.5614 - val_recall_m: 0.8810 - val_precision_m: 0.8810 - val_f1_m: 0.8810 - val_single_class_accuracy: 0.2954 - val_single_class_recall: 0.7169\n",
      "\n",
      "Epoch 00018: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 19/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.7214 - recall_m: 0.9030 - precision_m: 0.9030 - f1_m: 0.9030 - single_class_accuracy: 0.3473 - single_class_recall: 0.7731 - val_loss: 0.6064 - val_recall_m: 0.8651 - val_precision_m: 0.8651 - val_f1_m: 0.8651 - val_single_class_accuracy: 0.2738 - val_single_class_recall: 0.7368\n",
      "\n",
      "Epoch 00019: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 20/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.7108 - recall_m: 0.9051 - precision_m: 0.9051 - f1_m: 0.9051 - single_class_accuracy: 0.3533 - single_class_recall: 0.7671 - val_loss: 0.5968 - val_recall_m: 0.8686 - val_precision_m: 0.8686 - val_f1_m: 0.8686 - val_single_class_accuracy: 0.2792 - val_single_class_recall: 0.7399\n",
      "\n",
      "Epoch 00020: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 21/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.7006 - recall_m: 0.9072 - precision_m: 0.9072 - f1_m: 0.9072 - single_class_accuracy: 0.3609 - single_class_recall: 0.7758 - val_loss: 0.5469 - val_recall_m: 0.8861 - val_precision_m: 0.8861 - val_f1_m: 0.8861 - val_single_class_accuracy: 0.3033 - val_single_class_recall: 0.7118\n",
      "\n",
      "Epoch 00021: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 22/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.6953 - recall_m: 0.9082 - precision_m: 0.9082 - f1_m: 0.9082 - single_class_accuracy: 0.3567 - single_class_recall: 0.7654 - val_loss: 0.6397 - val_recall_m: 0.8546 - val_precision_m: 0.8546 - val_f1_m: 0.8546 - val_single_class_accuracy: 0.2584 - val_single_class_recall: 0.7499\n",
      "\n",
      "Epoch 00022: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 23/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6851 - recall_m: 0.9103 - precision_m: 0.9103 - f1_m: 0.9103 - single_class_accuracy: 0.3645 - single_class_recall: 0.7781 - val_loss: 0.5951 - val_recall_m: 0.8685 - val_precision_m: 0.8685 - val_f1_m: 0.8685 - val_single_class_accuracy: 0.2765 - val_single_class_recall: 0.7385\n",
      "\n",
      "Epoch 00023: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 24/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6793 - recall_m: 0.9119 - precision_m: 0.9119 - f1_m: 0.9119 - single_class_accuracy: 0.3709 - single_class_recall: 0.7708 - val_loss: 0.5544 - val_recall_m: 0.8836 - val_precision_m: 0.8836 - val_f1_m: 0.8836 - val_single_class_accuracy: 0.2986 - val_single_class_recall: 0.7193\n",
      "\n",
      "Epoch 00024: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 25/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.6775 - recall_m: 0.9118 - precision_m: 0.9118 - f1_m: 0.9118 - single_class_accuracy: 0.3681 - single_class_recall: 0.7645 - val_loss: 0.5664 - val_recall_m: 0.8805 - val_precision_m: 0.8805 - val_f1_m: 0.8805 - val_single_class_accuracy: 0.2974 - val_single_class_recall: 0.7305\n",
      "\n",
      "Epoch 00025: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 26/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6698 - recall_m: 0.9143 - precision_m: 0.9143 - f1_m: 0.9143 - single_class_accuracy: 0.3761 - single_class_recall: 0.7688 - val_loss: 0.5689 - val_recall_m: 0.8792 - val_precision_m: 0.8792 - val_f1_m: 0.8792 - val_single_class_accuracy: 0.2910 - val_single_class_recall: 0.7312\n",
      "\n",
      "Epoch 00026: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 27/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6613 - recall_m: 0.9164 - precision_m: 0.9164 - f1_m: 0.9164 - single_class_accuracy: 0.3812 - single_class_recall: 0.7679 - val_loss: 0.5595 - val_recall_m: 0.8828 - val_precision_m: 0.8828 - val_f1_m: 0.8828 - val_single_class_accuracy: 0.2987 - val_single_class_recall: 0.7198\n",
      "\n",
      "Epoch 00027: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 28/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.6596 - recall_m: 0.9162 - precision_m: 0.9162 - f1_m: 0.9162 - single_class_accuracy: 0.3782 - single_class_recall: 0.7741 - val_loss: 0.5973 - val_recall_m: 0.8701 - val_precision_m: 0.8701 - val_f1_m: 0.8701 - val_single_class_accuracy: 0.2794 - val_single_class_recall: 0.7407\n",
      "\n",
      "Epoch 00028: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 29/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6509 - recall_m: 0.9172 - precision_m: 0.9172 - f1_m: 0.9172 - single_class_accuracy: 0.3840 - single_class_recall: 0.7682 - val_loss: 0.5529 - val_recall_m: 0.8847 - val_precision_m: 0.8847 - val_f1_m: 0.8847 - val_single_class_accuracy: 0.3011 - val_single_class_recall: 0.7234\n",
      "\n",
      "Epoch 00029: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 30/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6462 - recall_m: 0.9185 - precision_m: 0.9185 - f1_m: 0.9185 - single_class_accuracy: 0.3894 - single_class_recall: 0.7779 - val_loss: 0.5921 - val_recall_m: 0.8724 - val_precision_m: 0.8724 - val_f1_m: 0.8724 - val_single_class_accuracy: 0.2833 - val_single_class_recall: 0.7419\n",
      "\n",
      "Epoch 00030: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 31/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6408 - recall_m: 0.9197 - precision_m: 0.9197 - f1_m: 0.9197 - single_class_accuracy: 0.3868 - single_class_recall: 0.7637 - val_loss: 0.5405 - val_recall_m: 0.8890 - val_precision_m: 0.8890 - val_f1_m: 0.8890 - val_single_class_accuracy: 0.3078 - val_single_class_recall: 0.7215\n",
      "\n",
      "Epoch 00031: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 32/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6357 - recall_m: 0.9214 - precision_m: 0.9214 - f1_m: 0.9214 - single_class_accuracy: 0.4020 - single_class_recall: 0.7810 - val_loss: 0.5158 - val_recall_m: 0.9000 - val_precision_m: 0.9000 - val_f1_m: 0.9000 - val_single_class_accuracy: 0.3276 - val_single_class_recall: 0.7033\n",
      "\n",
      "Epoch 00032: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 33/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.6302 - recall_m: 0.9226 - precision_m: 0.9226 - f1_m: 0.9226 - single_class_accuracy: 0.4014 - single_class_recall: 0.7804 - val_loss: 0.5820 - val_recall_m: 0.8752 - val_precision_m: 0.8752 - val_f1_m: 0.8752 - val_single_class_accuracy: 0.2861 - val_single_class_recall: 0.7376\n",
      "\n",
      "Epoch 00033: val_single_class_accuracy did not improve from 0.33428\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 34/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.6248 - recall_m: 0.9233 - precision_m: 0.9233 - f1_m: 0.9233 - single_class_accuracy: 0.4055 - single_class_recall: 0.7684 - val_loss: 0.5612 - val_recall_m: 0.8837 - val_precision_m: 0.8837 - val_f1_m: 0.8837 - val_single_class_accuracy: 0.3009 - val_single_class_recall: 0.7395\n",
      "\n",
      "Epoch 00034: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 35/100\n",
      "Learning rate:  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65244/65244 [==============================] - 320s 5ms/step - loss: 0.6211 - recall_m: 0.9235 - precision_m: 0.9235 - f1_m: 0.9235 - single_class_accuracy: 0.4078 - single_class_recall: 0.7881 - val_loss: 0.5176 - val_recall_m: 0.8986 - val_precision_m: 0.8986 - val_f1_m: 0.8986 - val_single_class_accuracy: 0.3262 - val_single_class_recall: 0.7152\n",
      "\n",
      "Epoch 00035: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 36/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6176 - recall_m: 0.9250 - precision_m: 0.9250 - f1_m: 0.9250 - single_class_accuracy: 0.4130 - single_class_recall: 0.7823 - val_loss: 0.5461 - val_recall_m: 0.8884 - val_precision_m: 0.8884 - val_f1_m: 0.8884 - val_single_class_accuracy: 0.3082 - val_single_class_recall: 0.7285\n",
      "\n",
      "Epoch 00036: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 37/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6078 - recall_m: 0.9265 - precision_m: 0.9265 - f1_m: 0.9265 - single_class_accuracy: 0.4161 - single_class_recall: 0.7868 - val_loss: 0.5202 - val_recall_m: 0.8980 - val_precision_m: 0.8980 - val_f1_m: 0.8980 - val_single_class_accuracy: 0.3236 - val_single_class_recall: 0.7151\n",
      "\n",
      "Epoch 00037: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 38/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 321s 5ms/step - loss: 0.6047 - recall_m: 0.9277 - precision_m: 0.9277 - f1_m: 0.9277 - single_class_accuracy: 0.4151 - single_class_recall: 0.7863 - val_loss: 0.5124 - val_recall_m: 0.9019 - val_precision_m: 0.9019 - val_f1_m: 0.9019 - val_single_class_accuracy: 0.3339 - val_single_class_recall: 0.7149\n",
      "\n",
      "Epoch 00038: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 39/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 323s 5ms/step - loss: 0.6055 - recall_m: 0.9276 - precision_m: 0.9276 - f1_m: 0.9276 - single_class_accuracy: 0.4176 - single_class_recall: 0.7779 - val_loss: 0.5813 - val_recall_m: 0.8773 - val_precision_m: 0.8773 - val_f1_m: 0.8773 - val_single_class_accuracy: 0.2908 - val_single_class_recall: 0.7378\n",
      "\n",
      "Epoch 00039: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 40/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.5967 - recall_m: 0.9282 - precision_m: 0.9282 - f1_m: 0.9282 - single_class_accuracy: 0.4189 - single_class_recall: 0.7869 - val_loss: 0.5304 - val_recall_m: 0.8947 - val_precision_m: 0.8947 - val_f1_m: 0.8947 - val_single_class_accuracy: 0.3199 - val_single_class_recall: 0.7244\n",
      "\n",
      "Epoch 00040: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 41/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 323s 5ms/step - loss: 0.5942 - recall_m: 0.9301 - precision_m: 0.9301 - f1_m: 0.9301 - single_class_accuracy: 0.4285 - single_class_recall: 0.7987 - val_loss: 0.5256 - val_recall_m: 0.8971 - val_precision_m: 0.8971 - val_f1_m: 0.8971 - val_single_class_accuracy: 0.3248 - val_single_class_recall: 0.7219\n",
      "\n",
      "Epoch 00041: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 42/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 323s 5ms/step - loss: 0.5886 - recall_m: 0.9310 - precision_m: 0.9310 - f1_m: 0.9310 - single_class_accuracy: 0.4258 - single_class_recall: 0.7881 - val_loss: 0.5151 - val_recall_m: 0.9009 - val_precision_m: 0.9009 - val_f1_m: 0.9009 - val_single_class_accuracy: 0.3317 - val_single_class_recall: 0.7133\n",
      "\n",
      "Epoch 00042: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 43/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.5865 - recall_m: 0.9305 - precision_m: 0.9305 - f1_m: 0.9305 - single_class_accuracy: 0.4312 - single_class_recall: 0.7882 - val_loss: 0.5682 - val_recall_m: 0.8800 - val_precision_m: 0.8800 - val_f1_m: 0.8800 - val_single_class_accuracy: 0.2956 - val_single_class_recall: 0.7393\n",
      "\n",
      "Epoch 00043: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 44/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 322s 5ms/step - loss: 0.5824 - recall_m: 0.9318 - precision_m: 0.9318 - f1_m: 0.9318 - single_class_accuracy: 0.4312 - single_class_recall: 0.7923 - val_loss: 0.5862 - val_recall_m: 0.8750 - val_precision_m: 0.8750 - val_f1_m: 0.8750 - val_single_class_accuracy: 0.2884 - val_single_class_recall: 0.7386\n",
      "\n",
      "Epoch 00044: val_single_class_accuracy did not improve from 0.33428\n",
      "Epoch 45/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 323s 5ms/step - loss: 0.5800 - recall_m: 0.9315 - precision_m: 0.9315 - f1_m: 0.9315 - single_class_accuracy: 0.4309 - single_class_recall: 0.7871 - val_loss: 0.5119 - val_recall_m: 0.9031 - val_precision_m: 0.9031 - val_f1_m: 0.9031 - val_single_class_accuracy: 0.3359 - val_single_class_recall: 0.7139\n",
      "\n",
      "Epoch 00045: val_single_class_accuracy improved from 0.33428 to 0.33589, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.045.h5\n",
      "Epoch 46/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 330s 5ms/step - loss: 0.5735 - recall_m: 0.9325 - precision_m: 0.9325 - f1_m: 0.9325 - single_class_accuracy: 0.4350 - single_class_recall: 0.7906 - val_loss: 0.5271 - val_recall_m: 0.8980 - val_precision_m: 0.8980 - val_f1_m: 0.8980 - val_single_class_accuracy: 0.3249 - val_single_class_recall: 0.7165\n",
      "\n",
      "Epoch 00046: val_single_class_accuracy did not improve from 0.33589\n",
      "Epoch 47/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 333s 5ms/step - loss: 0.5695 - recall_m: 0.9346 - precision_m: 0.9346 - f1_m: 0.9346 - single_class_accuracy: 0.4387 - single_class_recall: 0.7858 - val_loss: 0.5255 - val_recall_m: 0.8983 - val_precision_m: 0.8983 - val_f1_m: 0.8983 - val_single_class_accuracy: 0.3271 - val_single_class_recall: 0.7201\n",
      "\n",
      "Epoch 00047: val_single_class_accuracy did not improve from 0.33589\n",
      "Epoch 48/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 328s 5ms/step - loss: 0.5681 - recall_m: 0.9348 - precision_m: 0.9348 - f1_m: 0.9348 - single_class_accuracy: 0.4501 - single_class_recall: 0.7874 - val_loss: 0.5556 - val_recall_m: 0.8898 - val_precision_m: 0.8898 - val_f1_m: 0.8898 - val_single_class_accuracy: 0.3113 - val_single_class_recall: 0.7229\n",
      "\n",
      "Epoch 00048: val_single_class_accuracy did not improve from 0.33589\n",
      "Epoch 49/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 329s 5ms/step - loss: 0.5621 - recall_m: 0.9357 - precision_m: 0.9357 - f1_m: 0.9357 - single_class_accuracy: 0.4446 - single_class_recall: 0.7979 - val_loss: 0.4994 - val_recall_m: 0.9081 - val_precision_m: 0.9081 - val_f1_m: 0.9081 - val_single_class_accuracy: 0.3449 - val_single_class_recall: 0.7024\n",
      "\n",
      "Epoch 00049: val_single_class_accuracy improved from 0.33589 to 0.34489, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.049.h5\n",
      "Epoch 50/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 332s 5ms/step - loss: 0.5564 - recall_m: 0.9375 - precision_m: 0.9375 - f1_m: 0.9375 - single_class_accuracy: 0.4536 - single_class_recall: 0.7964 - val_loss: 0.4889 - val_recall_m: 0.9113 - val_precision_m: 0.9113 - val_f1_m: 0.9113 - val_single_class_accuracy: 0.3539 - val_single_class_recall: 0.7055\n",
      "\n",
      "Epoch 00050: val_single_class_accuracy improved from 0.34489 to 0.35389, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.050.h5\n",
      "Epoch 51/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 329s 5ms/step - loss: 0.5529 - recall_m: 0.9376 - precision_m: 0.9376 - f1_m: 0.9376 - single_class_accuracy: 0.4479 - single_class_recall: 0.7874 - val_loss: 0.5219 - val_recall_m: 0.8990 - val_precision_m: 0.8990 - val_f1_m: 0.8990 - val_single_class_accuracy: 0.3251 - val_single_class_recall: 0.7129\n",
      "\n",
      "Epoch 00051: val_single_class_accuracy did not improve from 0.35389\n",
      "Epoch 52/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 333s 5ms/step - loss: 0.5509 - recall_m: 0.9387 - precision_m: 0.9387 - f1_m: 0.9387 - single_class_accuracy: 0.4569 - single_class_recall: 0.7913 - val_loss: 0.4975 - val_recall_m: 0.9093 - val_precision_m: 0.9093 - val_f1_m: 0.9093 - val_single_class_accuracy: 0.3513 - val_single_class_recall: 0.7071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: val_single_class_accuracy did not improve from 0.35389\n",
      "Epoch 53/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 339s 5ms/step - loss: 0.5476 - recall_m: 0.9388 - precision_m: 0.9388 - f1_m: 0.9388 - single_class_accuracy: 0.4547 - single_class_recall: 0.7867 - val_loss: 0.4913 - val_recall_m: 0.9113 - val_precision_m: 0.9113 - val_f1_m: 0.9113 - val_single_class_accuracy: 0.3554 - val_single_class_recall: 0.7044\n",
      "\n",
      "Epoch 00053: val_single_class_accuracy improved from 0.35389 to 0.35539, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.053.h5\n",
      "Epoch 54/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 333s 5ms/step - loss: 0.5418 - recall_m: 0.9403 - precision_m: 0.9403 - f1_m: 0.9403 - single_class_accuracy: 0.4604 - single_class_recall: 0.7919 - val_loss: 0.4613 - val_recall_m: 0.9225 - val_precision_m: 0.9225 - val_f1_m: 0.9225 - val_single_class_accuracy: 0.3800 - val_single_class_recall: 0.6754\n",
      "\n",
      "Epoch 00054: val_single_class_accuracy improved from 0.35539 to 0.37998, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.054.h5\n",
      "Epoch 55/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 328s 5ms/step - loss: 0.5406 - recall_m: 0.9405 - precision_m: 0.9405 - f1_m: 0.9405 - single_class_accuracy: 0.4673 - single_class_recall: 0.7939 - val_loss: 0.5143 - val_recall_m: 0.9039 - val_precision_m: 0.9039 - val_f1_m: 0.9039 - val_single_class_accuracy: 0.3378 - val_single_class_recall: 0.7200\n",
      "\n",
      "Epoch 00055: val_single_class_accuracy did not improve from 0.37998\n",
      "Epoch 56/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 334s 5ms/step - loss: 0.5343 - recall_m: 0.9418 - precision_m: 0.9418 - f1_m: 0.9418 - single_class_accuracy: 0.4690 - single_class_recall: 0.7924 - val_loss: 0.4330 - val_recall_m: 0.9330 - val_precision_m: 0.9330 - val_f1_m: 0.9330 - val_single_class_accuracy: 0.4073 - val_single_class_recall: 0.6560\n",
      "\n",
      "Epoch 00056: val_single_class_accuracy improved from 0.37998 to 0.40733, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.056.h5\n",
      "Epoch 57/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 335s 5ms/step - loss: 0.5338 - recall_m: 0.9425 - precision_m: 0.9425 - f1_m: 0.9425 - single_class_accuracy: 0.4797 - single_class_recall: 0.8068 - val_loss: 0.4884 - val_recall_m: 0.9129 - val_precision_m: 0.9129 - val_f1_m: 0.9129 - val_single_class_accuracy: 0.3554 - val_single_class_recall: 0.6959\n",
      "\n",
      "Epoch 00057: val_single_class_accuracy did not improve from 0.40733\n",
      "Epoch 58/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 336s 5ms/step - loss: 0.5296 - recall_m: 0.9436 - precision_m: 0.9436 - f1_m: 0.9436 - single_class_accuracy: 0.4740 - single_class_recall: 0.7972 - val_loss: 0.4555 - val_recall_m: 0.9254 - val_precision_m: 0.9254 - val_f1_m: 0.9254 - val_single_class_accuracy: 0.3882 - val_single_class_recall: 0.6777\n",
      "\n",
      "Epoch 00058: val_single_class_accuracy did not improve from 0.40733\n",
      "Epoch 59/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 334s 5ms/step - loss: 0.5248 - recall_m: 0.9435 - precision_m: 0.9435 - f1_m: 0.9435 - single_class_accuracy: 0.4764 - single_class_recall: 0.7989 - val_loss: 0.4170 - val_recall_m: 0.9386 - val_precision_m: 0.9386 - val_f1_m: 0.9386 - val_single_class_accuracy: 0.4249 - val_single_class_recall: 0.6325\n",
      "\n",
      "Epoch 00059: val_single_class_accuracy improved from 0.40733 to 0.42490, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.059.h5\n",
      "Epoch 60/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 334s 5ms/step - loss: 0.5195 - recall_m: 0.9444 - precision_m: 0.9444 - f1_m: 0.9444 - single_class_accuracy: 0.4848 - single_class_recall: 0.8052 - val_loss: 0.4474 - val_recall_m: 0.9283 - val_precision_m: 0.9283 - val_f1_m: 0.9283 - val_single_class_accuracy: 0.3942 - val_single_class_recall: 0.6731\n",
      "\n",
      "Epoch 00060: val_single_class_accuracy did not improve from 0.42490\n",
      "Epoch 61/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 334s 5ms/step - loss: 0.5184 - recall_m: 0.9451 - precision_m: 0.9451 - f1_m: 0.9451 - single_class_accuracy: 0.4900 - single_class_recall: 0.8072 - val_loss: 0.4492 - val_recall_m: 0.9277 - val_precision_m: 0.9277 - val_f1_m: 0.9277 - val_single_class_accuracy: 0.3940 - val_single_class_recall: 0.6777\n",
      "\n",
      "Epoch 00061: val_single_class_accuracy did not improve from 0.42490\n",
      "Epoch 62/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 335s 5ms/step - loss: 0.5161 - recall_m: 0.9463 - precision_m: 0.9463 - f1_m: 0.9463 - single_class_accuracy: 0.4902 - single_class_recall: 0.7957 - val_loss: 0.4056 - val_recall_m: 0.9431 - val_precision_m: 0.9431 - val_f1_m: 0.9431 - val_single_class_accuracy: 0.4389 - val_single_class_recall: 0.6149\n",
      "\n",
      "Epoch 00062: val_single_class_accuracy improved from 0.42490 to 0.43886, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.062.h5\n",
      "Epoch 63/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 336s 5ms/step - loss: 0.5113 - recall_m: 0.9469 - precision_m: 0.9469 - f1_m: 0.9469 - single_class_accuracy: 0.4905 - single_class_recall: 0.8040 - val_loss: 0.4785 - val_recall_m: 0.9170 - val_precision_m: 0.9170 - val_f1_m: 0.9170 - val_single_class_accuracy: 0.3679 - val_single_class_recall: 0.6982\n",
      "\n",
      "Epoch 00063: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 64/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 330s 5ms/step - loss: 0.5084 - recall_m: 0.9471 - precision_m: 0.9471 - f1_m: 0.9471 - single_class_accuracy: 0.4868 - single_class_recall: 0.7981 - val_loss: 0.4648 - val_recall_m: 0.9216 - val_precision_m: 0.9216 - val_f1_m: 0.9216 - val_single_class_accuracy: 0.3770 - val_single_class_recall: 0.6904\n",
      "\n",
      "Epoch 00064: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 65/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 319s 5ms/step - loss: 0.5080 - recall_m: 0.9478 - precision_m: 0.9478 - f1_m: 0.9478 - single_class_accuracy: 0.4956 - single_class_recall: 0.8021 - val_loss: 0.4398 - val_recall_m: 0.9317 - val_precision_m: 0.9317 - val_f1_m: 0.9317 - val_single_class_accuracy: 0.4067 - val_single_class_recall: 0.6565\n",
      "\n",
      "Epoch 00065: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 66/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 320s 5ms/step - loss: 0.5018 - recall_m: 0.9481 - precision_m: 0.9481 - f1_m: 0.9481 - single_class_accuracy: 0.4969 - single_class_recall: 0.7972 - val_loss: 0.4329 - val_recall_m: 0.9335 - val_precision_m: 0.9335 - val_f1_m: 0.9335 - val_single_class_accuracy: 0.4128 - val_single_class_recall: 0.6601\n",
      "\n",
      "Epoch 00066: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 67/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 335s 5ms/step - loss: 0.4997 - recall_m: 0.9496 - precision_m: 0.9496 - f1_m: 0.9496 - single_class_accuracy: 0.4984 - single_class_recall: 0.7951 - val_loss: 0.4847 - val_recall_m: 0.9160 - val_precision_m: 0.9160 - val_f1_m: 0.9160 - val_single_class_accuracy: 0.3639 - val_single_class_recall: 0.6935\n",
      "\n",
      "Epoch 00067: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 68/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 344s 5ms/step - loss: 0.4962 - recall_m: 0.9501 - precision_m: 0.9501 - f1_m: 0.9501 - single_class_accuracy: 0.5066 - single_class_recall: 0.8093 - val_loss: 0.4184 - val_recall_m: 0.9395 - val_precision_m: 0.9395 - val_f1_m: 0.9395 - val_single_class_accuracy: 0.4264 - val_single_class_recall: 0.6356\n",
      "\n",
      "Epoch 00068: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 69/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 344s 5ms/step - loss: 0.4941 - recall_m: 0.9506 - precision_m: 0.9506 - f1_m: 0.9506 - single_class_accuracy: 0.5013 - single_class_recall: 0.8020 - val_loss: 0.4753 - val_recall_m: 0.9187 - val_precision_m: 0.9187 - val_f1_m: 0.9187 - val_single_class_accuracy: 0.3695 - val_single_class_recall: 0.6911\n",
      "\n",
      "Epoch 00069: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 70/100\n",
      "Learning rate:  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65244/65244 [==============================] - 346s 5ms/step - loss: 0.4902 - recall_m: 0.9504 - precision_m: 0.9504 - f1_m: 0.9504 - single_class_accuracy: 0.5030 - single_class_recall: 0.8026 - val_loss: 0.4324 - val_recall_m: 0.9344 - val_precision_m: 0.9344 - val_f1_m: 0.9344 - val_single_class_accuracy: 0.4171 - val_single_class_recall: 0.6576\n",
      "\n",
      "Epoch 00070: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 71/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 341s 5ms/step - loss: 0.4879 - recall_m: 0.9522 - precision_m: 0.9522 - f1_m: 0.9522 - single_class_accuracy: 0.5093 - single_class_recall: 0.7918 - val_loss: 0.4397 - val_recall_m: 0.9315 - val_precision_m: 0.9315 - val_f1_m: 0.9315 - val_single_class_accuracy: 0.4057 - val_single_class_recall: 0.6702\n",
      "\n",
      "Epoch 00071: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 72/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 339s 5ms/step - loss: 0.4856 - recall_m: 0.9523 - precision_m: 0.9523 - f1_m: 0.9523 - single_class_accuracy: 0.5156 - single_class_recall: 0.7983 - val_loss: 0.4375 - val_recall_m: 0.9325 - val_precision_m: 0.9325 - val_f1_m: 0.9325 - val_single_class_accuracy: 0.4071 - val_single_class_recall: 0.6642\n",
      "\n",
      "Epoch 00072: val_single_class_accuracy did not improve from 0.43886\n",
      "Epoch 73/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 323s 5ms/step - loss: 0.4811 - recall_m: 0.9530 - precision_m: 0.9530 - f1_m: 0.9530 - single_class_accuracy: 0.5241 - single_class_recall: 0.8157 - val_loss: 0.4122 - val_recall_m: 0.9418 - val_precision_m: 0.9418 - val_f1_m: 0.9418 - val_single_class_accuracy: 0.4389 - val_single_class_recall: 0.6350\n",
      "\n",
      "Epoch 00073: val_single_class_accuracy improved from 0.43886 to 0.43894, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.073.h5\n",
      "Epoch 74/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 324s 5ms/step - loss: 0.4789 - recall_m: 0.9536 - precision_m: 0.9536 - f1_m: 0.9536 - single_class_accuracy: 0.5159 - single_class_recall: 0.8091 - val_loss: 0.4033 - val_recall_m: 0.9460 - val_precision_m: 0.9460 - val_f1_m: 0.9460 - val_single_class_accuracy: 0.4549 - val_single_class_recall: 0.6289\n",
      "\n",
      "Epoch 00074: val_single_class_accuracy improved from 0.43894 to 0.45488, saving model to D:\\Work\\projects\\DL for MS\\models\\Abd_Buc_ResNet11v2_model.074.h5\n",
      "Epoch 75/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 325s 5ms/step - loss: 0.4751 - recall_m: 0.9536 - precision_m: 0.9536 - f1_m: 0.9536 - single_class_accuracy: 0.5215 - single_class_recall: 0.8109 - val_loss: 0.4057 - val_recall_m: 0.9442 - val_precision_m: 0.9442 - val_f1_m: 0.9442 - val_single_class_accuracy: 0.4469 - val_single_class_recall: 0.6186\n",
      "\n",
      "Epoch 00075: val_single_class_accuracy did not improve from 0.45488\n",
      "Epoch 76/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 333s 5ms/step - loss: 0.4716 - recall_m: 0.9556 - precision_m: 0.9556 - f1_m: 0.9556 - single_class_accuracy: 0.5322 - single_class_recall: 0.8101 - val_loss: 0.4434 - val_recall_m: 0.9312 - val_precision_m: 0.9312 - val_f1_m: 0.9312 - val_single_class_accuracy: 0.4047 - val_single_class_recall: 0.6685\n",
      "\n",
      "Epoch 00076: val_single_class_accuracy did not improve from 0.45488\n",
      "Epoch 77/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 331s 5ms/step - loss: 0.4710 - recall_m: 0.9551 - precision_m: 0.9551 - f1_m: 0.9551 - single_class_accuracy: 0.5255 - single_class_recall: 0.7998 - val_loss: 0.4337 - val_recall_m: 0.9346 - val_precision_m: 0.9346 - val_f1_m: 0.9346 - val_single_class_accuracy: 0.4135 - val_single_class_recall: 0.6639\n",
      "\n",
      "Epoch 00077: val_single_class_accuracy did not improve from 0.45488\n",
      "Epoch 78/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 334s 5ms/step - loss: 0.4669 - recall_m: 0.9560 - precision_m: 0.9560 - f1_m: 0.9560 - single_class_accuracy: 0.5246 - single_class_recall: 0.8007 - val_loss: 0.4262 - val_recall_m: 0.9376 - val_precision_m: 0.9376 - val_f1_m: 0.9376 - val_single_class_accuracy: 0.4241 - val_single_class_recall: 0.6530\n",
      "\n",
      "Epoch 00078: val_single_class_accuracy did not improve from 0.45488\n",
      "Epoch 79/100\n",
      "Learning rate:  0.01\n",
      "65244/65244 [==============================] - 332s 5ms/step - loss: 0.4656 - recall_m: 0.9557 - precision_m: 0.9557 - f1_m: 0.9557 - single_class_accuracy: 0.5298 - single_class_recall: 0.7992 - val_loss: 0.4537 - val_recall_m: 0.9273 - val_precision_m: 0.9273 - val_f1_m: 0.9273 - val_single_class_accuracy: 0.3981 - val_single_class_recall: 0.6899\n",
      "\n",
      "Epoch 00079: val_single_class_accuracy did not improve from 0.45488\n",
      "Epoch 80/100\n",
      "Learning rate:  0.01\n",
      "63424/65244 [============================>.] - ETA: 8s - loss: 0.4616 - recall_m: 0.9577 - precision_m: 0.9577 - f1_m: 0.9577 - single_class_accuracy: 0.5444 - single_class_recall: 0.8089"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6e29aeb327a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m               callbacks=callbacks,class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'Abd_Buc_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_single_class_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer =  ReduceLROnPlateau( min_lr=1e-6, monitor='val_single_class_accuracy', verbose=1,factor=0.8,patience=20)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks,class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/ICC_ResNet20v2_model.001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = y_pred.argmax(axis=1)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, Reshape#, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers.noise import GaussianNoise\n",
    "#Hyperparameters for the network\n",
    "DENSE = 256\n",
    "DROPOUT = 0.5\n",
    "C1_K  = 8 #Number of kernels/feature extractors for first layer\n",
    "C1_S  = 3 #Width of the convolutional mini networks\n",
    "C2_K  = 8\n",
    "C2_S  = 3\n",
    "C3_K  = 4\n",
    "C3_S  = 3\n",
    "C4_K  = 1\n",
    "C4_S  = 3\n",
    "\n",
    "activation='relu'\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "#The model\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    #Adding a bit of GaussianNoise also works as regularization\n",
    "    model.add(GaussianNoise(0, input_shape=(input_dim,)))\n",
    "    #First two is number of filter + kernel size\n",
    "    model.add(Reshape((input_dim, 1)))\n",
    "    model.add(Conv1D(C1_K, (C1_S), activation=activation, border_mode=\"same\"))\n",
    "    model.add(Conv1D(C2_K, (C2_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Conv1D(C3_K, (C3_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Conv1D(C4_K, (C4_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(DENSE, activation=activation))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adadelta(lr=1e-3),\n",
    "                  metrics=[recall_m,precision_m,f1_m,single_class_accuracy,single_class_recall])#, metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_15 (GaussianN (None, 12001)             0         \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (None, 12001, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 12001, 8)          32        \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 12001, 8)          200       \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 12001, 4)          100       \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 12001, 1)          13        \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 12001)             0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 12001)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               3072512   \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,073,371\n",
      "Trainable params: 3,073,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(8, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(8, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(4, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(1, 3, activation=\"relu\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "#keras.backend.clear_session()\n",
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65244 samples, validate on 27962 samples\n",
      "Epoch 1/200\n",
      "65244/65244 [==============================] - 21s 321us/step - loss: 1.3127 - recall_m: 0.3555 - precision_m: 0.3555 - f1_m: 0.3555 - single_class_accuracy: 0.0541 - single_class_recall: 0.6721 - val_loss: 0.6935 - val_recall_m: 0.4027 - val_precision_m: 0.4027 - val_f1_m: 0.4027 - val_single_class_accuracy: 0.0568 - val_single_class_recall: 0.6503\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.05678, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.001.h5\n",
      "Epoch 2/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3126 - recall_m: 0.3939 - precision_m: 0.3939 - f1_m: 0.3939 - single_class_accuracy: 0.0562 - single_class_recall: 0.6621 - val_loss: 0.6934 - val_recall_m: 0.4241 - val_precision_m: 0.4241 - val_f1_m: 0.4241 - val_single_class_accuracy: 0.0583 - val_single_class_recall: 0.6430\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.05678 to 0.05828, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.002.h5\n",
      "Epoch 3/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3126 - recall_m: 0.4254 - precision_m: 0.4254 - f1_m: 0.4254 - single_class_accuracy: 0.0579 - single_class_recall: 0.6435 - val_loss: 0.6933 - val_recall_m: 0.4841 - val_precision_m: 0.4841 - val_f1_m: 0.4841 - val_single_class_accuracy: 0.0607 - val_single_class_recall: 0.5894\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy improved from 0.05828 to 0.06074, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.003.h5\n",
      "Epoch 4/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3125 - recall_m: 0.4728 - precision_m: 0.4728 - f1_m: 0.4728 - single_class_accuracy: 0.0594 - single_class_recall: 0.6030 - val_loss: 0.6931 - val_recall_m: 0.5461 - val_precision_m: 0.5461 - val_f1_m: 0.5461 - val_single_class_accuracy: 0.0631 - val_single_class_recall: 0.5313\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.06074 to 0.06311, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.004.h5\n",
      "Epoch 5/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3125 - recall_m: 0.5069 - precision_m: 0.5069 - f1_m: 0.5069 - single_class_accuracy: 0.0605 - single_class_recall: 0.5656 - val_loss: 0.6930 - val_recall_m: 0.5877 - val_precision_m: 0.5877 - val_f1_m: 0.5877 - val_single_class_accuracy: 0.0671 - val_single_class_recall: 0.5120\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy improved from 0.06311 to 0.06708, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.005.h5\n",
      "Epoch 6/200\n",
      "65244/65244 [==============================] - 20s 301us/step - loss: 1.3125 - recall_m: 0.5721 - precision_m: 0.5721 - f1_m: 0.5721 - single_class_accuracy: 0.0634 - single_class_recall: 0.5046 - val_loss: 0.6929 - val_recall_m: 0.6366 - val_precision_m: 0.6366 - val_f1_m: 0.6366 - val_single_class_accuracy: 0.0714 - val_single_class_recall: 0.4751\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy improved from 0.06708 to 0.07143, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.006.h5\n",
      "Epoch 7/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3124 - recall_m: 0.5747 - precision_m: 0.5747 - f1_m: 0.5747 - single_class_accuracy: 0.0629 - single_class_recall: 0.5071 - val_loss: 0.6928 - val_recall_m: 0.6643 - val_precision_m: 0.6643 - val_f1_m: 0.6643 - val_single_class_accuracy: 0.0740 - val_single_class_recall: 0.4532\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy improved from 0.07143 to 0.07405, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.007.h5\n",
      "Epoch 8/200\n",
      "65244/65244 [==============================] - 20s 301us/step - loss: 1.3124 - recall_m: 0.5934 - precision_m: 0.5934 - f1_m: 0.5934 - single_class_accuracy: 0.0653 - single_class_recall: 0.4945 - val_loss: 0.6927 - val_recall_m: 0.6938 - val_precision_m: 0.6938 - val_f1_m: 0.6938 - val_single_class_accuracy: 0.0777 - val_single_class_recall: 0.4296\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy improved from 0.07405 to 0.07768, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.008.h5\n",
      "Epoch 9/200\n",
      "65244/65244 [==============================] - 20s 306us/step - loss: 1.3123 - recall_m: 0.6130 - precision_m: 0.6130 - f1_m: 0.6130 - single_class_accuracy: 0.0679 - single_class_recall: 0.4893 - val_loss: 0.6926 - val_recall_m: 0.7176 - val_precision_m: 0.7176 - val_f1_m: 0.7176 - val_single_class_accuracy: 0.0811 - val_single_class_recall: 0.4095\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy improved from 0.07768 to 0.08105, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.009.h5\n",
      "Epoch 10/200\n",
      "65244/65244 [==============================] - 20s 303us/step - loss: 1.3123 - recall_m: 0.6461 - precision_m: 0.6461 - f1_m: 0.6461 - single_class_accuracy: 0.0702 - single_class_recall: 0.4617 - val_loss: 0.6924 - val_recall_m: 0.7502 - val_precision_m: 0.7502 - val_f1_m: 0.7502 - val_single_class_accuracy: 0.0852 - val_single_class_recall: 0.3718\n",
      "\n",
      "Epoch 00010: val_single_class_accuracy improved from 0.08105 to 0.08515, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.010.h5\n",
      "Epoch 11/200\n",
      "26752/65244 [===========>..................] - ETA: 9s - loss: 1.3077 - recall_m: 0.6414 - precision_m: 0.6414 - f1_m: 0.6414 - single_class_accuracy: 0.0712 - single_class_recall: 0.4787"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-869fff6dd0f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n\u001b[1;32m---> 15\u001b[1;33m          class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    183\u001b[0m                         \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[1;32m--> 185\u001b[1;33m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[0;32m    186\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rdlr = ReduceLROnPlateau( min_lr=1e-6, monitor='val_single_class_accuracy', verbose=1,factor=0.8,patience=20)\n",
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'abd_CNN_model.{epoch:03d}.h5' \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_single_class_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n",
    "         class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ce3575d7cb95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_single_class_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'true positive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_recall_m'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_recall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(model.history.history['val_single_class_accuracy'], label='true positive')\n",
    "plt.plot(model.history.history['val_recall_m'], label='val_recall')\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "# ax2 = plt.gca().twinx()\n",
    "# ax2.plot(model.history.history['lr'], color='r')\n",
    "# ax2.set_ylabel('lr',color='r')\n",
    "\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model trained on ABD dataset\n",
    "\n",
    "dependencies = {\n",
    "    'recall_m': recall_m,'precision_m':precision_m,'f1_m':f1_m,'single_class_accuracy':single_class_accuracy,\n",
    "    'single_class_recall':single_class_recall\n",
    "}\n",
    "model = keras.models.load_model('models/abd_CNN_model.001.h5',custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9529284164859002,\n",
       "  'recall': 0.33177252473378144,\n",
       "  'f1-score': 0.49218531174724106,\n",
       "  'support': 26482},\n",
       " '1': {'precision': 0.05581047913776545,\n",
       "  'recall': 0.7067567567567568,\n",
       "  'f1-score': 0.10345168628226684,\n",
       "  'support': 1480},\n",
       " 'accuracy': 0.3516200557900007,\n",
       " 'macro avg': {'precision': 0.5043694478118328,\n",
       "  'recall': 0.5192646407452691,\n",
       "  'f1-score': 0.29781849901475393,\n",
       "  'support': 27962},\n",
       " 'weighted avg': {'precision': 0.9054448835742616,\n",
       "  'recall': 0.3516200557900007,\n",
       "  'f1-score': 0.47161003938874874,\n",
       "  'support': 27962}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "classification_report(y_test.argmax(axis=1), y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOADING second dataset\n",
    "# df_abd=pd.read_pickle('Orbitrap_aplysia/buc.pkl')\n",
    "# psm_ID=list(pd.read_csv('Aplysia_ganglia/Buccal/DB search psm.csv')['Scan'])\n",
    "# y=np.zeros(df_abd.shape[0])\n",
    "\n",
    "# for i in range(0,df_abd.shape[0]):\n",
    "#     if df_abd.index[i] in psm_ID:\n",
    "#         y[i]=1\n",
    "\n",
    "# X = df_abd.drop('RT',axis=1).fillna(0).values\n",
    "# y =y.astype(int)[X.sum(axis=1)!=0]\n",
    "# X = X[X.sum(axis=1)!=0]\n",
    "# X = X/X.max(axis=1).reshape(X.shape[0],1)\n",
    "\n",
    "# del df_abd\n",
    "# X = X.reshape((X.shape[0],X.shape[1]))\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "# del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32677 samples, validate on 14005 samples\n",
      "Epoch 1/100\n",
      "32677/32677 [==============================] - 26s 804us/step - loss: 1.3185 - recall_m: 0.9561 - precision_m: 0.9561 - f1_m: 0.9561 - single_class_accuracy: 0.1658 - val_loss: 0.6697 - val_recall_m: 0.9508 - val_precision_m: 0.9508 - val_f1_m: 0.9508 - val_single_class_accuracy: 0.3039\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.30391, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.001.h5\n",
      "Epoch 2/100\n",
      "32677/32677 [==============================] - 18s 550us/step - loss: 1.3170 - recall_m: 0.9560 - precision_m: 0.9560 - f1_m: 0.9560 - single_class_accuracy: 0.2288 - val_loss: 0.6677 - val_recall_m: 0.9514 - val_precision_m: 0.9514 - val_f1_m: 0.9514 - val_single_class_accuracy: 0.3097\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.30391 to 0.30970, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.002.h5\n",
      "Epoch 3/100\n",
      "32677/32677 [==============================] - 18s 550us/step - loss: 1.3157 - recall_m: 0.9550 - precision_m: 0.9550 - f1_m: 0.9550 - single_class_accuracy: 0.2132 - val_loss: 0.6659 - val_recall_m: 0.9513 - val_precision_m: 0.9513 - val_f1_m: 0.9513 - val_single_class_accuracy: 0.3120\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy improved from 0.30970 to 0.31199, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.003.h5\n",
      "Epoch 4/100\n",
      "32677/32677 [==============================] - 18s 550us/step - loss: 1.3142 - recall_m: 0.9565 - precision_m: 0.9565 - f1_m: 0.9565 - single_class_accuracy: 0.2343 - val_loss: 0.6646 - val_recall_m: 0.9502 - val_precision_m: 0.9502 - val_f1_m: 0.9502 - val_single_class_accuracy: 0.3296\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.31199 to 0.32961, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.004.h5\n",
      "Epoch 5/100\n",
      "32677/32677 [==============================] - 18s 552us/step - loss: 1.3126 - recall_m: 0.9569 - precision_m: 0.9569 - f1_m: 0.9569 - single_class_accuracy: 0.2637 - val_loss: 0.6640 - val_recall_m: 0.9472 - val_precision_m: 0.9472 - val_f1_m: 0.9472 - val_single_class_accuracy: 0.3274\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 6/100\n",
      "32677/32677 [==============================] - 18s 552us/step - loss: 1.3109 - recall_m: 0.9532 - precision_m: 0.9532 - f1_m: 0.9532 - single_class_accuracy: 0.2700 - val_loss: 0.6632 - val_recall_m: 0.9437 - val_precision_m: 0.9437 - val_f1_m: 0.9437 - val_single_class_accuracy: 0.3203\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 7/100\n",
      "32677/32677 [==============================] - 18s 555us/step - loss: 1.3095 - recall_m: 0.9448 - precision_m: 0.9448 - f1_m: 0.9448 - single_class_accuracy: 0.2406 - val_loss: 0.6622 - val_recall_m: 0.9377 - val_precision_m: 0.9377 - val_f1_m: 0.9377 - val_single_class_accuracy: 0.2968\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 8/100\n",
      "32677/32677 [==============================] - 18s 551us/step - loss: 1.3076 - recall_m: 0.9438 - precision_m: 0.9438 - f1_m: 0.9438 - single_class_accuracy: 0.2795 - val_loss: 0.6629 - val_recall_m: 0.9117 - val_precision_m: 0.9117 - val_f1_m: 0.9117 - val_single_class_accuracy: 0.2395\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 9/100\n",
      "32677/32677 [==============================] - 18s 555us/step - loss: 1.3052 - recall_m: 0.9248 - precision_m: 0.9248 - f1_m: 0.9248 - single_class_accuracy: 0.2192 - val_loss: 0.6630 - val_recall_m: 0.8743 - val_precision_m: 0.8743 - val_f1_m: 0.8743 - val_single_class_accuracy: 0.1783\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 10/100\n",
      " 7424/32677 [=====>........................] - ETA: 12s - loss: 1.2974 - recall_m: 0.9127 - precision_m: 0.9127 - f1_m: 0.9127 - single_class_accuracy: 0.1853"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-26d83e5c8312>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n\u001b[1;32m---> 15\u001b[1;33m          class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# rdlr = ReduceLROnPlateau( min_lr=1e-4, monitor='val_single_class_accuracy', verbose=1,factor=0.8,patience=20)\n",
    "# save_dir = os.path.join(os.getcwd(), 'models')\n",
    "# model_name = 'buc_CNN_model.{epoch:03d}.h5' \n",
    "# if not os.path.isdir(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "# filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "# checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "#                              monitor='val_single_class_accuracy',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True)\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n",
    "#          class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[:,1:].reshape((data.shape[0],100,120,1))\n",
    "#x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=1)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65244, 100, 120, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, Reshape, MaxPooling2D#, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers.noise import GaussianNoise\n",
    "#Hyperparameters for the network\n",
    "\n",
    "\n",
    "input_dim = x_train.shape[1:]\n",
    "\n",
    "#The model\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    #convolutional layer with rectified linear unit activation\n",
    "    model.add(Conv2D(8, kernel_size=(16, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    #32 convolution filters used each of size 3x3\n",
    "    #again\n",
    "    model.add(Conv2D(8, (1, 3), activation='relu'))\n",
    "    model.add(Conv2D(8, (1, 3), activation='relu'))\n",
    "    #64 convolution filters used each of size 3x3\n",
    "    #choose the best features via pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #randomly turn neurons on and off to improve convergence\n",
    "    model.add(Dropout(0.25))\n",
    "    #flatten since too many dimensions, we only want a classification output\n",
    "    model.add(Flatten())\n",
    "    #fully connected to get all relevant data\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    #one more dropout for convergence' sake :) \n",
    "    model.add(Dropout(0.5))\n",
    "    #output a softmax to squash the matrix into output probabilities\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adadelta(lr=1e-3),\n",
    "                  metrics=[recall_m,precision_m,f1_m,single_class_accuracy,single_class_recall])#, metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_67 (Conv2D)           (None, 85, 118, 8)        392       \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 85, 116, 8)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 85, 114, 8)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 42, 57, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 42, 57, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 19152)             0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               9806336   \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 9,808,154\n",
      "Trainable params: 9,808,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65244 samples, validate on 27962 samples\n",
      "Epoch 1/200\n",
      "65244/65244 [==============================] - 21s 327us/step - loss: 1.3129 - recall_m: 0.4690 - precision_m: 0.4690 - f1_m: 0.4690 - single_class_accuracy: 0.0540 - single_class_recall: 0.5389 - val_loss: 0.6936 - val_recall_m: 0.4779 - val_precision_m: 0.4779 - val_f1_m: 0.4779 - val_single_class_accuracy: 0.0620 - val_single_class_recall: 0.6181\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.06198, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.001.h5\n",
      "Epoch 2/200\n",
      "65244/65244 [==============================] - 19s 295us/step - loss: 1.3121 - recall_m: 0.5247 - precision_m: 0.5247 - f1_m: 0.5247 - single_class_accuracy: 0.0613 - single_class_recall: 0.5570 - val_loss: 0.6929 - val_recall_m: 0.5737 - val_precision_m: 0.5737 - val_f1_m: 0.5737 - val_single_class_accuracy: 0.0733 - val_single_class_recall: 0.5966\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.06198 to 0.07331, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.002.h5\n",
      "Epoch 3/200\n",
      "65244/65244 [==============================] - 19s 295us/step - loss: 1.3118 - recall_m: 0.5760 - precision_m: 0.5760 - f1_m: 0.5760 - single_class_accuracy: 0.0666 - single_class_recall: 0.5296 - val_loss: 0.6922 - val_recall_m: 0.6505 - val_precision_m: 0.6505 - val_f1_m: 0.6505 - val_single_class_accuracy: 0.0858 - val_single_class_recall: 0.5722\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy improved from 0.07331 to 0.08582, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.003.h5\n",
      "Epoch 4/200\n",
      "65244/65244 [==============================] - 19s 298us/step - loss: 1.3113 - recall_m: 0.6079 - precision_m: 0.6079 - f1_m: 0.6079 - single_class_accuracy: 0.0705 - single_class_recall: 0.5286 - val_loss: 0.6916 - val_recall_m: 0.6939 - val_precision_m: 0.6939 - val_f1_m: 0.6939 - val_single_class_accuracy: 0.0947 - val_single_class_recall: 0.5539\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.08582 to 0.09472, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.004.h5\n",
      "Epoch 5/200\n",
      "65244/65244 [==============================] - 19s 292us/step - loss: 1.3107 - recall_m: 0.6432 - precision_m: 0.6432 - f1_m: 0.6432 - single_class_accuracy: 0.0781 - single_class_recall: 0.5250 - val_loss: 0.6909 - val_recall_m: 0.7262 - val_precision_m: 0.7262 - val_f1_m: 0.7262 - val_single_class_accuracy: 0.1022 - val_single_class_recall: 0.5366\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy improved from 0.09472 to 0.10225, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.005.h5\n",
      "Epoch 6/200\n",
      "65244/65244 [==============================] - 19s 293us/step - loss: 1.3101 - recall_m: 0.6718 - precision_m: 0.6718 - f1_m: 0.6718 - single_class_accuracy: 0.0826 - single_class_recall: 0.5093 - val_loss: 0.6902 - val_recall_m: 0.7483 - val_precision_m: 0.7483 - val_f1_m: 0.7483 - val_single_class_accuracy: 0.1088 - val_single_class_recall: 0.5220\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy improved from 0.10225 to 0.10884, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.006.h5\n",
      "Epoch 7/200\n",
      "65244/65244 [==============================] - 19s 296us/step - loss: 1.3094 - recall_m: 0.6985 - precision_m: 0.6985 - f1_m: 0.6985 - single_class_accuracy: 0.0882 - single_class_recall: 0.5027 - val_loss: 0.6895 - val_recall_m: 0.7645 - val_precision_m: 0.7645 - val_f1_m: 0.7645 - val_single_class_accuracy: 0.1151 - val_single_class_recall: 0.5152\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy improved from 0.10884 to 0.11506, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.007.h5\n",
      "Epoch 8/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3091 - recall_m: 0.7182 - precision_m: 0.7182 - f1_m: 0.7182 - single_class_accuracy: 0.0938 - single_class_recall: 0.4930 - val_loss: 0.6888 - val_recall_m: 0.7763 - val_precision_m: 0.7763 - val_f1_m: 0.7763 - val_single_class_accuracy: 0.1191 - val_single_class_recall: 0.5052\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy improved from 0.11506 to 0.11915, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.008.h5\n",
      "Epoch 9/200\n",
      "65244/65244 [==============================] - 20s 299us/step - loss: 1.3083 - recall_m: 0.7400 - precision_m: 0.7400 - f1_m: 0.7400 - single_class_accuracy: 0.0999 - single_class_recall: 0.4887 - val_loss: 0.6880 - val_recall_m: 0.7843 - val_precision_m: 0.7843 - val_f1_m: 0.7843 - val_single_class_accuracy: 0.1223 - val_single_class_recall: 0.4985\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy improved from 0.11915 to 0.12230, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.009.h5\n",
      "Epoch 10/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3077 - recall_m: 0.7473 - precision_m: 0.7473 - f1_m: 0.7473 - single_class_accuracy: 0.1035 - single_class_recall: 0.4862 - val_loss: 0.6872 - val_recall_m: 0.7873 - val_precision_m: 0.7873 - val_f1_m: 0.7873 - val_single_class_accuracy: 0.1234 - val_single_class_recall: 0.4949\n",
      "\n",
      "Epoch 00010: val_single_class_accuracy improved from 0.12230 to 0.12341, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.010.h5\n",
      "Epoch 11/200\n",
      "65244/65244 [==============================] - 19s 295us/step - loss: 1.3071 - recall_m: 0.7571 - precision_m: 0.7571 - f1_m: 0.7571 - single_class_accuracy: 0.1058 - single_class_recall: 0.4734 - val_loss: 0.6865 - val_recall_m: 0.7901 - val_precision_m: 0.7901 - val_f1_m: 0.7901 - val_single_class_accuracy: 0.1247 - val_single_class_recall: 0.4931\n",
      "\n",
      "Epoch 00011: val_single_class_accuracy improved from 0.12341 to 0.12465, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.011.h5\n",
      "Epoch 12/200\n",
      "65244/65244 [==============================] - 19s 296us/step - loss: 1.3061 - recall_m: 0.7704 - precision_m: 0.7704 - f1_m: 0.7704 - single_class_accuracy: 0.1119 - single_class_recall: 0.4792 - val_loss: 0.6857 - val_recall_m: 0.7919 - val_precision_m: 0.7919 - val_f1_m: 0.7919 - val_single_class_accuracy: 0.1242 - val_single_class_recall: 0.4878\n",
      "\n",
      "Epoch 00012: val_single_class_accuracy did not improve from 0.12465\n",
      "Epoch 13/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3054 - recall_m: 0.7695 - precision_m: 0.7695 - f1_m: 0.7695 - single_class_accuracy: 0.1123 - single_class_recall: 0.4846 - val_loss: 0.6849 - val_recall_m: 0.7913 - val_precision_m: 0.7913 - val_f1_m: 0.7913 - val_single_class_accuracy: 0.1239 - val_single_class_recall: 0.4857\n",
      "\n",
      "Epoch 00013: val_single_class_accuracy did not improve from 0.12465\n",
      "Epoch 14/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3043 - recall_m: 0.7704 - precision_m: 0.7704 - f1_m: 0.7704 - single_class_accuracy: 0.1148 - single_class_recall: 0.4969 - val_loss: 0.6842 - val_recall_m: 0.7894 - val_precision_m: 0.7894 - val_f1_m: 0.7894 - val_single_class_accuracy: 0.1233 - val_single_class_recall: 0.4904\n",
      "\n",
      "Epoch 00014: val_single_class_accuracy did not improve from 0.12465\n",
      "Epoch 15/200\n",
      "39040/65244 [================>.............] - ETA: 6s - loss: 1.3068 - recall_m: 0.7694 - precision_m: 0.7694 - f1_m: 0.7694 - single_class_accuracy: 0.1154 - single_class_recall: 0.5006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-7f6c1b51bedd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n\u001b[1;32m---> 15\u001b[1;33m          class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rdlr = ReduceLROnPlateau( min_lr=1e-6, monitor='val_single_class_accuracy', verbose=1,factor=0.5,patience=20)\n",
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'abd_buc_CNN2D_model.{epoch:03d}.h5' \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_single_class_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n",
    "         class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
