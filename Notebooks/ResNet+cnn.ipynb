{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cuda_path = 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0\\\\bin'\n",
    "cudnn_path = 'D:\\\\Work\\\\software\\\\cuda\\\\bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + cuda_path\n",
    "os.environ[\"PATH\"] += os.pathsep + cudnn_path\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import analysis\n",
    "import sys\n",
    "sys.path.insert(0,'../scripts/')\n",
    "\n",
    "import test_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots,scatter\n",
    "import seaborn as sns\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "#import analysis\n",
    "def read_data(file_dir,DB_file_dir):\n",
    "    \n",
    "    data = []\n",
    "    label = []\n",
    "    \n",
    "    print('loading..{}'.format(file_dir))\n",
    "    df=pd.read_pickle(file_dir)\n",
    "    psm_ID=list(pd.read_csv(DB_file_dir)['Scan'])\n",
    "    y=np.zeros(df.shape[0])\n",
    "\n",
    "    for i in range(0,df.shape[0]):\n",
    "        if df.index[i] in psm_ID:\n",
    "            y[i]=1\n",
    "\n",
    "    X = df.drop('RT',axis=1).fillna(0).values\n",
    "    y =y.astype(int)[X.sum(axis=1)!=0]\n",
    "    X = X[X.sum(axis=1)!=0]\n",
    "    X = X/X.sum(axis=1).reshape(X.shape[0],1) #normalization\n",
    "    data.append(X)\n",
    "    label.append(y)\n",
    "    del X\n",
    "\n",
    "    data = np.concatenate((data))\n",
    "    label = np.concatenate((label))\n",
    "    return data,label\n",
    "\n",
    "from numpy.random import randint,seed,choice\n",
    "def under_sampler(data,label,n_sample):\n",
    "    \n",
    "    index_maj = np.where(label==0)[0]\n",
    "    index_min = np.where(label==1)[0]\n",
    "    \n",
    "    seed(19)\n",
    "    sample_index = choice(len(index_maj),size=n_sample,replace=False)\n",
    "    index_maj_sampled = index_maj[sample_index]\n",
    "    data_sampled = data[np.concatenate((index_maj_sampled,index_min))]\n",
    "    label_sampled = label[np.concatenate((index_maj_sampled,index_min))]\n",
    "    \n",
    "    shuffle_index = choice(len(data_sampled),size=len(data_sampled),replace=False)\n",
    "    data_sampled = data_sampled[shuffle_index]\n",
    "    label_sampled = label_sampled[shuffle_index]\n",
    "    \n",
    "    return data_sampled,label_sampled\n",
    "\n",
    "def load_sample_data(file_dir,DB_file_dir,n_sample):\n",
    "    \n",
    "    X_train,X_test,Y_train,Y_test = [],[],[],[]\n",
    "    for i in range(len(file_dir)):\n",
    "        data,label = read_data(file_dir[i],DB_file_dir[i])\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=1)\n",
    "        del data\n",
    "        \n",
    "        x_train_sampled,y_train_sampled = under_sampler(x_train,y_train,len(y_train[y_train==1])*n_sample)\n",
    "        del x_train,y_train\n",
    "        X_train.append(x_train_sampled)\n",
    "        X_test.append(x_test)\n",
    "        Y_train.append(y_train_sampled)\n",
    "        Y_test.append(y_test)\n",
    "        del x_test,y_test,x_train_sampled,y_train_sampled\n",
    "        \n",
    "    X_train = np.concatenate(X_train)\n",
    "    X_test = np.concatenate(X_test)\n",
    "    Y_train = np.concatenate(Y_train)\n",
    "    Y_test = np.concatenate(Y_test)\n",
    "\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading..../Orbitrap_aplysia/abd.pkl\n",
      "loading..../Orbitrap_aplysia/buc.pkl\n",
      "loading..../Orbitrap_aplysia/cer.pkl\n"
     ]
    }
   ],
   "source": [
    "# file_dir = ['../Orbitrap_aplysia/abd.pkl','../Orbitrap_aplysia/buc.pkl','../Orbitrap_aplysia/cer.pkl']\n",
    "# DB_file_dir = ['../Aplysia_ganglia/Abdominal/DB search psm.csv','../Aplysia_ganglia/Buccal/DB search psm.csv',\n",
    "#               '../Aplysia_ganglia/Cerebral/DB search psm.csv']\n",
    "\n",
    "# X_train,X_test,Y_train,Y_test = load_sample_data(file_dir,DB_file_dir,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../Orbitrap_aplysia/train_data_combined_sampled_x2.npy')\n",
    "Y_train = np.load('../Orbitrap_aplysia/train_label_combined_sampled_x2.npy')\n",
    "X_test = np.load('../Orbitrap_aplysia/cer_test_data.npy')\n",
    "Y_test = np.load('../Orbitrap_aplysia/cer_test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint,seed,choice\n",
    "seed(19)\n",
    "shuffle_index = choice(len(X_train),size=len(X_train),replace=False)\n",
    "X_train = X_train[shuffle_index]\n",
    "Y_train =Y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((X_train.shape[0],X_train.shape[1]))\n",
    "X_test=X_test.reshape((X_test.shape[0],X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Conv1D, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling1D, AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# import tensorflow as tf\n",
    "# K.clear_session()\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "# sess = tf.Session(config=config)\n",
    "# set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "num_classes = 2\n",
    "input_shape = X_train.shape[1:]\n",
    "scale_weight = Y_train[Y_train==0].shape[0]/Y_train[Y_train==1].shape[0]\n",
    "\n",
    "n = 1\n",
    "version = 2\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Input image dimensions.\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train_aug = keras.utils.to_categorical(y_train_aug, num_classes)\n",
    "Y_train_ = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test_ = keras.utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-2\n",
    "    if epoch > 100:\n",
    "        lr *= 0.5e-6\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-6\n",
    "    elif epoch > 60:\n",
    "        lr *= 1e-5\n",
    "    elif epoch > 40:\n",
    "        lr *= 1e-4\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=8,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv1D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=2):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv1D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling1D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0117 00:07:06.220641  9492 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0117 00:07:06.221638  9492 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0117 00:07:06.257993  9492 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0117 00:07:06.367401  9492 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0117 00:07:06.968178  9492 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0117 00:07:06.986157  9492 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0117 00:07:06.991120  9492 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12001, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 12001, 16)    64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 12001, 16)    64          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 12001, 16)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 12001, 16)    272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 12001, 16)    64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 12001, 16)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 12001, 16)    784         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 12001, 16)    64          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 12001, 16)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 12001, 64)    1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 12001, 64)    1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 12001, 64)    0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12001, 64)    256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12001, 64)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 6001, 64)     4160        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6001, 64)     256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 6001, 64)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 6001, 64)     12352       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6001, 64)     256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 6001, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 6001, 128)    8320        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 6001, 128)    8320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 6001, 128)    0           conv1d_9[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6001, 128)    512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6001, 128)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 3001, 128)    16512       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 3001, 128)    512         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 3001, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 3001, 128)    49280       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 3001, 128)    512         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 3001, 128)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 3001, 256)    33024       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 3001, 256)    33024       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 3001, 256)    0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 3001, 256)    1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 3001, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 375, 256)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 96000)        0           average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            192002      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 363,810\n",
      "Trainable params: 362,050\n",
      "Non-trainable params: 1,760\n",
      "__________________________________________________________________________________________________\n",
      "ResNet11v2\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "INTERESTING_CLASS_ID =  1 # Choose the class of interest\n",
    "\n",
    "def single_class_accuracy(y_true, y_pred):\n",
    "    class_id_true = K.argmax(y_true, axis=-1)\n",
    "    class_id_preds = K.argmax(y_pred, axis=-1)\n",
    "    accuracy_mask = K.cast(K.equal(class_id_preds, INTERESTING_CLASS_ID), 'int32')\n",
    "    #recall_mask = K.cast(K.equal(class_id_true, INTERESTING_CLASS_ID), 'int32')\n",
    "\n",
    "    class_acc_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * accuracy_mask\n",
    "    #class_recall_tensor = K.cast(K.equal(class_id_true, class_id_true), 'int32') * recall_mask\n",
    "    class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n",
    "    #class_recall = K.sum(class_recall_tensor) / K.maximum(K.sum(recall_mask), 1)\n",
    "    return class_acc\n",
    "\n",
    "def single_class_recall(y_true, y_pred):\n",
    "    class_id_true = K.argmax(y_true, axis=-1)\n",
    "    class_id_preds = K.argmax(y_pred, axis=-1)\n",
    "    #accuracy_mask = K.cast(K.equal(class_id_preds, INTERESTING_CLASS_ID), 'int32')\n",
    "    recall_mask = K.cast(K.equal(class_id_true, INTERESTING_CLASS_ID), 'int32')\n",
    "\n",
    "    #class_acc_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * accuracy_mask\n",
    "    class_recall_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * recall_mask\n",
    "    #class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n",
    "    class_recall = K.sum(class_recall_tensor) / K.maximum(K.sum(recall_mask), 1)\n",
    "    return class_recall\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adadelta(lr=1e-3),\n",
    "                  metrics=[recall_m,precision_m,f1_m,single_class_accuracy,single_class_recall])\n",
    "model.summary()\n",
    "print(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0117 00:07:08.433354  9492 deprecation.py:323] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28548 samples, validate on 13627 samples\n",
      "Epoch 1/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 152s 5ms/step - loss: 0.9131 - recall_m: 0.7608 - precision_m: 0.7608 - f1_m: 0.7608 - single_class_accuracy: 0.6190 - single_class_recall: 0.7954 - val_loss: 0.7701 - val_recall_m: 0.7982 - val_precision_m: 0.7982 - val_f1_m: 0.7982 - val_single_class_accuracy: 0.2813 - val_single_class_recall: 0.8029\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.28133, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Combined_Sampled_ResNet11v2_model.001.h5\n",
      "Epoch 2/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 144s 5ms/step - loss: 0.7824 - recall_m: 0.8305 - precision_m: 0.8305 - f1_m: 0.8305 - single_class_accuracy: 0.7053 - single_class_recall: 0.8516 - val_loss: 0.6591 - val_recall_m: 0.8320 - val_precision_m: 0.8320 - val_f1_m: 0.8320 - val_single_class_accuracy: 0.3161 - val_single_class_recall: 0.7684\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.28133 to 0.31611, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Combined_Sampled_ResNet11v2_model.002.h5\n",
      "Epoch 3/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.7509 - recall_m: 0.8421 - precision_m: 0.8421 - f1_m: 0.8421 - single_class_accuracy: 0.7163 - single_class_recall: 0.8654 - val_loss: 0.6809 - val_recall_m: 0.8245 - val_precision_m: 0.8245 - val_f1_m: 0.8245 - val_single_class_accuracy: 0.3121 - val_single_class_recall: 0.8016\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy did not improve from 0.31611\n",
      "Epoch 4/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.7301 - recall_m: 0.8506 - precision_m: 0.8506 - f1_m: 0.8506 - single_class_accuracy: 0.7313 - single_class_recall: 0.8731 - val_loss: 0.6047 - val_recall_m: 0.8554 - val_precision_m: 0.8554 - val_f1_m: 0.8554 - val_single_class_accuracy: 0.3511 - val_single_class_recall: 0.7469\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.31611 to 0.35107, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Combined_Sampled_ResNet11v2_model.004.h5\n",
      "Epoch 5/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.7157 - recall_m: 0.8586 - precision_m: 0.8586 - f1_m: 0.8586 - single_class_accuracy: 0.7439 - single_class_recall: 0.8822 - val_loss: 0.6958 - val_recall_m: 0.8213 - val_precision_m: 0.8213 - val_f1_m: 0.8213 - val_single_class_accuracy: 0.3123 - val_single_class_recall: 0.8312\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy did not improve from 0.35107\n",
      "Epoch 6/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.7034 - recall_m: 0.8615 - precision_m: 0.8615 - f1_m: 0.8615 - single_class_accuracy: 0.7491 - single_class_recall: 0.8837 - val_loss: 0.7516 - val_recall_m: 0.7967 - val_precision_m: 0.7967 - val_f1_m: 0.7967 - val_single_class_accuracy: 0.2891 - val_single_class_recall: 0.8637\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy did not improve from 0.35107\n",
      "Epoch 7/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6921 - recall_m: 0.8671 - precision_m: 0.8671 - f1_m: 0.8671 - single_class_accuracy: 0.7571 - single_class_recall: 0.8882 - val_loss: 0.7961 - val_recall_m: 0.7708 - val_precision_m: 0.7708 - val_f1_m: 0.7708 - val_single_class_accuracy: 0.2664 - val_single_class_recall: 0.8780\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy did not improve from 0.35107\n",
      "Epoch 8/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 142s 5ms/step - loss: 0.6840 - recall_m: 0.8696 - precision_m: 0.8696 - f1_m: 0.8696 - single_class_accuracy: 0.7599 - single_class_recall: 0.8890 - val_loss: 0.6853 - val_recall_m: 0.8322 - val_precision_m: 0.8322 - val_f1_m: 0.8322 - val_single_class_accuracy: 0.3292 - val_single_class_recall: 0.8410\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy did not improve from 0.35107\n",
      "Epoch 9/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.6763 - recall_m: 0.8728 - precision_m: 0.8728 - f1_m: 0.8728 - single_class_accuracy: 0.7647 - single_class_recall: 0.8910 - val_loss: 0.7227 - val_recall_m: 0.8114 - val_precision_m: 0.8114 - val_f1_m: 0.8114 - val_single_class_accuracy: 0.3055 - val_single_class_recall: 0.8644\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy did not improve from 0.35107\n",
      "Epoch 10/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6683 - recall_m: 0.8757 - precision_m: 0.8757 - f1_m: 0.8757 - single_class_accuracy: 0.7713 - single_class_recall: 0.8948 - val_loss: 1.1054 - val_recall_m: 0.5985 - val_precision_m: 0.5985 - val_f1_m: 0.5985 - val_single_class_accuracy: 0.1745 - val_single_class_recall: 0.9251\n",
      "\n",
      "Epoch 00010: val_single_class_accuracy did not improve from 0.35107\n",
      "Epoch 11/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6598 - recall_m: 0.8792 - precision_m: 0.8792 - f1_m: 0.8792 - single_class_accuracy: 0.7768 - single_class_recall: 0.8961 - val_loss: 0.7590 - val_recall_m: 0.7828 - val_precision_m: 0.7828 - val_f1_m: 0.7828 - val_single_class_accuracy: 0.2783 - val_single_class_recall: 0.8840\n",
      "\n",
      "Epoch 00011: val_single_class_accuracy did not improve from 0.35107\n",
      "Epoch 12/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6517 - recall_m: 0.8832 - precision_m: 0.8832 - f1_m: 0.8832 - single_class_accuracy: 0.7814 - single_class_recall: 0.8998 - val_loss: 0.5815 - val_recall_m: 0.8700 - val_precision_m: 0.8700 - val_f1_m: 0.8700 - val_single_class_accuracy: 0.3875 - val_single_class_recall: 0.8055\n",
      "\n",
      "Epoch 00012: val_single_class_accuracy improved from 0.35107 to 0.38746, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Combined_Sampled_ResNet11v2_model.012.h5\n",
      "Epoch 13/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6458 - recall_m: 0.8845 - precision_m: 0.8845 - f1_m: 0.8845 - single_class_accuracy: 0.7850 - single_class_recall: 0.9020 - val_loss: 0.5964 - val_recall_m: 0.8705 - val_precision_m: 0.8705 - val_f1_m: 0.8705 - val_single_class_accuracy: 0.3860 - val_single_class_recall: 0.8062\n",
      "\n",
      "Epoch 00013: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 14/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.6399 - recall_m: 0.8866 - precision_m: 0.8866 - f1_m: 0.8866 - single_class_accuracy: 0.7890 - single_class_recall: 0.9026 - val_loss: 1.3795 - val_recall_m: 0.5008 - val_precision_m: 0.5008 - val_f1_m: 0.5008 - val_single_class_accuracy: 0.1456 - val_single_class_recall: 0.9321\n",
      "\n",
      "Epoch 00014: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 15/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.6343 - recall_m: 0.8891 - precision_m: 0.8891 - f1_m: 0.8891 - single_class_accuracy: 0.7946 - single_class_recall: 0.9048 - val_loss: 0.6611 - val_recall_m: 0.8383 - val_precision_m: 0.8383 - val_f1_m: 0.8383 - val_single_class_accuracy: 0.3387 - val_single_class_recall: 0.8530\n",
      "\n",
      "Epoch 00015: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 16/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6267 - recall_m: 0.8921 - precision_m: 0.8921 - f1_m: 0.8921 - single_class_accuracy: 0.7983 - single_class_recall: 0.9072 - val_loss: 0.6146 - val_recall_m: 0.8592 - val_precision_m: 0.8592 - val_f1_m: 0.8592 - val_single_class_accuracy: 0.3676 - val_single_class_recall: 0.8280\n",
      "\n",
      "Epoch 00016: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 17/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6214 - recall_m: 0.8930 - precision_m: 0.8930 - f1_m: 0.8930 - single_class_accuracy: 0.7991 - single_class_recall: 0.9071 - val_loss: 0.6360 - val_recall_m: 0.8521 - val_precision_m: 0.8521 - val_f1_m: 0.8521 - val_single_class_accuracy: 0.3580 - val_single_class_recall: 0.8452\n",
      "\n",
      "Epoch 00017: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 18/100\n",
      "Learning rate:  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6159 - recall_m: 0.8943 - precision_m: 0.8943 - f1_m: 0.8943 - single_class_accuracy: 0.8027 - single_class_recall: 0.9085 - val_loss: 0.7976 - val_recall_m: 0.7815 - val_precision_m: 0.7815 - val_f1_m: 0.7815 - val_single_class_accuracy: 0.2779 - val_single_class_recall: 0.8924\n",
      "\n",
      "Epoch 00018: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 19/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6101 - recall_m: 0.8979 - precision_m: 0.8979 - f1_m: 0.8979 - single_class_accuracy: 0.8083 - single_class_recall: 0.9119 - val_loss: 2.3561 - val_recall_m: 0.3247 - val_precision_m: 0.3247 - val_f1_m: 0.3247 - val_single_class_accuracy: 0.1117 - val_single_class_recall: 0.9370\n",
      "\n",
      "Epoch 00019: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 20/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.6046 - recall_m: 0.8984 - precision_m: 0.8984 - f1_m: 0.8984 - single_class_accuracy: 0.8076 - single_class_recall: 0.9141 - val_loss: 0.7324 - val_recall_m: 0.8204 - val_precision_m: 0.8204 - val_f1_m: 0.8204 - val_single_class_accuracy: 0.3166 - val_single_class_recall: 0.8694\n",
      "\n",
      "Epoch 00020: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 21/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.6000 - recall_m: 0.8996 - precision_m: 0.8996 - f1_m: 0.8996 - single_class_accuracy: 0.8101 - single_class_recall: 0.9137 - val_loss: 0.6121 - val_recall_m: 0.8574 - val_precision_m: 0.8574 - val_f1_m: 0.8574 - val_single_class_accuracy: 0.3671 - val_single_class_recall: 0.8452\n",
      "\n",
      "Epoch 00021: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 22/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5949 - recall_m: 0.9007 - precision_m: 0.9007 - f1_m: 0.9007 - single_class_accuracy: 0.8108 - single_class_recall: 0.9134 - val_loss: 0.6348 - val_recall_m: 0.8554 - val_precision_m: 0.8554 - val_f1_m: 0.8554 - val_single_class_accuracy: 0.3604 - val_single_class_recall: 0.8415\n",
      "\n",
      "Epoch 00022: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 23/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5914 - recall_m: 0.9015 - precision_m: 0.9015 - f1_m: 0.9015 - single_class_accuracy: 0.8135 - single_class_recall: 0.9168 - val_loss: 4.2648 - val_recall_m: 0.1620 - val_precision_m: 0.1620 - val_f1_m: 0.1620 - val_single_class_accuracy: 0.0921 - val_single_class_recall: 0.9393\n",
      "\n",
      "Epoch 00023: val_single_class_accuracy did not improve from 0.38746\n",
      "Epoch 24/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5861 - recall_m: 0.9049 - precision_m: 0.9049 - f1_m: 0.9049 - single_class_accuracy: 0.8194 - single_class_recall: 0.9194 - val_loss: 0.5641 - val_recall_m: 0.8798 - val_precision_m: 0.8798 - val_f1_m: 0.8798 - val_single_class_accuracy: 0.4038 - val_single_class_recall: 0.8114\n",
      "\n",
      "Epoch 00024: val_single_class_accuracy improved from 0.38746 to 0.40375, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Combined_Sampled_ResNet11v2_model.024.h5\n",
      "Epoch 25/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5819 - recall_m: 0.9053 - precision_m: 0.9053 - f1_m: 0.9053 - single_class_accuracy: 0.8188 - single_class_recall: 0.9182 - val_loss: 0.7750 - val_recall_m: 0.8037 - val_precision_m: 0.8037 - val_f1_m: 0.8037 - val_single_class_accuracy: 0.2991 - val_single_class_recall: 0.8844\n",
      "\n",
      "Epoch 00025: val_single_class_accuracy did not improve from 0.40375\n",
      "Epoch 26/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5782 - recall_m: 0.9047 - precision_m: 0.9047 - f1_m: 0.9047 - single_class_accuracy: 0.8174 - single_class_recall: 0.9195 - val_loss: 0.5561 - val_recall_m: 0.8788 - val_precision_m: 0.8788 - val_f1_m: 0.8788 - val_single_class_accuracy: 0.4047 - val_single_class_recall: 0.8204\n",
      "\n",
      "Epoch 00026: val_single_class_accuracy improved from 0.40375 to 0.40469, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Combined_Sampled_ResNet11v2_model.026.h5\n",
      "Epoch 27/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.5751 - recall_m: 0.9066 - precision_m: 0.9066 - f1_m: 0.9066 - single_class_accuracy: 0.8239 - single_class_recall: 0.9212 - val_loss: 1.0012 - val_recall_m: 0.7061 - val_precision_m: 0.7061 - val_f1_m: 0.7061 - val_single_class_accuracy: 0.2238 - val_single_class_recall: 0.9156\n",
      "\n",
      "Epoch 00027: val_single_class_accuracy did not improve from 0.40469\n",
      "Epoch 28/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5705 - recall_m: 0.9085 - precision_m: 0.9085 - f1_m: 0.9085 - single_class_accuracy: 0.8242 - single_class_recall: 0.9210 - val_loss: 0.6468 - val_recall_m: 0.8473 - val_precision_m: 0.8473 - val_f1_m: 0.8473 - val_single_class_accuracy: 0.3504 - val_single_class_recall: 0.8597\n",
      "\n",
      "Epoch 00028: val_single_class_accuracy did not improve from 0.40469\n",
      "Epoch 29/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5655 - recall_m: 0.9105 - precision_m: 0.9105 - f1_m: 0.9105 - single_class_accuracy: 0.8273 - single_class_recall: 0.9265 - val_loss: 0.5552 - val_recall_m: 0.8817 - val_precision_m: 0.8817 - val_f1_m: 0.8817 - val_single_class_accuracy: 0.4100 - val_single_class_recall: 0.8151\n",
      "\n",
      "Epoch 00029: val_single_class_accuracy improved from 0.40469 to 0.41000, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Combined_Sampled_ResNet11v2_model.029.h5\n",
      "Epoch 30/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5622 - recall_m: 0.9104 - precision_m: 0.9104 - f1_m: 0.9104 - single_class_accuracy: 0.8262 - single_class_recall: 0.9255 - val_loss: 0.6711 - val_recall_m: 0.8380 - val_precision_m: 0.8380 - val_f1_m: 0.8380 - val_single_class_accuracy: 0.3389 - val_single_class_recall: 0.8667\n",
      "\n",
      "Epoch 00030: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 31/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5578 - recall_m: 0.9128 - precision_m: 0.9128 - f1_m: 0.9128 - single_class_accuracy: 0.8306 - single_class_recall: 0.9272 - val_loss: 1.4200 - val_recall_m: 0.5345 - val_precision_m: 0.5345 - val_f1_m: 0.5345 - val_single_class_accuracy: 0.1551 - val_single_class_recall: 0.9330\n",
      "\n",
      "Epoch 00031: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 32/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5538 - recall_m: 0.9130 - precision_m: 0.9130 - f1_m: 0.9130 - single_class_accuracy: 0.8307 - single_class_recall: 0.9298 - val_loss: 0.6653 - val_recall_m: 0.8391 - val_precision_m: 0.8391 - val_f1_m: 0.8391 - val_single_class_accuracy: 0.3392 - val_single_class_recall: 0.8702\n",
      "\n",
      "Epoch 00032: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 33/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5511 - recall_m: 0.9137 - precision_m: 0.9137 - f1_m: 0.9137 - single_class_accuracy: 0.8345 - single_class_recall: 0.9271 - val_loss: 0.6636 - val_recall_m: 0.8394 - val_precision_m: 0.8394 - val_f1_m: 0.8394 - val_single_class_accuracy: 0.3400 - val_single_class_recall: 0.8652\n",
      "\n",
      "Epoch 00033: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 34/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.5475 - recall_m: 0.9155 - precision_m: 0.9155 - f1_m: 0.9155 - single_class_accuracy: 0.8338 - single_class_recall: 0.9302 - val_loss: 0.7148 - val_recall_m: 0.8198 - val_precision_m: 0.8198 - val_f1_m: 0.8198 - val_single_class_accuracy: 0.3158 - val_single_class_recall: 0.8775\n",
      "\n",
      "Epoch 00034: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 35/100\n",
      "Learning rate:  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5476 - recall_m: 0.9143 - precision_m: 0.9143 - f1_m: 0.9143 - single_class_accuracy: 0.8354 - single_class_recall: 0.9286 - val_loss: 0.6262 - val_recall_m: 0.8612 - val_precision_m: 0.8612 - val_f1_m: 0.8612 - val_single_class_accuracy: 0.3684 - val_single_class_recall: 0.8534\n",
      "\n",
      "Epoch 00035: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 36/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5419 - recall_m: 0.9165 - precision_m: 0.9165 - f1_m: 0.9165 - single_class_accuracy: 0.8375 - single_class_recall: 0.9301 - val_loss: 0.7150 - val_recall_m: 0.8223 - val_precision_m: 0.8223 - val_f1_m: 0.8223 - val_single_class_accuracy: 0.3187 - val_single_class_recall: 0.8792\n",
      "\n",
      "Epoch 00036: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 37/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5389 - recall_m: 0.9171 - precision_m: 0.9171 - f1_m: 0.9171 - single_class_accuracy: 0.8381 - single_class_recall: 0.9322 - val_loss: 0.5607 - val_recall_m: 0.8808 - val_precision_m: 0.8808 - val_f1_m: 0.8808 - val_single_class_accuracy: 0.4055 - val_single_class_recall: 0.8210\n",
      "\n",
      "Epoch 00037: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 38/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5341 - recall_m: 0.9191 - precision_m: 0.9191 - f1_m: 0.9191 - single_class_accuracy: 0.8411 - single_class_recall: 0.9352 - val_loss: 0.6233 - val_recall_m: 0.8582 - val_precision_m: 0.8582 - val_f1_m: 0.8582 - val_single_class_accuracy: 0.3664 - val_single_class_recall: 0.8536\n",
      "\n",
      "Epoch 00038: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 39/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5318 - recall_m: 0.9192 - precision_m: 0.9192 - f1_m: 0.9192 - single_class_accuracy: 0.8416 - single_class_recall: 0.9347 - val_loss: 0.6569 - val_recall_m: 0.8507 - val_precision_m: 0.8507 - val_f1_m: 0.8507 - val_single_class_accuracy: 0.3563 - val_single_class_recall: 0.8615\n",
      "\n",
      "Epoch 00039: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 40/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.5315 - recall_m: 0.9199 - precision_m: 0.9199 - f1_m: 0.9199 - single_class_accuracy: 0.8425 - single_class_recall: 0.9339 - val_loss: 0.8781 - val_recall_m: 0.7593 - val_precision_m: 0.7593 - val_f1_m: 0.7593 - val_single_class_accuracy: 0.2598 - val_single_class_recall: 0.9061\n",
      "\n",
      "Epoch 00040: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 41/100\n",
      "Learning rate:  0.01\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5250 - recall_m: 0.9211 - precision_m: 0.9211 - f1_m: 0.9211 - single_class_accuracy: 0.8443 - single_class_recall: 0.9368 - val_loss: 3.5267 - val_recall_m: 0.1964 - val_precision_m: 0.1964 - val_f1_m: 0.1964 - val_single_class_accuracy: 0.0956 - val_single_class_recall: 0.9370\n",
      "\n",
      "Epoch 00041: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 42/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5229 - recall_m: 0.9168 - precision_m: 0.9168 - f1_m: 0.9168 - single_class_accuracy: 0.8225 - single_class_recall: 0.9555 - val_loss: 0.6329 - val_recall_m: 0.8543 - val_precision_m: 0.8543 - val_f1_m: 0.8543 - val_single_class_accuracy: 0.3606 - val_single_class_recall: 0.8615\n",
      "\n",
      "Epoch 00042: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 43/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5239 - recall_m: 0.9177 - precision_m: 0.9177 - f1_m: 0.9177 - single_class_accuracy: 0.8228 - single_class_recall: 0.9574 - val_loss: 0.6291 - val_recall_m: 0.8555 - val_precision_m: 0.8555 - val_f1_m: 0.8555 - val_single_class_accuracy: 0.3625 - val_single_class_recall: 0.8615\n",
      "\n",
      "Epoch 00043: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 44/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5226 - recall_m: 0.9186 - precision_m: 0.9186 - f1_m: 0.9186 - single_class_accuracy: 0.8247 - single_class_recall: 0.9565 - val_loss: 0.6327 - val_recall_m: 0.8551 - val_precision_m: 0.8551 - val_f1_m: 0.8551 - val_single_class_accuracy: 0.3617 - val_single_class_recall: 0.8615\n",
      "\n",
      "Epoch 00044: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 45/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5206 - recall_m: 0.9185 - precision_m: 0.9185 - f1_m: 0.9185 - single_class_accuracy: 0.8254 - single_class_recall: 0.9575 - val_loss: 0.6325 - val_recall_m: 0.8546 - val_precision_m: 0.8546 - val_f1_m: 0.8546 - val_single_class_accuracy: 0.3612 - val_single_class_recall: 0.8615\n",
      "\n",
      "Epoch 00045: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 46/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5215 - recall_m: 0.9180 - precision_m: 0.9180 - f1_m: 0.9180 - single_class_accuracy: 0.8245 - single_class_recall: 0.9573 - val_loss: 0.6309 - val_recall_m: 0.8555 - val_precision_m: 0.8555 - val_f1_m: 0.8555 - val_single_class_accuracy: 0.3624 - val_single_class_recall: 0.8615\n",
      "\n",
      "Epoch 00046: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 47/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.5222 - recall_m: 0.9186 - precision_m: 0.9186 - f1_m: 0.9186 - single_class_accuracy: 0.8269 - single_class_recall: 0.9551 - val_loss: 0.6292 - val_recall_m: 0.8565 - val_precision_m: 0.8565 - val_f1_m: 0.8565 - val_single_class_accuracy: 0.3641 - val_single_class_recall: 0.8607\n",
      "\n",
      "Epoch 00047: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 48/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5219 - recall_m: 0.9175 - precision_m: 0.9175 - f1_m: 0.9175 - single_class_accuracy: 0.8257 - single_class_recall: 0.9548 - val_loss: 0.6377 - val_recall_m: 0.8524 - val_precision_m: 0.8524 - val_f1_m: 0.8524 - val_single_class_accuracy: 0.3580 - val_single_class_recall: 0.8623\n",
      "\n",
      "Epoch 00048: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 49/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5216 - recall_m: 0.9183 - precision_m: 0.9183 - f1_m: 0.9183 - single_class_accuracy: 0.8270 - single_class_recall: 0.9549 - val_loss: 0.6272 - val_recall_m: 0.8566 - val_precision_m: 0.8566 - val_f1_m: 0.8566 - val_single_class_accuracy: 0.3644 - val_single_class_recall: 0.8607\n",
      "\n",
      "Epoch 00049: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 50/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5208 - recall_m: 0.9179 - precision_m: 0.9179 - f1_m: 0.9179 - single_class_accuracy: 0.8258 - single_class_recall: 0.9535 - val_loss: 0.6301 - val_recall_m: 0.8557 - val_precision_m: 0.8557 - val_f1_m: 0.8557 - val_single_class_accuracy: 0.3624 - val_single_class_recall: 0.8615\n",
      "\n",
      "Epoch 00050: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 51/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5212 - recall_m: 0.9188 - precision_m: 0.9188 - f1_m: 0.9188 - single_class_accuracy: 0.8280 - single_class_recall: 0.9545 - val_loss: 0.6280 - val_recall_m: 0.8563 - val_precision_m: 0.8563 - val_f1_m: 0.8563 - val_single_class_accuracy: 0.3641 - val_single_class_recall: 0.8607\n",
      "\n",
      "Epoch 00051: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 52/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5213 - recall_m: 0.9195 - precision_m: 0.9195 - f1_m: 0.9195 - single_class_accuracy: 0.8294 - single_class_recall: 0.9540 - val_loss: 0.6342 - val_recall_m: 0.8545 - val_precision_m: 0.8545 - val_f1_m: 0.8545 - val_single_class_accuracy: 0.3608 - val_single_class_recall: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 53/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5208 - recall_m: 0.9193 - precision_m: 0.9193 - f1_m: 0.9193 - single_class_accuracy: 0.8299 - single_class_recall: 0.9546 - val_loss: 0.6221 - val_recall_m: 0.8586 - val_precision_m: 0.8586 - val_f1_m: 0.8586 - val_single_class_accuracy: 0.3681 - val_single_class_recall: 0.8594\n",
      "\n",
      "Epoch 00053: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 54/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5214 - recall_m: 0.9181 - precision_m: 0.9181 - f1_m: 0.9181 - single_class_accuracy: 0.8268 - single_class_recall: 0.9543 - val_loss: 0.6237 - val_recall_m: 0.8581 - val_precision_m: 0.8581 - val_f1_m: 0.8581 - val_single_class_accuracy: 0.3674 - val_single_class_recall: 0.8602\n",
      "\n",
      "Epoch 00054: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 55/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5201 - recall_m: 0.9194 - precision_m: 0.9194 - f1_m: 0.9194 - single_class_accuracy: 0.8298 - single_class_recall: 0.9540 - val_loss: 0.6264 - val_recall_m: 0.8570 - val_precision_m: 0.8570 - val_f1_m: 0.8570 - val_single_class_accuracy: 0.3649 - val_single_class_recall: 0.8607\n",
      "\n",
      "Epoch 00055: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 56/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5203 - recall_m: 0.9206 - precision_m: 0.9206 - f1_m: 0.9206 - single_class_accuracy: 0.8303 - single_class_recall: 0.9529 - val_loss: 0.6247 - val_recall_m: 0.8576 - val_precision_m: 0.8576 - val_f1_m: 0.8576 - val_single_class_accuracy: 0.3658 - val_single_class_recall: 0.8602\n",
      "\n",
      "Epoch 00056: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 57/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5200 - recall_m: 0.9202 - precision_m: 0.9202 - f1_m: 0.9202 - single_class_accuracy: 0.8317 - single_class_recall: 0.9531 - val_loss: 0.6254 - val_recall_m: 0.8578 - val_precision_m: 0.8578 - val_f1_m: 0.8578 - val_single_class_accuracy: 0.3666 - val_single_class_recall: 0.8602\n",
      "\n",
      "Epoch 00057: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 58/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5202 - recall_m: 0.9208 - precision_m: 0.9208 - f1_m: 0.9208 - single_class_accuracy: 0.8327 - single_class_recall: 0.9535 - val_loss: 0.6200 - val_recall_m: 0.8593 - val_precision_m: 0.8593 - val_f1_m: 0.8592 - val_single_class_accuracy: 0.3686 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00058: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 59/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5213 - recall_m: 0.9194 - precision_m: 0.9194 - f1_m: 0.9194 - single_class_accuracy: 0.8300 - single_class_recall: 0.9552 - val_loss: 0.6252 - val_recall_m: 0.8579 - val_precision_m: 0.8579 - val_f1_m: 0.8579 - val_single_class_accuracy: 0.3661 - val_single_class_recall: 0.8600\n",
      "\n",
      "Epoch 00059: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 60/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.5195 - recall_m: 0.9201 - precision_m: 0.9201 - f1_m: 0.9201 - single_class_accuracy: 0.8334 - single_class_recall: 0.9509 - val_loss: 0.6270 - val_recall_m: 0.8568 - val_precision_m: 0.8568 - val_f1_m: 0.8568 - val_single_class_accuracy: 0.3642 - val_single_class_recall: 0.8607\n",
      "\n",
      "Epoch 00060: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 61/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5197 - recall_m: 0.9201 - precision_m: 0.9201 - f1_m: 0.9201 - single_class_accuracy: 0.8330 - single_class_recall: 0.9523 - val_loss: 0.6186 - val_recall_m: 0.8598 - val_precision_m: 0.8598 - val_f1_m: 0.8598 - val_single_class_accuracy: 0.3698 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00061: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 62/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5206 - recall_m: 0.9202 - precision_m: 0.9202 - f1_m: 0.9202 - single_class_accuracy: 0.8318 - single_class_recall: 0.9531 - val_loss: 0.6218 - val_recall_m: 0.8586 - val_precision_m: 0.8586 - val_f1_m: 0.8586 - val_single_class_accuracy: 0.3678 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00062: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 63/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5204 - recall_m: 0.9200 - precision_m: 0.9200 - f1_m: 0.9200 - single_class_accuracy: 0.8322 - single_class_recall: 0.9530 - val_loss: 0.6244 - val_recall_m: 0.8575 - val_precision_m: 0.8575 - val_f1_m: 0.8575 - val_single_class_accuracy: 0.3652 - val_single_class_recall: 0.8600\n",
      "\n",
      "Epoch 00063: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 64/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5200 - recall_m: 0.9195 - precision_m: 0.9195 - f1_m: 0.9195 - single_class_accuracy: 0.8306 - single_class_recall: 0.9514 - val_loss: 0.6193 - val_recall_m: 0.8593 - val_precision_m: 0.8593 - val_f1_m: 0.8592 - val_single_class_accuracy: 0.3690 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00064: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 65/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5193 - recall_m: 0.9209 - precision_m: 0.9209 - f1_m: 0.9209 - single_class_accuracy: 0.8334 - single_class_recall: 0.9517 - val_loss: 0.6239 - val_recall_m: 0.8581 - val_precision_m: 0.8581 - val_f1_m: 0.8581 - val_single_class_accuracy: 0.3664 - val_single_class_recall: 0.8602\n",
      "\n",
      "Epoch 00065: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 66/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.5196 - recall_m: 0.9205 - precision_m: 0.9205 - f1_m: 0.9205 - single_class_accuracy: 0.8316 - single_class_recall: 0.9521 - val_loss: 0.6189 - val_recall_m: 0.8596 - val_precision_m: 0.8596 - val_f1_m: 0.8596 - val_single_class_accuracy: 0.3695 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00066: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 67/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5198 - recall_m: 0.9203 - precision_m: 0.9203 - f1_m: 0.9203 - single_class_accuracy: 0.8326 - single_class_recall: 0.9511 - val_loss: 0.6184 - val_recall_m: 0.8599 - val_precision_m: 0.8599 - val_f1_m: 0.8599 - val_single_class_accuracy: 0.3698 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00067: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 68/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5200 - recall_m: 0.9202 - precision_m: 0.9202 - f1_m: 0.9202 - single_class_accuracy: 0.8347 - single_class_recall: 0.9493 - val_loss: 0.6261 - val_recall_m: 0.8573 - val_precision_m: 0.8573 - val_f1_m: 0.8573 - val_single_class_accuracy: 0.3655 - val_single_class_recall: 0.8607\n",
      "\n",
      "Epoch 00068: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 69/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5194 - recall_m: 0.9200 - precision_m: 0.9200 - f1_m: 0.9200 - single_class_accuracy: 0.8326 - single_class_recall: 0.9529 - val_loss: 0.6193 - val_recall_m: 0.8596 - val_precision_m: 0.8596 - val_f1_m: 0.8596 - val_single_class_accuracy: 0.3695 - val_single_class_recall: 0.8582\n",
      "\n",
      "Epoch 00069: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 70/100\n",
      "Learning rate:  1.0000000000000001e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5193 - recall_m: 0.9201 - precision_m: 0.9201 - f1_m: 0.9201 - single_class_accuracy: 0.8322 - single_class_recall: 0.9502 - val_loss: 0.6174 - val_recall_m: 0.8598 - val_precision_m: 0.8598 - val_f1_m: 0.8598 - val_single_class_accuracy: 0.3699 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00070: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 71/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5190 - recall_m: 0.9201 - precision_m: 0.9201 - f1_m: 0.9201 - single_class_accuracy: 0.8321 - single_class_recall: 0.9522 - val_loss: 0.6193 - val_recall_m: 0.8600 - val_precision_m: 0.8600 - val_f1_m: 0.8600 - val_single_class_accuracy: 0.3701 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00071: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 72/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5195 - recall_m: 0.9204 - precision_m: 0.9204 - f1_m: 0.9204 - single_class_accuracy: 0.8330 - single_class_recall: 0.9539 - val_loss: 0.6147 - val_recall_m: 0.8609 - val_precision_m: 0.8609 - val_f1_m: 0.8609 - val_single_class_accuracy: 0.3711 - val_single_class_recall: 0.8556\n",
      "\n",
      "Epoch 00072: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 73/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5187 - recall_m: 0.9206 - precision_m: 0.9206 - f1_m: 0.9206 - single_class_accuracy: 0.8326 - single_class_recall: 0.9534 - val_loss: 0.6189 - val_recall_m: 0.8598 - val_precision_m: 0.8598 - val_f1_m: 0.8598 - val_single_class_accuracy: 0.3699 - val_single_class_recall: 0.8582\n",
      "\n",
      "Epoch 00073: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 74/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5204 - recall_m: 0.9201 - precision_m: 0.9201 - f1_m: 0.9201 - single_class_accuracy: 0.8310 - single_class_recall: 0.9533 - val_loss: 0.6225 - val_recall_m: 0.8584 - val_precision_m: 0.8584 - val_f1_m: 0.8584 - val_single_class_accuracy: 0.3669 - val_single_class_recall: 0.8600\n",
      "\n",
      "Epoch 00074: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 75/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5190 - recall_m: 0.9196 - precision_m: 0.9196 - f1_m: 0.9196 - single_class_accuracy: 0.8309 - single_class_recall: 0.9502 - val_loss: 0.6262 - val_recall_m: 0.8571 - val_precision_m: 0.8571 - val_f1_m: 0.8571 - val_single_class_accuracy: 0.3649 - val_single_class_recall: 0.8600\n",
      "\n",
      "Epoch 00075: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 76/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5197 - recall_m: 0.9207 - precision_m: 0.9207 - f1_m: 0.9207 - single_class_accuracy: 0.8332 - single_class_recall: 0.9526 - val_loss: 0.6203 - val_recall_m: 0.8591 - val_precision_m: 0.8591 - val_f1_m: 0.8591 - val_single_class_accuracy: 0.3681 - val_single_class_recall: 0.8594\n",
      "\n",
      "Epoch 00076: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 77/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5188 - recall_m: 0.9219 - precision_m: 0.9219 - f1_m: 0.9219 - single_class_accuracy: 0.8360 - single_class_recall: 0.9538 - val_loss: 0.6224 - val_recall_m: 0.8586 - val_precision_m: 0.8586 - val_f1_m: 0.8586 - val_single_class_accuracy: 0.3673 - val_single_class_recall: 0.8594\n",
      "\n",
      "Epoch 00077: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 78/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5196 - recall_m: 0.9209 - precision_m: 0.9209 - f1_m: 0.9209 - single_class_accuracy: 0.8339 - single_class_recall: 0.9521 - val_loss: 0.6212 - val_recall_m: 0.8593 - val_precision_m: 0.8593 - val_f1_m: 0.8592 - val_single_class_accuracy: 0.3689 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00078: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 79/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.5189 - recall_m: 0.9211 - precision_m: 0.9211 - f1_m: 0.9211 - single_class_accuracy: 0.8353 - single_class_recall: 0.9523 - val_loss: 0.6240 - val_recall_m: 0.8581 - val_precision_m: 0.8581 - val_f1_m: 0.8581 - val_single_class_accuracy: 0.3665 - val_single_class_recall: 0.8600\n",
      "\n",
      "Epoch 00079: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 80/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5203 - recall_m: 0.9204 - precision_m: 0.9204 - f1_m: 0.9204 - single_class_accuracy: 0.8335 - single_class_recall: 0.9515 - val_loss: 0.6227 - val_recall_m: 0.8589 - val_precision_m: 0.8589 - val_f1_m: 0.8589 - val_single_class_accuracy: 0.3687 - val_single_class_recall: 0.8594\n",
      "\n",
      "Epoch 00080: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 81/100\n",
      "Learning rate:  1.0000000000000001e-07\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5193 - recall_m: 0.9195 - precision_m: 0.9195 - f1_m: 0.9195 - single_class_accuracy: 0.8310 - single_class_recall: 0.9530 - val_loss: 0.6138 - val_recall_m: 0.8619 - val_precision_m: 0.8619 - val_f1_m: 0.8619 - val_single_class_accuracy: 0.3731 - val_single_class_recall: 0.8564\n",
      "\n",
      "Epoch 00081: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 82/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5195 - recall_m: 0.9198 - precision_m: 0.9198 - f1_m: 0.9198 - single_class_accuracy: 0.8329 - single_class_recall: 0.9510 - val_loss: 0.6210 - val_recall_m: 0.8589 - val_precision_m: 0.8589 - val_f1_m: 0.8589 - val_single_class_accuracy: 0.3680 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00082: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 83/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5191 - recall_m: 0.9199 - precision_m: 0.9199 - f1_m: 0.9199 - single_class_accuracy: 0.8308 - single_class_recall: 0.9511 - val_loss: 0.6182 - val_recall_m: 0.8595 - val_precision_m: 0.8595 - val_f1_m: 0.8595 - val_single_class_accuracy: 0.3694 - val_single_class_recall: 0.8580\n",
      "\n",
      "Epoch 00083: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 84/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5204 - recall_m: 0.9202 - precision_m: 0.9202 - f1_m: 0.9202 - single_class_accuracy: 0.8323 - single_class_recall: 0.9517 - val_loss: 0.6180 - val_recall_m: 0.8595 - val_precision_m: 0.8595 - val_f1_m: 0.8595 - val_single_class_accuracy: 0.3693 - val_single_class_recall: 0.8580\n",
      "\n",
      "Epoch 00084: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 85/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.5204 - recall_m: 0.9194 - precision_m: 0.9194 - f1_m: 0.9194 - single_class_accuracy: 0.8312 - single_class_recall: 0.9502 - val_loss: 0.6166 - val_recall_m: 0.8603 - val_precision_m: 0.8603 - val_f1_m: 0.8603 - val_single_class_accuracy: 0.3706 - val_single_class_recall: 0.8580\n",
      "\n",
      "Epoch 00085: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 86/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5197 - recall_m: 0.9205 - precision_m: 0.9205 - f1_m: 0.9205 - single_class_accuracy: 0.8330 - single_class_recall: 0.9525 - val_loss: 0.6181 - val_recall_m: 0.8605 - val_precision_m: 0.8605 - val_f1_m: 0.8605 - val_single_class_accuracy: 0.3710 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00086: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 87/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5198 - recall_m: 0.9202 - precision_m: 0.9202 - f1_m: 0.9202 - single_class_accuracy: 0.8333 - single_class_recall: 0.9516 - val_loss: 0.6285 - val_recall_m: 0.8565 - val_precision_m: 0.8565 - val_f1_m: 0.8565 - val_single_class_accuracy: 0.3641 - val_single_class_recall: 0.8607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00087: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 88/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5199 - recall_m: 0.9200 - precision_m: 0.9200 - f1_m: 0.9200 - single_class_accuracy: 0.8326 - single_class_recall: 0.9513 - val_loss: 0.6200 - val_recall_m: 0.8590 - val_precision_m: 0.8590 - val_f1_m: 0.8590 - val_single_class_accuracy: 0.3679 - val_single_class_recall: 0.8588\n",
      "\n",
      "Epoch 00088: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 89/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5196 - recall_m: 0.9196 - precision_m: 0.9196 - f1_m: 0.9196 - single_class_accuracy: 0.8313 - single_class_recall: 0.9531 - val_loss: 0.6255 - val_recall_m: 0.8578 - val_precision_m: 0.8578 - val_f1_m: 0.8578 - val_single_class_accuracy: 0.3659 - val_single_class_recall: 0.8600\n",
      "\n",
      "Epoch 00089: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 90/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5192 - recall_m: 0.9204 - precision_m: 0.9204 - f1_m: 0.9204 - single_class_accuracy: 0.8325 - single_class_recall: 0.9520 - val_loss: 0.6200 - val_recall_m: 0.8594 - val_precision_m: 0.8594 - val_f1_m: 0.8594 - val_single_class_accuracy: 0.3694 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00090: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 91/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5199 - recall_m: 0.9196 - precision_m: 0.9196 - f1_m: 0.9196 - single_class_accuracy: 0.8314 - single_class_recall: 0.9512 - val_loss: 0.6203 - val_recall_m: 0.8592 - val_precision_m: 0.8592 - val_f1_m: 0.8592 - val_single_class_accuracy: 0.3685 - val_single_class_recall: 0.8600\n",
      "\n",
      "Epoch 00091: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 92/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5190 - recall_m: 0.9206 - precision_m: 0.9206 - f1_m: 0.9206 - single_class_accuracy: 0.8330 - single_class_recall: 0.9537 - val_loss: 0.6187 - val_recall_m: 0.8599 - val_precision_m: 0.8599 - val_f1_m: 0.8599 - val_single_class_accuracy: 0.3699 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00092: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 93/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5193 - recall_m: 0.9205 - precision_m: 0.9205 - f1_m: 0.9205 - single_class_accuracy: 0.8339 - single_class_recall: 0.9504 - val_loss: 0.6178 - val_recall_m: 0.8596 - val_precision_m: 0.8596 - val_f1_m: 0.8596 - val_single_class_accuracy: 0.3690 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00093: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 94/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5190 - recall_m: 0.9208 - precision_m: 0.9208 - f1_m: 0.9208 - single_class_accuracy: 0.8335 - single_class_recall: 0.9516 - val_loss: 0.6202 - val_recall_m: 0.8593 - val_precision_m: 0.8593 - val_f1_m: 0.8593 - val_single_class_accuracy: 0.3692 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00094: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 95/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5202 - recall_m: 0.9203 - precision_m: 0.9203 - f1_m: 0.9203 - single_class_accuracy: 0.8337 - single_class_recall: 0.9525 - val_loss: 0.6217 - val_recall_m: 0.8583 - val_precision_m: 0.8583 - val_f1_m: 0.8583 - val_single_class_accuracy: 0.3669 - val_single_class_recall: 0.8600\n",
      "\n",
      "Epoch 00095: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 96/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5195 - recall_m: 0.9208 - precision_m: 0.9208 - f1_m: 0.9208 - single_class_accuracy: 0.8335 - single_class_recall: 0.9522 - val_loss: 0.6159 - val_recall_m: 0.8608 - val_precision_m: 0.8608 - val_f1_m: 0.8608 - val_single_class_accuracy: 0.3714 - val_single_class_recall: 0.8582\n",
      "\n",
      "Epoch 00096: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 97/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5198 - recall_m: 0.9202 - precision_m: 0.9202 - f1_m: 0.9202 - single_class_accuracy: 0.8316 - single_class_recall: 0.9525 - val_loss: 0.6203 - val_recall_m: 0.8590 - val_precision_m: 0.8590 - val_f1_m: 0.8590 - val_single_class_accuracy: 0.3677 - val_single_class_recall: 0.8590\n",
      "\n",
      "Epoch 00097: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 98/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 141s 5ms/step - loss: 0.5202 - recall_m: 0.9204 - precision_m: 0.9204 - f1_m: 0.9204 - single_class_accuracy: 0.8324 - single_class_recall: 0.9528 - val_loss: 0.6157 - val_recall_m: 0.8608 - val_precision_m: 0.8608 - val_f1_m: 0.8608 - val_single_class_accuracy: 0.3712 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00098: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 99/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5203 - recall_m: 0.9195 - precision_m: 0.9195 - f1_m: 0.9195 - single_class_accuracy: 0.8301 - single_class_recall: 0.9519 - val_loss: 0.6181 - val_recall_m: 0.8596 - val_precision_m: 0.8596 - val_f1_m: 0.8596 - val_single_class_accuracy: 0.3695 - val_single_class_recall: 0.8586\n",
      "\n",
      "Epoch 00099: val_single_class_accuracy did not improve from 0.41000\n",
      "Epoch 100/100\n",
      "Learning rate:  1e-08\n",
      "28548/28548 [==============================] - 140s 5ms/step - loss: 0.5195 - recall_m: 0.9200 - precision_m: 0.9200 - f1_m: 0.9200 - single_class_accuracy: 0.8319 - single_class_recall: 0.9533 - val_loss: 0.6228 - val_recall_m: 0.8587 - val_precision_m: 0.8587 - val_f1_m: 0.8587 - val_single_class_accuracy: 0.3674 - val_single_class_recall: 0.8594\n",
      "\n",
      "Epoch 00100: val_single_class_accuracy did not improve from 0.41000\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'Combined_Sampled_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_single_class_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer =  ReduceLROnPlateau(min_lr=1e-6, monitor='val_single_class_accuracy', verbose=1,factor=0.8,patience=20)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train_,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test, Y_test_),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks,class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/ICC_ResNet20v2_model.001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = y_pred.argmax(axis=1)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, Reshape#, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers.noise import GaussianNoise\n",
    "#Hyperparameters for the network\n",
    "DENSE = 256\n",
    "DROPOUT = 0.5\n",
    "C1_K  = 8 #Number of kernels/feature extractors for first layer\n",
    "C1_S  = 3 #Width of the convolutional mini networks\n",
    "C2_K  = 8\n",
    "C2_S  = 3\n",
    "C3_K  = 4\n",
    "C3_S  = 3\n",
    "C4_K  = 1\n",
    "C4_S  = 3\n",
    "\n",
    "activation='relu'\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "#The model\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    #Adding a bit of GaussianNoise also works as regularization\n",
    "    model.add(GaussianNoise(0, input_shape=(input_dim,)))\n",
    "    #First two is number of filter + kernel size\n",
    "    model.add(Reshape((input_dim, 1)))\n",
    "    model.add(Conv1D(C1_K, (C1_S), activation=activation, border_mode=\"same\"))\n",
    "    model.add(Conv1D(C2_K, (C2_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Conv1D(C3_K, (C3_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Conv1D(C4_K, (C4_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(DENSE, activation=activation))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adadelta(lr=1e-3),\n",
    "                  metrics=[recall_m,precision_m,f1_m,single_class_accuracy,single_class_recall])#, metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(8, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(8, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(4, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(1, 3, activation=\"relu\", padding=\"same\")`\n",
      "W0117 09:04:15.958045  9492 deprecation.py:506] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_1 (GaussianNo (None, 12001)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 12001, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 12001, 8)          32        \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 12001, 8)          200       \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 12001, 4)          100       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 12001, 1)          13        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12001)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12001)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               3072512   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,073,371\n",
      "Trainable params: 3,073,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#keras.backend.clear_session()\n",
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28548 samples, validate on 13627 samples\n",
      "Epoch 1/200\n",
      "28548/28548 [==============================] - 12s 431us/step - loss: 0.9242 - recall_m: 0.5603 - precision_m: 0.5604 - f1_m: 0.5604 - single_class_accuracy: 0.3521 - single_class_recall: 0.3801 - val_loss: 0.6931 - val_recall_m: 0.5987 - val_precision_m: 0.5988 - val_f1_m: 0.5988 - val_single_class_accuracy: 0.0970 - val_single_class_recall: 0.4469\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.09701, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\abd_CNN_model.001.h5\n",
      "Epoch 2/200\n",
      "28548/28548 [==============================] - 8s 294us/step - loss: 0.9241 - recall_m: 0.5337 - precision_m: 0.5338 - f1_m: 0.5338 - single_class_accuracy: 0.3722 - single_class_recall: 0.5753 - val_loss: 0.6932 - val_recall_m: 0.3686 - val_precision_m: 0.3686 - val_f1_m: 0.3686 - val_single_class_accuracy: 0.1013 - val_single_class_recall: 0.8164\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.09701 to 0.10131, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\abd_CNN_model.002.h5\n",
      "Epoch 3/200\n",
      "28548/28548 [==============================] - 8s 296us/step - loss: 0.9241 - recall_m: 0.5055 - precision_m: 0.5056 - f1_m: 0.5055 - single_class_accuracy: 0.3785 - single_class_recall: 0.7489 - val_loss: 0.6933 - val_recall_m: 0.3106 - val_precision_m: 0.3106 - val_f1_m: 0.3106 - val_single_class_accuracy: 0.1006 - val_single_class_recall: 0.8949\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy did not improve from 0.10131\n",
      "Epoch 4/200\n",
      "28548/28548 [==============================] - 8s 297us/step - loss: 0.9241 - recall_m: 0.4994 - precision_m: 0.4994 - f1_m: 0.4994 - single_class_accuracy: 0.3821 - single_class_recall: 0.8148 - val_loss: 0.6934 - val_recall_m: 0.2697 - val_precision_m: 0.2697 - val_f1_m: 0.2697 - val_single_class_accuracy: 0.0997 - val_single_class_recall: 0.9452\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy did not improve from 0.10131\n",
      "Epoch 5/200\n",
      "28548/28548 [==============================] - 8s 295us/step - loss: 0.9241 - recall_m: 0.4930 - precision_m: 0.4930 - f1_m: 0.4930 - single_class_accuracy: 0.3852 - single_class_recall: 0.8706 - val_loss: 0.6935 - val_recall_m: 0.2257 - val_precision_m: 0.2257 - val_f1_m: 0.2257 - val_single_class_accuracy: 0.0963 - val_single_class_recall: 0.9687\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy did not improve from 0.10131\n",
      "Epoch 6/200\n",
      "28548/28548 [==============================] - 9s 298us/step - loss: 0.9240 - recall_m: 0.4650 - precision_m: 0.4650 - f1_m: 0.4650 - single_class_accuracy: 0.3775 - single_class_recall: 0.9303 - val_loss: 0.6936 - val_recall_m: 0.1993 - val_precision_m: 0.1993 - val_f1_m: 0.1993 - val_single_class_accuracy: 0.0949 - val_single_class_recall: 0.9873\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy did not improve from 0.10131\n",
      "Epoch 7/200\n",
      "28548/28548 [==============================] - 8s 296us/step - loss: 0.9240 - recall_m: 0.4506 - precision_m: 0.4506 - f1_m: 0.4506 - single_class_accuracy: 0.3734 - single_class_recall: 0.9544 - val_loss: 0.6937 - val_recall_m: 0.1871 - val_precision_m: 0.1871 - val_f1_m: 0.1871 - val_single_class_accuracy: 0.0938 - val_single_class_recall: 0.9903\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy did not improve from 0.10131\n",
      "Epoch 8/200\n",
      "13184/28548 [============>.................] - ETA: 3s - loss: 0.9178 - recall_m: 0.4459 - precision_m: 0.4459 - f1_m: 0.4459 - single_class_accuracy: 0.3646 - single_class_recall: 0.9517"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-9e5892e39cc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model.fit(X_train, Y_train_, epochs=200, batch_size=128, validation_data=(X_test, Y_test_), callbacks=[rdlr,checkpoint],\n\u001b[1;32m---> 15\u001b[1;33m          class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rdlr = ReduceLROnPlateau( min_lr=1e-6, monitor='val_single_class_accuracy', verbose=1,factor=0.8,patience=20)\n",
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'abd_CNN_model.{epoch:03d}.h5' \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_single_class_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "model.fit(X_train, Y_train_, epochs=200, batch_size=128, validation_data=(X_test, Y_test_), callbacks=[rdlr,checkpoint],\n",
    "         class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ce3575d7cb95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_single_class_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'true positive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_recall_m'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_recall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(model.history.history['val_single_class_accuracy'], label='true positive')\n",
    "plt.plot(model.history.history['val_recall_m'], label='val_recall')\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "# ax2 = plt.gca().twinx()\n",
    "# ax2.plot(model.history.history['lr'], color='r')\n",
    "# ax2.set_ylabel('lr',color='r')\n",
    "\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model trained on ABD dataset\n",
    "\n",
    "dependencies = {\n",
    "    'recall_m': recall_m,'precision_m':precision_m,'f1_m':f1_m,'single_class_accuracy':single_class_accuracy,\n",
    "    'single_class_recall':single_class_recall\n",
    "}\n",
    "model = keras.models.load_model('models/abd_CNN_model.001.h5',custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9529284164859002,\n",
       "  'recall': 0.33177252473378144,\n",
       "  'f1-score': 0.49218531174724106,\n",
       "  'support': 26482},\n",
       " '1': {'precision': 0.05581047913776545,\n",
       "  'recall': 0.7067567567567568,\n",
       "  'f1-score': 0.10345168628226684,\n",
       "  'support': 1480},\n",
       " 'accuracy': 0.3516200557900007,\n",
       " 'macro avg': {'precision': 0.5043694478118328,\n",
       "  'recall': 0.5192646407452691,\n",
       "  'f1-score': 0.29781849901475393,\n",
       "  'support': 27962},\n",
       " 'weighted avg': {'precision': 0.9054448835742616,\n",
       "  'recall': 0.3516200557900007,\n",
       "  'f1-score': 0.47161003938874874,\n",
       "  'support': 27962}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "classification_report(y_test.argmax(axis=1), y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOADING second dataset\n",
    "# df_abd=pd.read_pickle('Orbitrap_aplysia/buc.pkl')\n",
    "# psm_ID=list(pd.read_csv('Aplysia_ganglia/Buccal/DB search psm.csv')['Scan'])\n",
    "# y=np.zeros(df_abd.shape[0])\n",
    "\n",
    "# for i in range(0,df_abd.shape[0]):\n",
    "#     if df_abd.index[i] in psm_ID:\n",
    "#         y[i]=1\n",
    "\n",
    "# X = df_abd.drop('RT',axis=1).fillna(0).values\n",
    "# y =y.astype(int)[X.sum(axis=1)!=0]\n",
    "# X = X[X.sum(axis=1)!=0]\n",
    "# X = X/X.max(axis=1).reshape(X.shape[0],1)\n",
    "\n",
    "# del df_abd\n",
    "# X = X.reshape((X.shape[0],X.shape[1]))\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "# del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32677 samples, validate on 14005 samples\n",
      "Epoch 1/100\n",
      "32677/32677 [==============================] - 26s 804us/step - loss: 1.3185 - recall_m: 0.9561 - precision_m: 0.9561 - f1_m: 0.9561 - single_class_accuracy: 0.1658 - val_loss: 0.6697 - val_recall_m: 0.9508 - val_precision_m: 0.9508 - val_f1_m: 0.9508 - val_single_class_accuracy: 0.3039\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.30391, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.001.h5\n",
      "Epoch 2/100\n",
      "32677/32677 [==============================] - 18s 550us/step - loss: 1.3170 - recall_m: 0.9560 - precision_m: 0.9560 - f1_m: 0.9560 - single_class_accuracy: 0.2288 - val_loss: 0.6677 - val_recall_m: 0.9514 - val_precision_m: 0.9514 - val_f1_m: 0.9514 - val_single_class_accuracy: 0.3097\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.30391 to 0.30970, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.002.h5\n",
      "Epoch 3/100\n",
      "32677/32677 [==============================] - 18s 550us/step - loss: 1.3157 - recall_m: 0.9550 - precision_m: 0.9550 - f1_m: 0.9550 - single_class_accuracy: 0.2132 - val_loss: 0.6659 - val_recall_m: 0.9513 - val_precision_m: 0.9513 - val_f1_m: 0.9513 - val_single_class_accuracy: 0.3120\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy improved from 0.30970 to 0.31199, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.003.h5\n",
      "Epoch 4/100\n",
      "32677/32677 [==============================] - 18s 550us/step - loss: 1.3142 - recall_m: 0.9565 - precision_m: 0.9565 - f1_m: 0.9565 - single_class_accuracy: 0.2343 - val_loss: 0.6646 - val_recall_m: 0.9502 - val_precision_m: 0.9502 - val_f1_m: 0.9502 - val_single_class_accuracy: 0.3296\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.31199 to 0.32961, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.004.h5\n",
      "Epoch 5/100\n",
      "32677/32677 [==============================] - 18s 552us/step - loss: 1.3126 - recall_m: 0.9569 - precision_m: 0.9569 - f1_m: 0.9569 - single_class_accuracy: 0.2637 - val_loss: 0.6640 - val_recall_m: 0.9472 - val_precision_m: 0.9472 - val_f1_m: 0.9472 - val_single_class_accuracy: 0.3274\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 6/100\n",
      "32677/32677 [==============================] - 18s 552us/step - loss: 1.3109 - recall_m: 0.9532 - precision_m: 0.9532 - f1_m: 0.9532 - single_class_accuracy: 0.2700 - val_loss: 0.6632 - val_recall_m: 0.9437 - val_precision_m: 0.9437 - val_f1_m: 0.9437 - val_single_class_accuracy: 0.3203\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 7/100\n",
      "32677/32677 [==============================] - 18s 555us/step - loss: 1.3095 - recall_m: 0.9448 - precision_m: 0.9448 - f1_m: 0.9448 - single_class_accuracy: 0.2406 - val_loss: 0.6622 - val_recall_m: 0.9377 - val_precision_m: 0.9377 - val_f1_m: 0.9377 - val_single_class_accuracy: 0.2968\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 8/100\n",
      "32677/32677 [==============================] - 18s 551us/step - loss: 1.3076 - recall_m: 0.9438 - precision_m: 0.9438 - f1_m: 0.9438 - single_class_accuracy: 0.2795 - val_loss: 0.6629 - val_recall_m: 0.9117 - val_precision_m: 0.9117 - val_f1_m: 0.9117 - val_single_class_accuracy: 0.2395\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 9/100\n",
      "32677/32677 [==============================] - 18s 555us/step - loss: 1.3052 - recall_m: 0.9248 - precision_m: 0.9248 - f1_m: 0.9248 - single_class_accuracy: 0.2192 - val_loss: 0.6630 - val_recall_m: 0.8743 - val_precision_m: 0.8743 - val_f1_m: 0.8743 - val_single_class_accuracy: 0.1783\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 10/100\n",
      " 7424/32677 [=====>........................] - ETA: 12s - loss: 1.2974 - recall_m: 0.9127 - precision_m: 0.9127 - f1_m: 0.9127 - single_class_accuracy: 0.1853"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-26d83e5c8312>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n\u001b[1;32m---> 15\u001b[1;33m          class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# rdlr = ReduceLROnPlateau( min_lr=1e-4, monitor='val_single_class_accuracy', verbose=1,factor=0.8,patience=20)\n",
    "# save_dir = os.path.join(os.getcwd(), 'models')\n",
    "# model_name = 'buc_CNN_model.{epoch:03d}.h5' \n",
    "# if not os.path.isdir(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "# filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "# checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "#                              monitor='val_single_class_accuracy',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True)\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n",
    "#          class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[:,1:].reshape((data.shape[0],100,120,1))\n",
    "#x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=1)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65244, 100, 120, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, Reshape, MaxPooling2D#, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers.noise import GaussianNoise\n",
    "#Hyperparameters for the network\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[:]\n",
    "\n",
    "#The model\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    #convolutional layer with rectified linear unit activation\n",
    "    model.add(Conv2D(8, kernel_size=(16, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    #32 convolution filters used each of size 3x3\n",
    "    #again\n",
    "    model.add(Conv2D(8, (1, 3), activation='relu'))\n",
    "    model.add(Conv2D(8, (1, 3), activation='relu'))\n",
    "    #64 convolution filters used each of size 3x3\n",
    "    #choose the best features via pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #randomly turn neurons on and off to improve convergence\n",
    "    model.add(Dropout(0.25))\n",
    "    #flatten since too many dimensions, we only want a classification output\n",
    "    model.add(Flatten())\n",
    "    #fully connected to get all relevant data\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    #one more dropout for convergence' sake :) \n",
    "    model.add(Dropout(0.5))\n",
    "    #output a softmax to squash the matrix into output probabilities\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adadelta(lr=1e-3),\n",
    "                  metrics=[recall_m,precision_m,f1_m,single_class_accuracy,single_class_recall])#, metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_2: expected ndim=4, found ndim=3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-690f3800b402>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-67a261df5036>\u001b[0m in \u001b[0;36mmake_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     model.add(Conv2D(8, kernel_size=(16, 3),\n\u001b[0;32m     17\u001b[0m                      \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                      input_shape=input_shape))\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;31m#32 convolution filters used each of size 3x3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    163\u001b[0m                     \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_2: expected ndim=4, found ndim=3"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65244 samples, validate on 27962 samples\n",
      "Epoch 1/200\n",
      "65244/65244 [==============================] - 21s 327us/step - loss: 1.3129 - recall_m: 0.4690 - precision_m: 0.4690 - f1_m: 0.4690 - single_class_accuracy: 0.0540 - single_class_recall: 0.5389 - val_loss: 0.6936 - val_recall_m: 0.4779 - val_precision_m: 0.4779 - val_f1_m: 0.4779 - val_single_class_accuracy: 0.0620 - val_single_class_recall: 0.6181\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.06198, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.001.h5\n",
      "Epoch 2/200\n",
      "65244/65244 [==============================] - 19s 295us/step - loss: 1.3121 - recall_m: 0.5247 - precision_m: 0.5247 - f1_m: 0.5247 - single_class_accuracy: 0.0613 - single_class_recall: 0.5570 - val_loss: 0.6929 - val_recall_m: 0.5737 - val_precision_m: 0.5737 - val_f1_m: 0.5737 - val_single_class_accuracy: 0.0733 - val_single_class_recall: 0.5966\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.06198 to 0.07331, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.002.h5\n",
      "Epoch 3/200\n",
      "65244/65244 [==============================] - 19s 295us/step - loss: 1.3118 - recall_m: 0.5760 - precision_m: 0.5760 - f1_m: 0.5760 - single_class_accuracy: 0.0666 - single_class_recall: 0.5296 - val_loss: 0.6922 - val_recall_m: 0.6505 - val_precision_m: 0.6505 - val_f1_m: 0.6505 - val_single_class_accuracy: 0.0858 - val_single_class_recall: 0.5722\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy improved from 0.07331 to 0.08582, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.003.h5\n",
      "Epoch 4/200\n",
      "65244/65244 [==============================] - 19s 298us/step - loss: 1.3113 - recall_m: 0.6079 - precision_m: 0.6079 - f1_m: 0.6079 - single_class_accuracy: 0.0705 - single_class_recall: 0.5286 - val_loss: 0.6916 - val_recall_m: 0.6939 - val_precision_m: 0.6939 - val_f1_m: 0.6939 - val_single_class_accuracy: 0.0947 - val_single_class_recall: 0.5539\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.08582 to 0.09472, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.004.h5\n",
      "Epoch 5/200\n",
      "65244/65244 [==============================] - 19s 292us/step - loss: 1.3107 - recall_m: 0.6432 - precision_m: 0.6432 - f1_m: 0.6432 - single_class_accuracy: 0.0781 - single_class_recall: 0.5250 - val_loss: 0.6909 - val_recall_m: 0.7262 - val_precision_m: 0.7262 - val_f1_m: 0.7262 - val_single_class_accuracy: 0.1022 - val_single_class_recall: 0.5366\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy improved from 0.09472 to 0.10225, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.005.h5\n",
      "Epoch 6/200\n",
      "65244/65244 [==============================] - 19s 293us/step - loss: 1.3101 - recall_m: 0.6718 - precision_m: 0.6718 - f1_m: 0.6718 - single_class_accuracy: 0.0826 - single_class_recall: 0.5093 - val_loss: 0.6902 - val_recall_m: 0.7483 - val_precision_m: 0.7483 - val_f1_m: 0.7483 - val_single_class_accuracy: 0.1088 - val_single_class_recall: 0.5220\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy improved from 0.10225 to 0.10884, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.006.h5\n",
      "Epoch 7/200\n",
      "65244/65244 [==============================] - 19s 296us/step - loss: 1.3094 - recall_m: 0.6985 - precision_m: 0.6985 - f1_m: 0.6985 - single_class_accuracy: 0.0882 - single_class_recall: 0.5027 - val_loss: 0.6895 - val_recall_m: 0.7645 - val_precision_m: 0.7645 - val_f1_m: 0.7645 - val_single_class_accuracy: 0.1151 - val_single_class_recall: 0.5152\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy improved from 0.10884 to 0.11506, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.007.h5\n",
      "Epoch 8/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3091 - recall_m: 0.7182 - precision_m: 0.7182 - f1_m: 0.7182 - single_class_accuracy: 0.0938 - single_class_recall: 0.4930 - val_loss: 0.6888 - val_recall_m: 0.7763 - val_precision_m: 0.7763 - val_f1_m: 0.7763 - val_single_class_accuracy: 0.1191 - val_single_class_recall: 0.5052\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy improved from 0.11506 to 0.11915, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.008.h5\n",
      "Epoch 9/200\n",
      "65244/65244 [==============================] - 20s 299us/step - loss: 1.3083 - recall_m: 0.7400 - precision_m: 0.7400 - f1_m: 0.7400 - single_class_accuracy: 0.0999 - single_class_recall: 0.4887 - val_loss: 0.6880 - val_recall_m: 0.7843 - val_precision_m: 0.7843 - val_f1_m: 0.7843 - val_single_class_accuracy: 0.1223 - val_single_class_recall: 0.4985\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy improved from 0.11915 to 0.12230, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.009.h5\n",
      "Epoch 10/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3077 - recall_m: 0.7473 - precision_m: 0.7473 - f1_m: 0.7473 - single_class_accuracy: 0.1035 - single_class_recall: 0.4862 - val_loss: 0.6872 - val_recall_m: 0.7873 - val_precision_m: 0.7873 - val_f1_m: 0.7873 - val_single_class_accuracy: 0.1234 - val_single_class_recall: 0.4949\n",
      "\n",
      "Epoch 00010: val_single_class_accuracy improved from 0.12230 to 0.12341, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.010.h5\n",
      "Epoch 11/200\n",
      "65244/65244 [==============================] - 19s 295us/step - loss: 1.3071 - recall_m: 0.7571 - precision_m: 0.7571 - f1_m: 0.7571 - single_class_accuracy: 0.1058 - single_class_recall: 0.4734 - val_loss: 0.6865 - val_recall_m: 0.7901 - val_precision_m: 0.7901 - val_f1_m: 0.7901 - val_single_class_accuracy: 0.1247 - val_single_class_recall: 0.4931\n",
      "\n",
      "Epoch 00011: val_single_class_accuracy improved from 0.12341 to 0.12465, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.011.h5\n",
      "Epoch 12/200\n",
      "65244/65244 [==============================] - 19s 296us/step - loss: 1.3061 - recall_m: 0.7704 - precision_m: 0.7704 - f1_m: 0.7704 - single_class_accuracy: 0.1119 - single_class_recall: 0.4792 - val_loss: 0.6857 - val_recall_m: 0.7919 - val_precision_m: 0.7919 - val_f1_m: 0.7919 - val_single_class_accuracy: 0.1242 - val_single_class_recall: 0.4878\n",
      "\n",
      "Epoch 00012: val_single_class_accuracy did not improve from 0.12465\n",
      "Epoch 13/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3054 - recall_m: 0.7695 - precision_m: 0.7695 - f1_m: 0.7695 - single_class_accuracy: 0.1123 - single_class_recall: 0.4846 - val_loss: 0.6849 - val_recall_m: 0.7913 - val_precision_m: 0.7913 - val_f1_m: 0.7913 - val_single_class_accuracy: 0.1239 - val_single_class_recall: 0.4857\n",
      "\n",
      "Epoch 00013: val_single_class_accuracy did not improve from 0.12465\n",
      "Epoch 14/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3043 - recall_m: 0.7704 - precision_m: 0.7704 - f1_m: 0.7704 - single_class_accuracy: 0.1148 - single_class_recall: 0.4969 - val_loss: 0.6842 - val_recall_m: 0.7894 - val_precision_m: 0.7894 - val_f1_m: 0.7894 - val_single_class_accuracy: 0.1233 - val_single_class_recall: 0.4904\n",
      "\n",
      "Epoch 00014: val_single_class_accuracy did not improve from 0.12465\n",
      "Epoch 15/200\n",
      "39040/65244 [================>.............] - ETA: 6s - loss: 1.3068 - recall_m: 0.7694 - precision_m: 0.7694 - f1_m: 0.7694 - single_class_accuracy: 0.1154 - single_class_recall: 0.5006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-7f6c1b51bedd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n\u001b[1;32m---> 15\u001b[1;33m          class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rdlr = ReduceLROnPlateau( min_lr=1e-6, monitor='val_single_class_accuracy', verbose=1,factor=0.5,patience=20)\n",
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'abd_buc_CNN2D_model.{epoch:03d}.h5' \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_single_class_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n",
    "         class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
