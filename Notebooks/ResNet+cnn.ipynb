{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cuda_path = 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0\\\\bin'\n",
    "cudnn_path = 'D:\\\\Work\\\\software\\\\cuda\\\\bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + cuda_path\n",
    "os.environ[\"PATH\"] += os.pathsep + cudnn_path\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import analysis\n",
    "import sys\n",
    "sys.path.insert(0,'../scripts/')\n",
    "\n",
    "import test_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots,scatter\n",
    "import seaborn as sns\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "#import analysis\n",
    "def read_data(file_dir,DB_file_dir):\n",
    "    \n",
    "    data = []\n",
    "    label = []\n",
    "    \n",
    "    print('loading..{}'.format(file_dir))\n",
    "    df=pd.read_pickle(file_dir)\n",
    "    psm_ID=list(pd.read_csv(DB_file_dir)['Scan'])\n",
    "    y=np.zeros(df.shape[0])\n",
    "\n",
    "    for i in range(0,df.shape[0]):\n",
    "        if df.index[i] in psm_ID:\n",
    "            y[i]=1\n",
    "\n",
    "    X = df.drop('RT',axis=1).fillna(0).values\n",
    "    y =y.astype(int)[X.sum(axis=1)!=0]\n",
    "    X = X[X.sum(axis=1)!=0]\n",
    "    X = X/X.sum(axis=1).reshape(X.shape[0],1) #normalization\n",
    "    data.append(X)\n",
    "    label.append(y)\n",
    "    del X\n",
    "\n",
    "    data = np.concatenate((data))\n",
    "    label = np.concatenate((label))\n",
    "    return data,label\n",
    "\n",
    "from numpy.random import randint,seed,choice\n",
    "def under_sampler(data,label,n_sample):\n",
    "    \n",
    "    index_maj = np.where(label==0)[0]\n",
    "    index_min = np.where(label==1)[0]\n",
    "    \n",
    "    seed(19)\n",
    "    sample_index = choice(len(index_maj),size=n_sample,replace=False)\n",
    "    index_maj_sampled = index_maj[sample_index]\n",
    "    data_sampled = data[np.concatenate((index_maj_sampled,index_min))]\n",
    "    label_sampled = label[np.concatenate((index_maj_sampled,index_min))]\n",
    "    \n",
    "    shuffle_index = choice(len(data_sampled),size=len(data_sampled),replace=False)\n",
    "    data_sampled = data_sampled[shuffle_index]\n",
    "    label_sampled = label_sampled[shuffle_index]\n",
    "    \n",
    "    return data_sampled,label_sampled\n",
    "\n",
    "def load_sample_data(file_dir,DB_file_dir,n_sample):\n",
    "    \n",
    "    X_train,X_test,Y_train,Y_test = [],[],[],[]\n",
    "    for i in range(len(file_dir)):\n",
    "        data,label = read_data(file_dir[i],DB_file_dir[i])\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=1)\n",
    "        del data\n",
    "        \n",
    "        x_train_sampled,y_train_sampled = under_sampler(x_train,y_train,len(y_train[y_train==1])*n_sample)\n",
    "        del x_train,y_train\n",
    "        X_train.append(x_train_sampled)\n",
    "        X_test.append(x_test)\n",
    "        Y_train.append(y_train_sampled)\n",
    "        Y_test.append(y_test)\n",
    "        del x_test,y_test,x_train_sampled,y_train_sampled\n",
    "        \n",
    "    X_train = np.concatenate(X_train)\n",
    "    X_test = np.concatenate(X_test)\n",
    "    Y_train = np.concatenate(Y_train)\n",
    "    Y_test = np.concatenate(Y_test)\n",
    "\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading..../Orbitrap_aplysia/abd.pkl\n",
      "loading..../Orbitrap_aplysia/buc.pkl\n",
      "loading..../Orbitrap_aplysia/cer.pkl\n"
     ]
    }
   ],
   "source": [
    "file_dir = ['../Orbitrap_aplysia/abd.pkl','../Orbitrap_aplysia/buc.pkl','../Orbitrap_aplysia/cer.pkl']\n",
    "DB_file_dir = ['../Aplysia_ganglia/Abdominal/DB search psm.csv','../Aplysia_ganglia/Buccal/DB search psm.csv',\n",
    "              '../Aplysia_ganglia/Cerebral/DB search psm.csv']\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = load_sample_data(file_dir,DB_file_dir,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Conv1D, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling1D, AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# import tensorflow as tf\n",
    "# K.clear_session()\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "# sess = tf.Session(config=config)\n",
    "# set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "num_classes = 2\n",
    "input_shape = X_train.shape[1:]\n",
    "scale_weight = Y_train[Y_train==0].shape[0]/Y_train[Y_train==1].shape[0]\n",
    "\n",
    "n = 1\n",
    "version = 2\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Input image dimensions.\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train_aug = keras.utils.to_categorical(y_train_aug, num_classes)\n",
    "Y_train_ = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test_ = keras.utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-2\n",
    "    if epoch > 100:\n",
    "        lr *= 0.5e-6\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-6\n",
    "    elif epoch > 60:\n",
    "        lr *= 1e-5\n",
    "    elif epoch > 40:\n",
    "        lr *= 1e-4\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=8,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv1D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=2):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv1D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling1D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0115 17:05:13.616310 18648 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0115 17:05:13.645348 18648 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0115 17:05:13.829168 18648 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0115 17:05:14.158424 18648 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0115 17:05:15.478189 18648 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0115 17:05:15.521079 18648 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0115 17:05:15.526057 18648 deprecation_wrapper.py:119] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 12001, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 12001, 16)    64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 12001, 16)    64          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 12001, 16)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 12001, 16)    272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 12001, 16)    64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 12001, 16)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 12001, 16)    784         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 12001, 16)    64          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 12001, 16)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 12001, 64)    1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 12001, 64)    1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 12001, 64)    0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12001, 64)    256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12001, 64)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 6001, 64)     4160        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6001, 64)     256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 6001, 64)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 6001, 64)     12352       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6001, 64)     256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 6001, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 6001, 128)    8320        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 6001, 128)    8320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 6001, 128)    0           conv1d_9[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6001, 128)    512         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6001, 128)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 3001, 128)    16512       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 3001, 128)    512         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 3001, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 3001, 128)    49280       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 3001, 128)    512         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 3001, 128)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 3001, 256)    33024       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 3001, 256)    33024       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 3001, 256)    0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 3001, 256)    1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 3001, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 375, 256)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 96000)        0           average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            192002      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 363,810\n",
      "Trainable params: 362,050\n",
      "Non-trainable params: 1,760\n",
      "__________________________________________________________________________________________________\n",
      "ResNet11v2\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "INTERESTING_CLASS_ID =  1 # Choose the class of interest\n",
    "\n",
    "def single_class_accuracy(y_true, y_pred):\n",
    "    class_id_true = K.argmax(y_true, axis=-1)\n",
    "    class_id_preds = K.argmax(y_pred, axis=-1)\n",
    "    accuracy_mask = K.cast(K.equal(class_id_preds, INTERESTING_CLASS_ID), 'int32')\n",
    "    #recall_mask = K.cast(K.equal(class_id_true, INTERESTING_CLASS_ID), 'int32')\n",
    "\n",
    "    class_acc_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * accuracy_mask\n",
    "    #class_recall_tensor = K.cast(K.equal(class_id_true, class_id_true), 'int32') * recall_mask\n",
    "    class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n",
    "    #class_recall = K.sum(class_recall_tensor) / K.maximum(K.sum(recall_mask), 1)\n",
    "    return class_acc\n",
    "\n",
    "def single_class_recall(y_true, y_pred):\n",
    "    class_id_true = K.argmax(y_true, axis=-1)\n",
    "    class_id_preds = K.argmax(y_pred, axis=-1)\n",
    "    #accuracy_mask = K.cast(K.equal(class_id_preds, INTERESTING_CLASS_ID), 'int32')\n",
    "    recall_mask = K.cast(K.equal(class_id_true, INTERESTING_CLASS_ID), 'int32')\n",
    "\n",
    "    #class_acc_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * accuracy_mask\n",
    "    class_recall_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * recall_mask\n",
    "    #class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n",
    "    class_recall = K.sum(class_recall_tensor) / K.maximum(K.sum(recall_mask), 1)\n",
    "    return class_recall\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adadelta(lr=1e-3),\n",
    "                  metrics=[recall_m,precision_m,f1_m,single_class_accuracy,single_class_recall])\n",
    "model.summary()\n",
    "print(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0115 17:05:45.808696 18648 deprecation.py:323] From C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 18006 samples, validate on 41590 samples\n",
      "Epoch 1/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 151s 8ms/step - loss: 1.0233 - recall_m: 0.6734 - precision_m: 0.6734 - f1_m: 0.6734 - single_class_accuracy: 0.5039 - single_class_recall: 0.7587 - val_loss: 0.7583 - val_recall_m: 0.7335 - val_precision_m: 0.7335 - val_f1_m: 0.7335 - val_single_class_accuracy: 0.1713 - val_single_class_recall: 0.7025\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.17128, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.001.h5\n",
      "Epoch 2/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 141s 8ms/step - loss: 0.8333 - recall_m: 0.8101 - precision_m: 0.8101 - f1_m: 0.8101 - single_class_accuracy: 0.6711 - single_class_recall: 0.8520 - val_loss: 0.6843 - val_recall_m: 0.8105 - val_precision_m: 0.8105 - val_f1_m: 0.8105 - val_single_class_accuracy: 0.2292 - val_single_class_recall: 0.7157\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.17128 to 0.22922, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.002.h5\n",
      "Epoch 3/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 144s 8ms/step - loss: 0.7650 - recall_m: 0.8384 - precision_m: 0.8384 - f1_m: 0.8384 - single_class_accuracy: 0.7116 - single_class_recall: 0.8613 - val_loss: 0.7471 - val_recall_m: 0.7883 - val_precision_m: 0.7883 - val_f1_m: 0.7883 - val_single_class_accuracy: 0.2188 - val_single_class_recall: 0.7763\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy did not improve from 0.22922\n",
      "Epoch 4/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 146s 8ms/step - loss: 0.7339 - recall_m: 0.8520 - precision_m: 0.8520 - f1_m: 0.8520 - single_class_accuracy: 0.7344 - single_class_recall: 0.8739 - val_loss: 0.6860 - val_recall_m: 0.8188 - val_precision_m: 0.8188 - val_f1_m: 0.8188 - val_single_class_accuracy: 0.2441 - val_single_class_recall: 0.7628\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.22922 to 0.24410, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.004.h5\n",
      "Epoch 5/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 146s 8ms/step - loss: 0.7171 - recall_m: 0.8593 - precision_m: 0.8593 - f1_m: 0.8593 - single_class_accuracy: 0.7423 - single_class_recall: 0.8803 - val_loss: 0.6664 - val_recall_m: 0.8319 - val_precision_m: 0.8319 - val_f1_m: 0.8319 - val_single_class_accuracy: 0.2593 - val_single_class_recall: 0.7607\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy improved from 0.24410 to 0.25931, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.005.h5\n",
      "Epoch 6/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 143s 8ms/step - loss: 0.7011 - recall_m: 0.8671 - precision_m: 0.8671 - f1_m: 0.8671 - single_class_accuracy: 0.7535 - single_class_recall: 0.8872 - val_loss: 0.6483 - val_recall_m: 0.8387 - val_precision_m: 0.8387 - val_f1_m: 0.8387 - val_single_class_accuracy: 0.2660 - val_single_class_recall: 0.7528\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy improved from 0.25931 to 0.26599, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.006.h5\n",
      "Epoch 7/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 140s 8ms/step - loss: 0.6881 - recall_m: 0.8702 - precision_m: 0.8702 - f1_m: 0.8702 - single_class_accuracy: 0.7626 - single_class_recall: 0.8915 - val_loss: 0.6325 - val_recall_m: 0.8486 - val_precision_m: 0.8486 - val_f1_m: 0.8486 - val_single_class_accuracy: 0.2781 - val_single_class_recall: 0.7500\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy improved from 0.26599 to 0.27814, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.007.h5\n",
      "Epoch 8/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 144s 8ms/step - loss: 0.6770 - recall_m: 0.8756 - precision_m: 0.8756 - f1_m: 0.8756 - single_class_accuracy: 0.7705 - single_class_recall: 0.8957 - val_loss: 0.5895 - val_recall_m: 0.8720 - val_precision_m: 0.8720 - val_f1_m: 0.8720 - val_single_class_accuracy: 0.3124 - val_single_class_recall: 0.7302\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy improved from 0.27814 to 0.31237, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.008.h5\n",
      "Epoch 9/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 146s 8ms/step - loss: 0.6706 - recall_m: 0.8779 - precision_m: 0.8779 - f1_m: 0.8779 - single_class_accuracy: 0.7733 - single_class_recall: 0.8988 - val_loss: 0.6401 - val_recall_m: 0.8452 - val_precision_m: 0.8452 - val_f1_m: 0.8452 - val_single_class_accuracy: 0.2752 - val_single_class_recall: 0.7585\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 10/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 145s 8ms/step - loss: 0.6604 - recall_m: 0.8832 - precision_m: 0.8832 - f1_m: 0.8832 - single_class_accuracy: 0.7795 - single_class_recall: 0.9067 - val_loss: 0.6139 - val_recall_m: 0.8589 - val_precision_m: 0.8589 - val_f1_m: 0.8589 - val_single_class_accuracy: 0.2946 - val_single_class_recall: 0.7501\n",
      "\n",
      "Epoch 00010: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 11/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 152s 8ms/step - loss: 0.6507 - recall_m: 0.8842 - precision_m: 0.8842 - f1_m: 0.8842 - single_class_accuracy: 0.7841 - single_class_recall: 0.9035 - val_loss: 0.6151 - val_recall_m: 0.8601 - val_precision_m: 0.8601 - val_f1_m: 0.8601 - val_single_class_accuracy: 0.2955 - val_single_class_recall: 0.7540\n",
      "\n",
      "Epoch 00011: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 12/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 153s 9ms/step - loss: 0.6455 - recall_m: 0.8880 - precision_m: 0.8880 - f1_m: 0.8880 - single_class_accuracy: 0.7877 - single_class_recall: 0.9114 - val_loss: 0.6477 - val_recall_m: 0.8436 - val_precision_m: 0.8436 - val_f1_m: 0.8436 - val_single_class_accuracy: 0.2746 - val_single_class_recall: 0.7699\n",
      "\n",
      "Epoch 00012: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 13/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 153s 8ms/step - loss: 0.6368 - recall_m: 0.8878 - precision_m: 0.8878 - f1_m: 0.8878 - single_class_accuracy: 0.7892 - single_class_recall: 0.9064 - val_loss: 0.5935 - val_recall_m: 0.8697 - val_precision_m: 0.8697 - val_f1_m: 0.8697 - val_single_class_accuracy: 0.3105 - val_single_class_recall: 0.7470\n",
      "\n",
      "Epoch 00013: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 14/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 154s 9ms/step - loss: 0.6289 - recall_m: 0.8924 - precision_m: 0.8924 - f1_m: 0.8924 - single_class_accuracy: 0.7929 - single_class_recall: 0.9129 - val_loss: 0.6283 - val_recall_m: 0.8560 - val_precision_m: 0.8560 - val_f1_m: 0.8560 - val_single_class_accuracy: 0.2921 - val_single_class_recall: 0.7645\n",
      "\n",
      "Epoch 00014: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 15/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 154s 9ms/step - loss: 0.6243 - recall_m: 0.8939 - precision_m: 0.8939 - f1_m: 0.8939 - single_class_accuracy: 0.7967 - single_class_recall: 0.9158 - val_loss: 0.5853 - val_recall_m: 0.8698 - val_precision_m: 0.8698 - val_f1_m: 0.8698 - val_single_class_accuracy: 0.3102 - val_single_class_recall: 0.7479\n",
      "\n",
      "Epoch 00015: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 16/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 153s 8ms/step - loss: 0.6177 - recall_m: 0.8947 - precision_m: 0.8947 - f1_m: 0.8947 - single_class_accuracy: 0.7986 - single_class_recall: 0.9166 - val_loss: 0.6423 - val_recall_m: 0.8448 - val_precision_m: 0.8448 - val_f1_m: 0.8448 - val_single_class_accuracy: 0.2780 - val_single_class_recall: 0.7757\n",
      "\n",
      "Epoch 00016: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 17/100\n",
      "Learning rate:  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18006/18006 [==============================] - 152s 8ms/step - loss: 0.6123 - recall_m: 0.8984 - precision_m: 0.8984 - f1_m: 0.8984 - single_class_accuracy: 0.8050 - single_class_recall: 0.9210 - val_loss: 0.5927 - val_recall_m: 0.8691 - val_precision_m: 0.8691 - val_f1_m: 0.8691 - val_single_class_accuracy: 0.3109 - val_single_class_recall: 0.7567\n",
      "\n",
      "Epoch 00017: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 18/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 152s 8ms/step - loss: 0.6083 - recall_m: 0.8975 - precision_m: 0.8975 - f1_m: 0.8975 - single_class_accuracy: 0.8021 - single_class_recall: 0.9192 - val_loss: 0.6108 - val_recall_m: 0.8618 - val_precision_m: 0.8618 - val_f1_m: 0.8618 - val_single_class_accuracy: 0.3012 - val_single_class_recall: 0.7659\n",
      "\n",
      "Epoch 00018: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 19/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 152s 8ms/step - loss: 0.6015 - recall_m: 0.9001 - precision_m: 0.9001 - f1_m: 0.9001 - single_class_accuracy: 0.8073 - single_class_recall: 0.9207 - val_loss: 0.6309 - val_recall_m: 0.8538 - val_precision_m: 0.8538 - val_f1_m: 0.8538 - val_single_class_accuracy: 0.2914 - val_single_class_recall: 0.7754\n",
      "\n",
      "Epoch 00019: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 20/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 153s 8ms/step - loss: 0.5953 - recall_m: 0.9016 - precision_m: 0.9016 - f1_m: 0.9016 - single_class_accuracy: 0.8097 - single_class_recall: 0.9201 - val_loss: 0.6213 - val_recall_m: 0.8555 - val_precision_m: 0.8555 - val_f1_m: 0.8555 - val_single_class_accuracy: 0.2929 - val_single_class_recall: 0.7735\n",
      "\n",
      "Epoch 00020: val_single_class_accuracy did not improve from 0.31237\n",
      "Epoch 21/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 152s 8ms/step - loss: 0.5910 - recall_m: 0.9042 - precision_m: 0.9042 - f1_m: 0.9042 - single_class_accuracy: 0.8146 - single_class_recall: 0.9244 - val_loss: 0.5671 - val_recall_m: 0.8788 - val_precision_m: 0.8788 - val_f1_m: 0.8788 - val_single_class_accuracy: 0.3253 - val_single_class_recall: 0.7436\n",
      "\n",
      "Epoch 00021: val_single_class_accuracy improved from 0.31237 to 0.32534, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.021.h5\n",
      "Epoch 22/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 143s 8ms/step - loss: 0.5876 - recall_m: 0.9049 - precision_m: 0.9049 - f1_m: 0.9049 - single_class_accuracy: 0.8169 - single_class_recall: 0.9257 - val_loss: 0.5870 - val_recall_m: 0.8686 - val_precision_m: 0.8686 - val_f1_m: 0.8686 - val_single_class_accuracy: 0.3100 - val_single_class_recall: 0.7605\n",
      "\n",
      "Epoch 00022: val_single_class_accuracy did not improve from 0.32534\n",
      "Epoch 23/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 143s 8ms/step - loss: 0.5814 - recall_m: 0.9072 - precision_m: 0.9072 - f1_m: 0.9072 - single_class_accuracy: 0.8188 - single_class_recall: 0.9266 - val_loss: 0.5940 - val_recall_m: 0.8702 - val_precision_m: 0.8702 - val_f1_m: 0.8702 - val_single_class_accuracy: 0.3153 - val_single_class_recall: 0.7641\n",
      "\n",
      "Epoch 00023: val_single_class_accuracy did not improve from 0.32534\n",
      "Epoch 24/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 143s 8ms/step - loss: 0.5769 - recall_m: 0.9075 - precision_m: 0.9075 - f1_m: 0.9075 - single_class_accuracy: 0.8184 - single_class_recall: 0.9286 - val_loss: 0.5753 - val_recall_m: 0.8755 - val_precision_m: 0.8755 - val_f1_m: 0.8755 - val_single_class_accuracy: 0.3209 - val_single_class_recall: 0.7549\n",
      "\n",
      "Epoch 00024: val_single_class_accuracy did not improve from 0.32534\n",
      "Epoch 25/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 142s 8ms/step - loss: 0.5742 - recall_m: 0.9069 - precision_m: 0.9069 - f1_m: 0.9069 - single_class_accuracy: 0.8190 - single_class_recall: 0.9274 - val_loss: 0.6499 - val_recall_m: 0.8441 - val_precision_m: 0.8441 - val_f1_m: 0.8441 - val_single_class_accuracy: 0.2780 - val_single_class_recall: 0.7896\n",
      "\n",
      "Epoch 00025: val_single_class_accuracy did not improve from 0.32534\n",
      "Epoch 26/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 146s 8ms/step - loss: 0.5690 - recall_m: 0.9098 - precision_m: 0.9098 - f1_m: 0.9098 - single_class_accuracy: 0.8224 - single_class_recall: 0.9310 - val_loss: 0.6827 - val_recall_m: 0.8257 - val_precision_m: 0.8257 - val_f1_m: 0.8257 - val_single_class_accuracy: 0.2581 - val_single_class_recall: 0.7983\n",
      "\n",
      "Epoch 00026: val_single_class_accuracy did not improve from 0.32534\n",
      "Epoch 27/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 144s 8ms/step - loss: 0.5659 - recall_m: 0.9110 - precision_m: 0.9110 - f1_m: 0.9110 - single_class_accuracy: 0.8254 - single_class_recall: 0.9308 - val_loss: 0.6200 - val_recall_m: 0.8562 - val_precision_m: 0.8562 - val_f1_m: 0.8562 - val_single_class_accuracy: 0.2946 - val_single_class_recall: 0.7808\n",
      "\n",
      "Epoch 00027: val_single_class_accuracy did not improve from 0.32534\n",
      "Epoch 28/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 144s 8ms/step - loss: 0.5613 - recall_m: 0.9118 - precision_m: 0.9118 - f1_m: 0.9118 - single_class_accuracy: 0.8260 - single_class_recall: 0.9296 - val_loss: 0.5921 - val_recall_m: 0.8701 - val_precision_m: 0.8701 - val_f1_m: 0.8701 - val_single_class_accuracy: 0.3163 - val_single_class_recall: 0.7672\n",
      "\n",
      "Epoch 00028: val_single_class_accuracy did not improve from 0.32534\n",
      "Epoch 29/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 146s 8ms/step - loss: 0.5575 - recall_m: 0.9133 - precision_m: 0.9133 - f1_m: 0.9133 - single_class_accuracy: 0.8309 - single_class_recall: 0.9334 - val_loss: 0.6318 - val_recall_m: 0.8514 - val_precision_m: 0.8514 - val_f1_m: 0.8514 - val_single_class_accuracy: 0.2891 - val_single_class_recall: 0.7844\n",
      "\n",
      "Epoch 00029: val_single_class_accuracy did not improve from 0.32534\n",
      "Epoch 30/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 142s 8ms/step - loss: 0.5540 - recall_m: 0.9149 - precision_m: 0.9149 - f1_m: 0.9149 - single_class_accuracy: 0.8315 - single_class_recall: 0.9347 - val_loss: 0.5055 - val_recall_m: 0.9032 - val_precision_m: 0.9032 - val_f1_m: 0.9032 - val_single_class_accuracy: 0.3672 - val_single_class_recall: 0.7061\n",
      "\n",
      "Epoch 00030: val_single_class_accuracy improved from 0.32534 to 0.36722, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.030.h5\n",
      "Epoch 31/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 141s 8ms/step - loss: 0.5498 - recall_m: 0.9151 - precision_m: 0.9151 - f1_m: 0.9151 - single_class_accuracy: 0.8293 - single_class_recall: 0.9373 - val_loss: 0.5940 - val_recall_m: 0.8644 - val_precision_m: 0.8644 - val_f1_m: 0.8644 - val_single_class_accuracy: 0.3022 - val_single_class_recall: 0.7702\n",
      "\n",
      "Epoch 00031: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 32/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 149s 8ms/step - loss: 0.5459 - recall_m: 0.9158 - precision_m: 0.9158 - f1_m: 0.9158 - single_class_accuracy: 0.8339 - single_class_recall: 0.9357 - val_loss: 0.6063 - val_recall_m: 0.8606 - val_precision_m: 0.8606 - val_f1_m: 0.8606 - val_single_class_accuracy: 0.3005 - val_single_class_recall: 0.7755\n",
      "\n",
      "Epoch 00032: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 33/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 146s 8ms/step - loss: 0.5437 - recall_m: 0.9172 - precision_m: 0.9172 - f1_m: 0.9172 - single_class_accuracy: 0.8342 - single_class_recall: 0.9365 - val_loss: 0.6134 - val_recall_m: 0.8607 - val_precision_m: 0.8607 - val_f1_m: 0.8607 - val_single_class_accuracy: 0.3033 - val_single_class_recall: 0.7837\n",
      "\n",
      "Epoch 00033: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 34/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 141s 8ms/step - loss: 0.5384 - recall_m: 0.9191 - precision_m: 0.9191 - f1_m: 0.9191 - single_class_accuracy: 0.8382 - single_class_recall: 0.9394 - val_loss: 1.3124 - val_recall_m: 0.5537 - val_precision_m: 0.5537 - val_f1_m: 0.5537 - val_single_class_accuracy: 0.1261 - val_single_class_recall: 0.8460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 35/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 145s 8ms/step - loss: 0.5353 - recall_m: 0.9191 - precision_m: 0.9191 - f1_m: 0.9191 - single_class_accuracy: 0.8397 - single_class_recall: 0.9389 - val_loss: 0.5755 - val_recall_m: 0.8752 - val_precision_m: 0.8752 - val_f1_m: 0.8752 - val_single_class_accuracy: 0.3236 - val_single_class_recall: 0.7633\n",
      "\n",
      "Epoch 00035: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 36/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 144s 8ms/step - loss: 0.5329 - recall_m: 0.9212 - precision_m: 0.9212 - f1_m: 0.9212 - single_class_accuracy: 0.8418 - single_class_recall: 0.9416 - val_loss: 0.5252 - val_recall_m: 0.8945 - val_precision_m: 0.8945 - val_f1_m: 0.8945 - val_single_class_accuracy: 0.3541 - val_single_class_recall: 0.7330\n",
      "\n",
      "Epoch 00036: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 37/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 141s 8ms/step - loss: 0.5298 - recall_m: 0.9212 - precision_m: 0.9212 - f1_m: 0.9212 - single_class_accuracy: 0.8413 - single_class_recall: 0.9395 - val_loss: 0.5862 - val_recall_m: 0.8717 - val_precision_m: 0.8717 - val_f1_m: 0.8717 - val_single_class_accuracy: 0.3187 - val_single_class_recall: 0.7681\n",
      "\n",
      "Epoch 00037: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 38/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 145s 8ms/step - loss: 0.5265 - recall_m: 0.9242 - precision_m: 0.9242 - f1_m: 0.9242 - single_class_accuracy: 0.8481 - single_class_recall: 0.9429 - val_loss: 0.6492 - val_recall_m: 0.8475 - val_precision_m: 0.8475 - val_f1_m: 0.8475 - val_single_class_accuracy: 0.2853 - val_single_class_recall: 0.7952\n",
      "\n",
      "Epoch 00038: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 39/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 144s 8ms/step - loss: 0.5226 - recall_m: 0.9239 - precision_m: 0.9239 - f1_m: 0.9239 - single_class_accuracy: 0.8463 - single_class_recall: 0.9423 - val_loss: 0.5268 - val_recall_m: 0.8948 - val_precision_m: 0.8948 - val_f1_m: 0.8948 - val_single_class_accuracy: 0.3536 - val_single_class_recall: 0.7353\n",
      "\n",
      "Epoch 00039: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 40/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 142s 8ms/step - loss: 0.5180 - recall_m: 0.9254 - precision_m: 0.9254 - f1_m: 0.9254 - single_class_accuracy: 0.8478 - single_class_recall: 0.9474 - val_loss: 0.5261 - val_recall_m: 0.8931 - val_precision_m: 0.8931 - val_f1_m: 0.8931 - val_single_class_accuracy: 0.3509 - val_single_class_recall: 0.7347\n",
      "\n",
      "Epoch 00040: val_single_class_accuracy did not improve from 0.36722\n",
      "Epoch 41/100\n",
      "Learning rate:  0.01\n",
      "18006/18006 [==============================] - 147s 8ms/step - loss: 0.5171 - recall_m: 0.9260 - precision_m: 0.9260 - f1_m: 0.9260 - single_class_accuracy: 0.8508 - single_class_recall: 0.9456 - val_loss: 0.4869 - val_recall_m: 0.9076 - val_precision_m: 0.9076 - val_f1_m: 0.9076 - val_single_class_accuracy: 0.3789 - val_single_class_recall: 0.7053\n",
      "\n",
      "Epoch 00041: val_single_class_accuracy improved from 0.36722 to 0.37893, saving model to D:\\Work\\projects\\DL for MS\\Notebooks\\models\\Sampled_ResNet11v2_model.041.h5\n",
      "Epoch 42/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "18006/18006 [==============================] - 144s 8ms/step - loss: 0.5070 - recall_m: 0.9281 - precision_m: 0.9281 - f1_m: 0.9281 - single_class_accuracy: 0.8506 - single_class_recall: 0.9537 - val_loss: 0.5912 - val_recall_m: 0.8700 - val_precision_m: 0.8700 - val_f1_m: 0.8700 - val_single_class_accuracy: 0.3157 - val_single_class_recall: 0.7750\n",
      "\n",
      "Epoch 00042: val_single_class_accuracy did not improve from 0.37893\n",
      "Epoch 43/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "18006/18006 [==============================] - 141s 8ms/step - loss: 0.5069 - recall_m: 0.9287 - precision_m: 0.9287 - f1_m: 0.9287 - single_class_accuracy: 0.8516 - single_class_recall: 0.9549 - val_loss: 0.5899 - val_recall_m: 0.8704 - val_precision_m: 0.8704 - val_f1_m: 0.8704 - val_single_class_accuracy: 0.3161 - val_single_class_recall: 0.7744\n",
      "\n",
      "Epoch 00043: val_single_class_accuracy did not improve from 0.37893\n",
      "Epoch 44/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "18006/18006 [==============================] - 140s 8ms/step - loss: 0.5095 - recall_m: 0.9271 - precision_m: 0.9271 - f1_m: 0.9271 - single_class_accuracy: 0.8470 - single_class_recall: 0.9515 - val_loss: 0.5915 - val_recall_m: 0.8699 - val_precision_m: 0.8699 - val_f1_m: 0.8699 - val_single_class_accuracy: 0.3158 - val_single_class_recall: 0.7761\n",
      "\n",
      "Epoch 00044: val_single_class_accuracy did not improve from 0.37893\n",
      "Epoch 45/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "18006/18006 [==============================] - 142s 8ms/step - loss: 0.5071 - recall_m: 0.9293 - precision_m: 0.9293 - f1_m: 0.9293 - single_class_accuracy: 0.8517 - single_class_recall: 0.9564 - val_loss: 0.5921 - val_recall_m: 0.8698 - val_precision_m: 0.8698 - val_f1_m: 0.8698 - val_single_class_accuracy: 0.3155 - val_single_class_recall: 0.7761\n",
      "\n",
      "Epoch 00045: val_single_class_accuracy did not improve from 0.37893\n",
      "Epoch 46/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "18006/18006 [==============================] - 140s 8ms/step - loss: 0.5076 - recall_m: 0.9281 - precision_m: 0.9281 - f1_m: 0.9281 - single_class_accuracy: 0.8522 - single_class_recall: 0.9520 - val_loss: 0.5868 - val_recall_m: 0.8718 - val_precision_m: 0.8718 - val_f1_m: 0.8718 - val_single_class_accuracy: 0.3187 - val_single_class_recall: 0.7718\n",
      "\n",
      "Epoch 00046: val_single_class_accuracy did not improve from 0.37893\n",
      "Epoch 47/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "18006/18006 [==============================] - 142s 8ms/step - loss: 0.5070 - recall_m: 0.9289 - precision_m: 0.9289 - f1_m: 0.9289 - single_class_accuracy: 0.8508 - single_class_recall: 0.9545 - val_loss: 0.5899 - val_recall_m: 0.8708 - val_precision_m: 0.8708 - val_f1_m: 0.8708 - val_single_class_accuracy: 0.3173 - val_single_class_recall: 0.7749\n",
      "\n",
      "Epoch 00047: val_single_class_accuracy did not improve from 0.37893\n",
      "Epoch 48/100\n",
      "Learning rate:  1.0000000000000002e-06\n",
      " 4960/18006 [=======>......................] - ETA: 55s - loss: 0.5002 - recall_m: 0.9302 - precision_m: 0.9302 - f1_m: 0.9302 - single_class_accuracy: 0.8576 - single_class_recall: 0.9551"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-76a02f518b9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m               callbacks=callbacks,class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'Sampled_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_single_class_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer =  ReduceLROnPlateau(min_lr=1e-6, monitor='val_single_class_accuracy', verbose=1,factor=0.8,patience=20)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train_,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test, Y_test_),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks,class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/ICC_ResNet20v2_model.001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = y_pred.argmax(axis=1)\n",
    "classification_report(y_test, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, Reshape#, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers.noise import GaussianNoise\n",
    "#Hyperparameters for the network\n",
    "DENSE = 256\n",
    "DROPOUT = 0.5\n",
    "C1_K  = 8 #Number of kernels/feature extractors for first layer\n",
    "C1_S  = 3 #Width of the convolutional mini networks\n",
    "C2_K  = 8\n",
    "C2_S  = 3\n",
    "C3_K  = 4\n",
    "C3_S  = 3\n",
    "C4_K  = 1\n",
    "C4_S  = 3\n",
    "\n",
    "activation='relu'\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "#The model\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    #Adding a bit of GaussianNoise also works as regularization\n",
    "    model.add(GaussianNoise(0, input_shape=(input_dim,)))\n",
    "    #First two is number of filter + kernel size\n",
    "    model.add(Reshape((input_dim, 1)))\n",
    "    model.add(Conv1D(C1_K, (C1_S), activation=activation, border_mode=\"same\"))\n",
    "    model.add(Conv1D(C2_K, (C2_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Conv1D(C3_K, (C3_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Conv1D(C4_K, (C4_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(DENSE, activation=activation))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adadelta(lr=1e-3),\n",
    "                  metrics=[recall_m,precision_m,f1_m,single_class_accuracy,single_class_recall])#, metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_15 (GaussianN (None, 12001)             0         \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (None, 12001, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 12001, 8)          32        \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 12001, 8)          200       \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 12001, 4)          100       \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 12001, 1)          13        \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 12001)             0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 12001)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               3072512   \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,073,371\n",
      "Trainable params: 3,073,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(8, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(8, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(4, 3, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\Richard\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(1, 3, activation=\"relu\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "#keras.backend.clear_session()\n",
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65244 samples, validate on 27962 samples\n",
      "Epoch 1/200\n",
      "65244/65244 [==============================] - 21s 321us/step - loss: 1.3127 - recall_m: 0.3555 - precision_m: 0.3555 - f1_m: 0.3555 - single_class_accuracy: 0.0541 - single_class_recall: 0.6721 - val_loss: 0.6935 - val_recall_m: 0.4027 - val_precision_m: 0.4027 - val_f1_m: 0.4027 - val_single_class_accuracy: 0.0568 - val_single_class_recall: 0.6503\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.05678, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.001.h5\n",
      "Epoch 2/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3126 - recall_m: 0.3939 - precision_m: 0.3939 - f1_m: 0.3939 - single_class_accuracy: 0.0562 - single_class_recall: 0.6621 - val_loss: 0.6934 - val_recall_m: 0.4241 - val_precision_m: 0.4241 - val_f1_m: 0.4241 - val_single_class_accuracy: 0.0583 - val_single_class_recall: 0.6430\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.05678 to 0.05828, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.002.h5\n",
      "Epoch 3/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3126 - recall_m: 0.4254 - precision_m: 0.4254 - f1_m: 0.4254 - single_class_accuracy: 0.0579 - single_class_recall: 0.6435 - val_loss: 0.6933 - val_recall_m: 0.4841 - val_precision_m: 0.4841 - val_f1_m: 0.4841 - val_single_class_accuracy: 0.0607 - val_single_class_recall: 0.5894\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy improved from 0.05828 to 0.06074, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.003.h5\n",
      "Epoch 4/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3125 - recall_m: 0.4728 - precision_m: 0.4728 - f1_m: 0.4728 - single_class_accuracy: 0.0594 - single_class_recall: 0.6030 - val_loss: 0.6931 - val_recall_m: 0.5461 - val_precision_m: 0.5461 - val_f1_m: 0.5461 - val_single_class_accuracy: 0.0631 - val_single_class_recall: 0.5313\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.06074 to 0.06311, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.004.h5\n",
      "Epoch 5/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3125 - recall_m: 0.5069 - precision_m: 0.5069 - f1_m: 0.5069 - single_class_accuracy: 0.0605 - single_class_recall: 0.5656 - val_loss: 0.6930 - val_recall_m: 0.5877 - val_precision_m: 0.5877 - val_f1_m: 0.5877 - val_single_class_accuracy: 0.0671 - val_single_class_recall: 0.5120\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy improved from 0.06311 to 0.06708, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.005.h5\n",
      "Epoch 6/200\n",
      "65244/65244 [==============================] - 20s 301us/step - loss: 1.3125 - recall_m: 0.5721 - precision_m: 0.5721 - f1_m: 0.5721 - single_class_accuracy: 0.0634 - single_class_recall: 0.5046 - val_loss: 0.6929 - val_recall_m: 0.6366 - val_precision_m: 0.6366 - val_f1_m: 0.6366 - val_single_class_accuracy: 0.0714 - val_single_class_recall: 0.4751\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy improved from 0.06708 to 0.07143, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.006.h5\n",
      "Epoch 7/200\n",
      "65244/65244 [==============================] - 20s 300us/step - loss: 1.3124 - recall_m: 0.5747 - precision_m: 0.5747 - f1_m: 0.5747 - single_class_accuracy: 0.0629 - single_class_recall: 0.5071 - val_loss: 0.6928 - val_recall_m: 0.6643 - val_precision_m: 0.6643 - val_f1_m: 0.6643 - val_single_class_accuracy: 0.0740 - val_single_class_recall: 0.4532\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy improved from 0.07143 to 0.07405, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.007.h5\n",
      "Epoch 8/200\n",
      "65244/65244 [==============================] - 20s 301us/step - loss: 1.3124 - recall_m: 0.5934 - precision_m: 0.5934 - f1_m: 0.5934 - single_class_accuracy: 0.0653 - single_class_recall: 0.4945 - val_loss: 0.6927 - val_recall_m: 0.6938 - val_precision_m: 0.6938 - val_f1_m: 0.6938 - val_single_class_accuracy: 0.0777 - val_single_class_recall: 0.4296\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy improved from 0.07405 to 0.07768, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.008.h5\n",
      "Epoch 9/200\n",
      "65244/65244 [==============================] - 20s 306us/step - loss: 1.3123 - recall_m: 0.6130 - precision_m: 0.6130 - f1_m: 0.6130 - single_class_accuracy: 0.0679 - single_class_recall: 0.4893 - val_loss: 0.6926 - val_recall_m: 0.7176 - val_precision_m: 0.7176 - val_f1_m: 0.7176 - val_single_class_accuracy: 0.0811 - val_single_class_recall: 0.4095\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy improved from 0.07768 to 0.08105, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.009.h5\n",
      "Epoch 10/200\n",
      "65244/65244 [==============================] - 20s 303us/step - loss: 1.3123 - recall_m: 0.6461 - precision_m: 0.6461 - f1_m: 0.6461 - single_class_accuracy: 0.0702 - single_class_recall: 0.4617 - val_loss: 0.6924 - val_recall_m: 0.7502 - val_precision_m: 0.7502 - val_f1_m: 0.7502 - val_single_class_accuracy: 0.0852 - val_single_class_recall: 0.3718\n",
      "\n",
      "Epoch 00010: val_single_class_accuracy improved from 0.08105 to 0.08515, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_CNN_model.010.h5\n",
      "Epoch 11/200\n",
      "26752/65244 [===========>..................] - ETA: 9s - loss: 1.3077 - recall_m: 0.6414 - precision_m: 0.6414 - f1_m: 0.6414 - single_class_accuracy: 0.0712 - single_class_recall: 0.4787"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-869fff6dd0f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n\u001b[1;32m---> 15\u001b[1;33m          class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    183\u001b[0m                         \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[1;32m--> 185\u001b[1;33m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[0;32m    186\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rdlr = ReduceLROnPlateau( min_lr=1e-6, monitor='val_single_class_accuracy', verbose=1,factor=0.8,patience=20)\n",
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'abd_CNN_model.{epoch:03d}.h5' \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_single_class_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n",
    "         class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ce3575d7cb95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_single_class_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'true positive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_recall_m'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_recall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(model.history.history['val_single_class_accuracy'], label='true positive')\n",
    "plt.plot(model.history.history['val_recall_m'], label='val_recall')\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "# ax2 = plt.gca().twinx()\n",
    "# ax2.plot(model.history.history['lr'], color='r')\n",
    "# ax2.set_ylabel('lr',color='r')\n",
    "\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model trained on ABD dataset\n",
    "\n",
    "dependencies = {\n",
    "    'recall_m': recall_m,'precision_m':precision_m,'f1_m':f1_m,'single_class_accuracy':single_class_accuracy,\n",
    "    'single_class_recall':single_class_recall\n",
    "}\n",
    "model = keras.models.load_model('models/abd_CNN_model.001.h5',custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9529284164859002,\n",
       "  'recall': 0.33177252473378144,\n",
       "  'f1-score': 0.49218531174724106,\n",
       "  'support': 26482},\n",
       " '1': {'precision': 0.05581047913776545,\n",
       "  'recall': 0.7067567567567568,\n",
       "  'f1-score': 0.10345168628226684,\n",
       "  'support': 1480},\n",
       " 'accuracy': 0.3516200557900007,\n",
       " 'macro avg': {'precision': 0.5043694478118328,\n",
       "  'recall': 0.5192646407452691,\n",
       "  'f1-score': 0.29781849901475393,\n",
       "  'support': 27962},\n",
       " 'weighted avg': {'precision': 0.9054448835742616,\n",
       "  'recall': 0.3516200557900007,\n",
       "  'f1-score': 0.47161003938874874,\n",
       "  'support': 27962}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "classification_report(y_test.argmax(axis=1), y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOADING second dataset\n",
    "# df_abd=pd.read_pickle('Orbitrap_aplysia/buc.pkl')\n",
    "# psm_ID=list(pd.read_csv('Aplysia_ganglia/Buccal/DB search psm.csv')['Scan'])\n",
    "# y=np.zeros(df_abd.shape[0])\n",
    "\n",
    "# for i in range(0,df_abd.shape[0]):\n",
    "#     if df_abd.index[i] in psm_ID:\n",
    "#         y[i]=1\n",
    "\n",
    "# X = df_abd.drop('RT',axis=1).fillna(0).values\n",
    "# y =y.astype(int)[X.sum(axis=1)!=0]\n",
    "# X = X[X.sum(axis=1)!=0]\n",
    "# X = X/X.max(axis=1).reshape(X.shape[0],1)\n",
    "\n",
    "# del df_abd\n",
    "# X = X.reshape((X.shape[0],X.shape[1]))\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "# del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32677 samples, validate on 14005 samples\n",
      "Epoch 1/100\n",
      "32677/32677 [==============================] - 26s 804us/step - loss: 1.3185 - recall_m: 0.9561 - precision_m: 0.9561 - f1_m: 0.9561 - single_class_accuracy: 0.1658 - val_loss: 0.6697 - val_recall_m: 0.9508 - val_precision_m: 0.9508 - val_f1_m: 0.9508 - val_single_class_accuracy: 0.3039\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.30391, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.001.h5\n",
      "Epoch 2/100\n",
      "32677/32677 [==============================] - 18s 550us/step - loss: 1.3170 - recall_m: 0.9560 - precision_m: 0.9560 - f1_m: 0.9560 - single_class_accuracy: 0.2288 - val_loss: 0.6677 - val_recall_m: 0.9514 - val_precision_m: 0.9514 - val_f1_m: 0.9514 - val_single_class_accuracy: 0.3097\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.30391 to 0.30970, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.002.h5\n",
      "Epoch 3/100\n",
      "32677/32677 [==============================] - 18s 550us/step - loss: 1.3157 - recall_m: 0.9550 - precision_m: 0.9550 - f1_m: 0.9550 - single_class_accuracy: 0.2132 - val_loss: 0.6659 - val_recall_m: 0.9513 - val_precision_m: 0.9513 - val_f1_m: 0.9513 - val_single_class_accuracy: 0.3120\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy improved from 0.30970 to 0.31199, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.003.h5\n",
      "Epoch 4/100\n",
      "32677/32677 [==============================] - 18s 550us/step - loss: 1.3142 - recall_m: 0.9565 - precision_m: 0.9565 - f1_m: 0.9565 - single_class_accuracy: 0.2343 - val_loss: 0.6646 - val_recall_m: 0.9502 - val_precision_m: 0.9502 - val_f1_m: 0.9502 - val_single_class_accuracy: 0.3296\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.31199 to 0.32961, saving model to D:\\Work\\projects\\DL for MS\\models\\buc_CNN_model.004.h5\n",
      "Epoch 5/100\n",
      "32677/32677 [==============================] - 18s 552us/step - loss: 1.3126 - recall_m: 0.9569 - precision_m: 0.9569 - f1_m: 0.9569 - single_class_accuracy: 0.2637 - val_loss: 0.6640 - val_recall_m: 0.9472 - val_precision_m: 0.9472 - val_f1_m: 0.9472 - val_single_class_accuracy: 0.3274\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 6/100\n",
      "32677/32677 [==============================] - 18s 552us/step - loss: 1.3109 - recall_m: 0.9532 - precision_m: 0.9532 - f1_m: 0.9532 - single_class_accuracy: 0.2700 - val_loss: 0.6632 - val_recall_m: 0.9437 - val_precision_m: 0.9437 - val_f1_m: 0.9437 - val_single_class_accuracy: 0.3203\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 7/100\n",
      "32677/32677 [==============================] - 18s 555us/step - loss: 1.3095 - recall_m: 0.9448 - precision_m: 0.9448 - f1_m: 0.9448 - single_class_accuracy: 0.2406 - val_loss: 0.6622 - val_recall_m: 0.9377 - val_precision_m: 0.9377 - val_f1_m: 0.9377 - val_single_class_accuracy: 0.2968\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 8/100\n",
      "32677/32677 [==============================] - 18s 551us/step - loss: 1.3076 - recall_m: 0.9438 - precision_m: 0.9438 - f1_m: 0.9438 - single_class_accuracy: 0.2795 - val_loss: 0.6629 - val_recall_m: 0.9117 - val_precision_m: 0.9117 - val_f1_m: 0.9117 - val_single_class_accuracy: 0.2395\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 9/100\n",
      "32677/32677 [==============================] - 18s 555us/step - loss: 1.3052 - recall_m: 0.9248 - precision_m: 0.9248 - f1_m: 0.9248 - single_class_accuracy: 0.2192 - val_loss: 0.6630 - val_recall_m: 0.8743 - val_precision_m: 0.8743 - val_f1_m: 0.8743 - val_single_class_accuracy: 0.1783\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy did not improve from 0.32961\n",
      "Epoch 10/100\n",
      " 7424/32677 [=====>........................] - ETA: 12s - loss: 1.2974 - recall_m: 0.9127 - precision_m: 0.9127 - f1_m: 0.9127 - single_class_accuracy: 0.1853"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-26d83e5c8312>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n\u001b[1;32m---> 15\u001b[1;33m          class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# rdlr = ReduceLROnPlateau( min_lr=1e-4, monitor='val_single_class_accuracy', verbose=1,factor=0.8,patience=20)\n",
    "# save_dir = os.path.join(os.getcwd(), 'models')\n",
    "# model_name = 'buc_CNN_model.{epoch:03d}.h5' \n",
    "# if not os.path.isdir(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "# filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "# checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "#                              monitor='val_single_class_accuracy',\n",
    "#                              verbose=1,\n",
    "#                              save_best_only=True)\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n",
    "#          class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[:,1:].reshape((data.shape[0],100,120,1))\n",
    "#x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=1)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65244, 100, 120, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, Reshape, MaxPooling2D#, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers.noise import GaussianNoise\n",
    "#Hyperparameters for the network\n",
    "\n",
    "\n",
    "input_dim = x_train.shape[1:]\n",
    "\n",
    "#The model\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    #convolutional layer with rectified linear unit activation\n",
    "    model.add(Conv2D(8, kernel_size=(16, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    #32 convolution filters used each of size 3x3\n",
    "    #again\n",
    "    model.add(Conv2D(8, (1, 3), activation='relu'))\n",
    "    model.add(Conv2D(8, (1, 3), activation='relu'))\n",
    "    #64 convolution filters used each of size 3x3\n",
    "    #choose the best features via pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #randomly turn neurons on and off to improve convergence\n",
    "    model.add(Dropout(0.25))\n",
    "    #flatten since too many dimensions, we only want a classification output\n",
    "    model.add(Flatten())\n",
    "    #fully connected to get all relevant data\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    #one more dropout for convergence' sake :) \n",
    "    model.add(Dropout(0.5))\n",
    "    #output a softmax to squash the matrix into output probabilities\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adadelta(lr=1e-3),\n",
    "                  metrics=[recall_m,precision_m,f1_m,single_class_accuracy,single_class_recall])#, metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_67 (Conv2D)           (None, 85, 118, 8)        392       \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 85, 116, 8)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 85, 114, 8)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 42, 57, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 42, 57, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 19152)             0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               9806336   \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 9,808,154\n",
      "Trainable params: 9,808,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65244 samples, validate on 27962 samples\n",
      "Epoch 1/200\n",
      "65244/65244 [==============================] - 21s 327us/step - loss: 1.3129 - recall_m: 0.4690 - precision_m: 0.4690 - f1_m: 0.4690 - single_class_accuracy: 0.0540 - single_class_recall: 0.5389 - val_loss: 0.6936 - val_recall_m: 0.4779 - val_precision_m: 0.4779 - val_f1_m: 0.4779 - val_single_class_accuracy: 0.0620 - val_single_class_recall: 0.6181\n",
      "\n",
      "Epoch 00001: val_single_class_accuracy improved from -inf to 0.06198, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.001.h5\n",
      "Epoch 2/200\n",
      "65244/65244 [==============================] - 19s 295us/step - loss: 1.3121 - recall_m: 0.5247 - precision_m: 0.5247 - f1_m: 0.5247 - single_class_accuracy: 0.0613 - single_class_recall: 0.5570 - val_loss: 0.6929 - val_recall_m: 0.5737 - val_precision_m: 0.5737 - val_f1_m: 0.5737 - val_single_class_accuracy: 0.0733 - val_single_class_recall: 0.5966\n",
      "\n",
      "Epoch 00002: val_single_class_accuracy improved from 0.06198 to 0.07331, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.002.h5\n",
      "Epoch 3/200\n",
      "65244/65244 [==============================] - 19s 295us/step - loss: 1.3118 - recall_m: 0.5760 - precision_m: 0.5760 - f1_m: 0.5760 - single_class_accuracy: 0.0666 - single_class_recall: 0.5296 - val_loss: 0.6922 - val_recall_m: 0.6505 - val_precision_m: 0.6505 - val_f1_m: 0.6505 - val_single_class_accuracy: 0.0858 - val_single_class_recall: 0.5722\n",
      "\n",
      "Epoch 00003: val_single_class_accuracy improved from 0.07331 to 0.08582, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.003.h5\n",
      "Epoch 4/200\n",
      "65244/65244 [==============================] - 19s 298us/step - loss: 1.3113 - recall_m: 0.6079 - precision_m: 0.6079 - f1_m: 0.6079 - single_class_accuracy: 0.0705 - single_class_recall: 0.5286 - val_loss: 0.6916 - val_recall_m: 0.6939 - val_precision_m: 0.6939 - val_f1_m: 0.6939 - val_single_class_accuracy: 0.0947 - val_single_class_recall: 0.5539\n",
      "\n",
      "Epoch 00004: val_single_class_accuracy improved from 0.08582 to 0.09472, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.004.h5\n",
      "Epoch 5/200\n",
      "65244/65244 [==============================] - 19s 292us/step - loss: 1.3107 - recall_m: 0.6432 - precision_m: 0.6432 - f1_m: 0.6432 - single_class_accuracy: 0.0781 - single_class_recall: 0.5250 - val_loss: 0.6909 - val_recall_m: 0.7262 - val_precision_m: 0.7262 - val_f1_m: 0.7262 - val_single_class_accuracy: 0.1022 - val_single_class_recall: 0.5366\n",
      "\n",
      "Epoch 00005: val_single_class_accuracy improved from 0.09472 to 0.10225, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.005.h5\n",
      "Epoch 6/200\n",
      "65244/65244 [==============================] - 19s 293us/step - loss: 1.3101 - recall_m: 0.6718 - precision_m: 0.6718 - f1_m: 0.6718 - single_class_accuracy: 0.0826 - single_class_recall: 0.5093 - val_loss: 0.6902 - val_recall_m: 0.7483 - val_precision_m: 0.7483 - val_f1_m: 0.7483 - val_single_class_accuracy: 0.1088 - val_single_class_recall: 0.5220\n",
      "\n",
      "Epoch 00006: val_single_class_accuracy improved from 0.10225 to 0.10884, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.006.h5\n",
      "Epoch 7/200\n",
      "65244/65244 [==============================] - 19s 296us/step - loss: 1.3094 - recall_m: 0.6985 - precision_m: 0.6985 - f1_m: 0.6985 - single_class_accuracy: 0.0882 - single_class_recall: 0.5027 - val_loss: 0.6895 - val_recall_m: 0.7645 - val_precision_m: 0.7645 - val_f1_m: 0.7645 - val_single_class_accuracy: 0.1151 - val_single_class_recall: 0.5152\n",
      "\n",
      "Epoch 00007: val_single_class_accuracy improved from 0.10884 to 0.11506, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.007.h5\n",
      "Epoch 8/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3091 - recall_m: 0.7182 - precision_m: 0.7182 - f1_m: 0.7182 - single_class_accuracy: 0.0938 - single_class_recall: 0.4930 - val_loss: 0.6888 - val_recall_m: 0.7763 - val_precision_m: 0.7763 - val_f1_m: 0.7763 - val_single_class_accuracy: 0.1191 - val_single_class_recall: 0.5052\n",
      "\n",
      "Epoch 00008: val_single_class_accuracy improved from 0.11506 to 0.11915, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.008.h5\n",
      "Epoch 9/200\n",
      "65244/65244 [==============================] - 20s 299us/step - loss: 1.3083 - recall_m: 0.7400 - precision_m: 0.7400 - f1_m: 0.7400 - single_class_accuracy: 0.0999 - single_class_recall: 0.4887 - val_loss: 0.6880 - val_recall_m: 0.7843 - val_precision_m: 0.7843 - val_f1_m: 0.7843 - val_single_class_accuracy: 0.1223 - val_single_class_recall: 0.4985\n",
      "\n",
      "Epoch 00009: val_single_class_accuracy improved from 0.11915 to 0.12230, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.009.h5\n",
      "Epoch 10/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3077 - recall_m: 0.7473 - precision_m: 0.7473 - f1_m: 0.7473 - single_class_accuracy: 0.1035 - single_class_recall: 0.4862 - val_loss: 0.6872 - val_recall_m: 0.7873 - val_precision_m: 0.7873 - val_f1_m: 0.7873 - val_single_class_accuracy: 0.1234 - val_single_class_recall: 0.4949\n",
      "\n",
      "Epoch 00010: val_single_class_accuracy improved from 0.12230 to 0.12341, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.010.h5\n",
      "Epoch 11/200\n",
      "65244/65244 [==============================] - 19s 295us/step - loss: 1.3071 - recall_m: 0.7571 - precision_m: 0.7571 - f1_m: 0.7571 - single_class_accuracy: 0.1058 - single_class_recall: 0.4734 - val_loss: 0.6865 - val_recall_m: 0.7901 - val_precision_m: 0.7901 - val_f1_m: 0.7901 - val_single_class_accuracy: 0.1247 - val_single_class_recall: 0.4931\n",
      "\n",
      "Epoch 00011: val_single_class_accuracy improved from 0.12341 to 0.12465, saving model to D:\\Work\\projects\\DL for MS\\models\\abd_buc_CNN2D_model.011.h5\n",
      "Epoch 12/200\n",
      "65244/65244 [==============================] - 19s 296us/step - loss: 1.3061 - recall_m: 0.7704 - precision_m: 0.7704 - f1_m: 0.7704 - single_class_accuracy: 0.1119 - single_class_recall: 0.4792 - val_loss: 0.6857 - val_recall_m: 0.7919 - val_precision_m: 0.7919 - val_f1_m: 0.7919 - val_single_class_accuracy: 0.1242 - val_single_class_recall: 0.4878\n",
      "\n",
      "Epoch 00012: val_single_class_accuracy did not improve from 0.12465\n",
      "Epoch 13/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3054 - recall_m: 0.7695 - precision_m: 0.7695 - f1_m: 0.7695 - single_class_accuracy: 0.1123 - single_class_recall: 0.4846 - val_loss: 0.6849 - val_recall_m: 0.7913 - val_precision_m: 0.7913 - val_f1_m: 0.7913 - val_single_class_accuracy: 0.1239 - val_single_class_recall: 0.4857\n",
      "\n",
      "Epoch 00013: val_single_class_accuracy did not improve from 0.12465\n",
      "Epoch 14/200\n",
      "65244/65244 [==============================] - 19s 294us/step - loss: 1.3043 - recall_m: 0.7704 - precision_m: 0.7704 - f1_m: 0.7704 - single_class_accuracy: 0.1148 - single_class_recall: 0.4969 - val_loss: 0.6842 - val_recall_m: 0.7894 - val_precision_m: 0.7894 - val_f1_m: 0.7894 - val_single_class_accuracy: 0.1233 - val_single_class_recall: 0.4904\n",
      "\n",
      "Epoch 00014: val_single_class_accuracy did not improve from 0.12465\n",
      "Epoch 15/200\n",
      "39040/65244 [================>.............] - ETA: 6s - loss: 1.3068 - recall_m: 0.7694 - precision_m: 0.7694 - f1_m: 0.7694 - single_class_accuracy: 0.1154 - single_class_recall: 0.5006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-7f6c1b51bedd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n\u001b[1;32m---> 15\u001b[1;33m          class_weight={0:1,1:scale_weight})\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rdlr = ReduceLROnPlateau( min_lr=1e-6, monitor='val_single_class_accuracy', verbose=1,factor=0.5,patience=20)\n",
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "model_name = 'abd_buc_CNN2D_model.{epoch:03d}.h5' \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_single_class_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_test, y_test), callbacks=[rdlr,checkpoint],\n",
    "         class_weight={0:1,1:scale_weight})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
